{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17493425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "import copy\n",
    "import pandas as pd\n",
    "from scipy.special import comb\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sns.set_style(\"whitegrid\") #darkgrid\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "SMALL_SIZE=12\n",
    "MEDIUM_SIZE=15\n",
    "BIGGER_SIZE=20\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "#plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "#plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.metrics as metrics\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "print(physical_devices)\n",
    "import concept_model\n",
    "import helper\n",
    "# from test_baselines import run_eval\n",
    "\n",
    "\n",
    "from utils.test_utils import arg_parser, prepare_data, get_measures\n",
    "from utils.test_utils import ConceptProfiles\n",
    "from utils.test_utils import get_recovered_features\n",
    "from utils.ood_utils import run_ood_over_batch\n",
    "from utils.stat_utils import hellinger, compute_pval, bayes_posterior, FLD, multivar_separa\n",
    "from utils.plot_utils import plot_stats, plot_per_class_stats, plot_score_distr\n",
    "from utils import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03108c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.in_data = \"data/AwA2/test\"\n",
    "        self.out_data = \"MSCOCO\"\n",
    "        self.workers = 4\n",
    "        \n",
    "        self.batch_size = 256\n",
    "        self.name = \"test\"\n",
    "        self.model = \"InceptionV3\"\n",
    "        self.model_path = \"results/AwA2/inceptionv3_AwA2_e20.weights.h5\"\n",
    "\n",
    "        self.gpu = \"0\"\n",
    "        self.result_dir = \"results/AwA2_1_baseline_s0/epoch_20\"\n",
    "        self.logdir = self.result_dir+\"/logs\"\n",
    "        \n",
    "        self.visualize = True\n",
    "        self.visualize_with_ood = True\n",
    "        self.shap = True\n",
    "        self.separate = True\n",
    "        self.explain = True\n",
    "        self.plot = True\n",
    "        self.out_data_dim = 224\n",
    "        self.score = \"Energy\"\n",
    "        self.temperature_energy = 1\n",
    "\n",
    "        self.opt = \"adam\"\n",
    "\n",
    "args = ARGS()\n",
    "softmax = layers.Activation('softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee29317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_concepts(topic_vec, return_mapping=False):\n",
    "    # Remove one concept vector if there are two vectors where the dot product is over 0.95\n",
    "    # topic_vec: dim=(dim_features, n_concepts) (2048, 70)\n",
    "    # print(np.shape(topic_vec))\n",
    "    n_concept = topic_vec.shape[1]\n",
    "    thresh = 0.95\n",
    "    topic_vec_n = topic_vec/(np.linalg.norm(topic_vec,axis=0,keepdims=True)+1e-9)\n",
    "\n",
    "    topic_vec_n_dot = np.transpose(topic_vec_n) @ topic_vec_n - np.eye(n_concept)\n",
    "    dict_similar_topic = {}\n",
    "    idx_delete = set()\n",
    "    for i in range(n_concept):\n",
    "        ith_redundant_concepts = [j for j in range(n_concept) if topic_vec_n_dot[i][j] >= 0.95]\n",
    "        dict_similar_topic[i] = ith_redundant_concepts\n",
    "        \n",
    "        ith_redundant_concepts = [x for x in ith_redundant_concepts if x > i]\n",
    "        idx_delete.update(ith_redundant_concepts)\n",
    "    idx_delete = list(idx_delete)\n",
    "\n",
    "    print(dict_similar_topic)\n",
    "    print(idx_delete)\n",
    "\n",
    "    topic_vec_r = np.delete(topic_vec, idx_delete, axis=1)\n",
    "\n",
    "\n",
    "    dict_topic_mapping = {}\n",
    "    count = 0\n",
    "    for i in range(n_concept):\n",
    "        if i in idx_delete:\n",
    "            dict_topic_mapping[i] = None\n",
    "        else:\n",
    "            dict_topic_mapping[i] = count\n",
    "            count += 1\n",
    "    print('concept mapping between before/after duplicate removal......')\n",
    "    print(dict_topic_mapping)\n",
    "    if return_mapping:\n",
    "        return topic_vec_r, dict_similar_topic, dict_topic_mapping\n",
    "    else:\n",
    "        return topic_vec_r, dict_similar_topic\n",
    "    \n",
    "def compute_concept_scores(topic_vec, feature, predict_model=None):\n",
    "    # topic_vec: concept vectors (dim= (feature_dim, n_concepts))\n",
    "    # feature: features extracted from an intermediate layer of trained model\n",
    "\n",
    "    feature_n = tf.math.l2_normalize(feature, axis=3)\n",
    "    topic_vec_n = tf.math.l2_normalize(topic_vec, axis=0)\n",
    "\n",
    "    topic_prob = tf.matmul(feature_n, topic_vec_n) # K.dot\n",
    "\n",
    "    prob_max = tf.math.reduce_max(topic_prob, axis=(1,2))\n",
    "    prob_max_abs = tf.math.reduce_max(tf.abs(topic_prob), axis=(1,2))\n",
    "    concept_scores = tf.where(prob_max == prob_max_abs, prob_max, -prob_max_abs)\n",
    "\n",
    "    \"\"\"\n",
    "    ##for debugging\n",
    "    n_concept = np.shape(concept_scores)[1]\n",
    "    print(tf.reduce_mean(input_tensor=tf.nn.top_k(K.transpose(K.reshape(topic_prob,(-1,n_concept))),k=10,sorted=True).values))\n",
    "    print(tf.reduce_mean(input_tensor=K.dot(K.transpose(K.variable(value=topic_vec_n)), K.variable(value=topic_vec_n)) - np.eye(n_concept)))\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if predict_model: # in eager execution\n",
    "        pred = softmax(predict_model(feature))\n",
    "        #pred = tf.math.argmax(pred, axis=1)\n",
    "        return concept_scores.numpy(), pred.numpy()\n",
    "    else:\n",
    "        return concept_scores\n",
    "\n",
    "def compute_completeness(y, yhat, yhat_recov, num_class, logger=None, label=None):\n",
    "    \"\"\"\n",
    "    compute completeness score by Yeh et al.\n",
    "    :param y: groundtruth class labels, dim=(N,)\n",
    "    :param yhat: predicted class labels, dim=(N,)\n",
    "    :param yhat_recov: predicted class labels using recovered features, dim=(N,).\n",
    "                       If label is not None, per-class predicted labels, dim=(N',) where N' <= N\n",
    "    \"\"\"\n",
    "\n",
    "    acc = np.sum(y == yhat)/len(y)\n",
    "    if logger:\n",
    "        logger.info(f'[ID TEST] accuracy with original features: {acc}')\n",
    "    \n",
    "    if label is not None:\n",
    "        acc_recov = np.sum(y[y==label] == yhat_recov)/len(yhat_recov)\n",
    "        if logger:\n",
    "            logger.info(f'[ID TEST] per-class accuracy with recovered features: {acc_recov}')\n",
    "        acc_random = 1/num_class #0.5 #NOTE: check a_r = 0.5?\n",
    "    else:\n",
    "        acc_recov = np.sum(y == yhat_recov)/len(y)\n",
    "        if logger:\n",
    "            logger.info(f'[ID TEST] accuracy with recovered features: {acc_recov}')\n",
    "        acc_random = 1/num_class\n",
    "    \n",
    "    # compute completeness\n",
    "    completeness = (acc_recov - acc_random) / (acc - 1/num_class)\n",
    "    if logger:\n",
    "        logger.info(f'[ID TEST] completeness score: {completeness}')\n",
    "    return completeness\n",
    "\n",
    "def compute_detection_completeness(auroc, auroc_recov, logger=None):\n",
    "    \"\"\"\n",
    "    compute detection completeness score\n",
    "    \"\"\"\n",
    "    # compute completeness\n",
    "    auroc_random = 1/2\n",
    "    completeness = (auroc_recov - auroc_random) / (auroc - auroc_random)\n",
    "    if logger:\n",
    "        logger.info(f'[DETECTION] auroc with original features: {auroc}')\n",
    "        logger.info(f'[DETECTION] auroc with recovered features: {auroc_recov}')\n",
    "        logger.info(f'[DETECTION] completeness score: {completeness}')\n",
    "    return completeness\n",
    "\n",
    "def run_eval(feature_model, predict_model, in_loader, out_loader, logger, args, num_classes):\n",
    "    in_scores = np.array([])\n",
    "    for i, (x, y) in tqdm(enumerate(in_loader)):\n",
    "        if i == len(in_loader):\n",
    "            break\n",
    "        score = run_ood_over_batch(x, feature_model, predict_model, args, num_classes).numpy()\n",
    "        in_scores = np.concatenate([in_scores, score])\n",
    "    out_scores = np.array([])\n",
    "    for i, x in tqdm(enumerate(out_loader)):\n",
    "        if i == len(in_loader):\n",
    "            break\n",
    "        score = run_ood_over_batch(x, feature_model, predict_model, args, num_classes).numpy()\n",
    "        out_scores = np.concatenate([out_scores, score])\n",
    "    in_examples = np.expand_dims(in_scores, axis=1)\n",
    "    out_examples = np.expand_dims(out_scores, axis=1)\n",
    "    auroc, aupr_in, aupr_out, fpr, thres95 = get_measures(in_examples, out_examples)\n",
    "    return in_scores, out_scores, auroc, fpr, thres95\n",
    "\n",
    "def get_class_labels(loader, savepath):\n",
    "    \"\"\"\n",
    "    extract groundtruth class labels from data loader\n",
    "    :param loader: data loader\n",
    "    :param savepath: path to the numpy file\n",
    "    \"\"\"\n",
    "    if os.path.exists(savepath):\n",
    "        y = np.load(savepath)\n",
    "    else:\n",
    "        num_data = len(loader.filenames)\n",
    "        y = []\n",
    "        for (_, y_batch), _ in zip(loader, range(len(loader))):\n",
    "            y.extend(y_batch)\n",
    "       \n",
    "        np.save(savepath, y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f81a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "\n",
    "# with tf.device('/CPU:0'):\n",
    "\n",
    "logger = log.setup_logger(args, filename=\"eval_{}.log\".format(args.score))\n",
    "LOAD_DIR = 'data/AwA2'\n",
    "TOPIC_PATH = os.path.join(args.result_dir,'topic_vec_inceptionv3.npy')\n",
    "INPUT_SHAPE = (args.out_data_dim, args.out_data_dim)\n",
    "TRAIN_DIR = \"data/AwA2/train\"\n",
    "N_CLASSES = 50\n",
    "N_CONCEPTS_ORIG = 100 #np.shape(topic_vec_orig)[-1]\n",
    "_ = 0\n",
    "\n",
    "if args.score == 'ODIN':\n",
    "    args.batch_size = 200\n",
    "\n",
    "if not os.path.exists(os.path.join(args.result_dir, 'plots')):\n",
    "    os.makedirs(os.path.join(args.result_dir, 'plots'))\n",
    "if not os.path.exists(os.path.join(args.result_dir, 'explanations')):\n",
    "    os.makedirs(os.path.join(args.result_dir, 'explanations'))\n",
    "if not os.path.exists(os.path.join(args.result_dir, 'explanations', args.out_data+'_'+args.score)):\n",
    "    os.makedirs(os.path.join(args.result_dir, 'explanations', args.out_data+'_'+args.score))\n",
    "explain_dir = os.path.join(args.result_dir, 'explanations', args.out_data+'_'+args.score)\n",
    "\n",
    "in_loader, out_loader = prepare_data(args, logger)\n",
    "\n",
    "## load trained_model\n",
    "logger.info(f\"Loading model from {args.model_path}\")\n",
    "feature_model, predict_model = helper.load_model_inception_new(_, in_loader, batch_size=args.batch_size, \n",
    "                                    input_size=INPUT_SHAPE, pretrain=True, modelname=args.model_path)\n",
    "\n",
    "in_test_features = feature_model.predict(in_loader)\n",
    "N_IN = in_test_features.shape[0]\n",
    "# out_test_features = feature_model.predict(out_loader, steps=len(in_loader))\n",
    "# N_OUT = out_test_features.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add30f49-65c0-4576-a101-9869005355fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load topic model\n",
    "topic_model = concept_model.TopicModel(in_test_features, N_CONCEPTS_ORIG, thres=0.0, predict=predict_model)\n",
    "topic_model(in_test_features)\n",
    "topic_model.load_weights(os.path.dirname(args.result_dir)+'/topic_epoch20.weights.h5')\n",
    "for layer in topic_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "topic_vec_orig = topic_model.layers[0].get_weights()[0]\n",
    "np.save(args.result_dir+'/topic_vec_orig.npy', topic_vec_orig)\n",
    "logger.info(f'Number of concepts before removing duplicate ones: {str(N_CONCEPTS_ORIG)}')\n",
    "\n",
    "topic_vec, dict_dupl_topic = remove_duplicate_concepts(topic_vec_orig)\n",
    "N_CONCEPTS = np.shape(topic_vec)[-1] # 25\n",
    "logger.info(f'Number of concepts after removing duplicate ones: {str(N_CONCEPTS)}')\n",
    "\n",
    "in_test_concepts, in_test_logits = compute_concept_scores(topic_vec, in_test_features, predict_model)\n",
    "in_test_yhat = np.argmax(in_test_logits, axis=1) \n",
    "\n",
    "# out_test_concepts, out_test_logits = compute_concept_scores(topic_vec, out_test_features, predict_model)\n",
    "# out_test_yhat = np.argmax(out_test_logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target OOD detector\n",
    "logger.info(\"[ID TEST] performance of target OOD detector with test set...\")\n",
    "\n",
    "## Evaluating the difference between two worlds......\n",
    "y_test = np.argmax(np.load('data/AwA2/y_test.npy'), axis=1) # true labels\n",
    "\n",
    "# compute completeness scores\n",
    "_, logits_recov, _ = topic_model(in_test_features)\n",
    "in_test_yhat_recov = tf.math.argmax(logits_recov, axis=1).numpy()\n",
    "compute_completeness(y_test, in_test_yhat, in_test_yhat_recov, N_CLASSES, logger)\n",
    "\n",
    "# in_test_scores, out_test_scores, auroc, fpr, thres95 = run_eval(feature_model, predict_model, in_loader, out_loader, logger, args, N_CLASSES)\n",
    "# in_test_scores, out_test_scores, thres95, auroc = np.random.rand(N_IN), np.random.rand(N_OUT), 0.5419758558273315, 0.955332290562036\n",
    "# compute_detection_completeness(auroc, auroc_recov, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad90b71-69a7-4163-863e-1686f9b5ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute completeness\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TRAIN_DIR = \"data/AwA2/train\"\n",
    "VAL_DIR = \"data/AwA2/val\"\n",
    "\n",
    "print('Loading images through generators ...')\n",
    "datagen = ImageDataGenerator(rescale=1. / 255.)\n",
    "train_loader = datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                            batch_size=args.batch_size,\n",
    "                                            target_size=(224, 224),\n",
    "                                            class_mode='categorical',\n",
    "                                            shuffle=True)\n",
    "val_loader = datagen.flow_from_directory(VAL_DIR,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        target_size=(224, 224),\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=False)\n",
    "\n",
    "y_val_ = np.load('data/AwA2/y_val.npy')\n",
    "y_test_ = np.load('data/AwA2/y_test.npy')\n",
    "\n",
    "if args.opt =='sgd':\n",
    "    \"\"\"\n",
    "    optimizer = SGD(lr=0.1)\n",
    "    optimizer_state = [optimizer.iterations, optimizer.lr, optimizer.momentum, optimizer.decay]\n",
    "    optimizer_reset = tf.compat.v1.variables_initializer(optimizer_state)\n",
    "    \"\"\"\n",
    "    optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "elif args.opt =='adam':\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    optimizer_state = [optimizer.iterations, optimizer.learning_rate, optimizer.beta_1, optimizer.beta_2, optimizer.weight_decay]\n",
    "    optimizer_reset = tf.compat.v1.variables_initializer(optimizer_state)\n",
    "\n",
    "train_acc_metric = metrics.CategoricalAccuracy()\n",
    "val_acc_metric = metrics.CategoricalAccuracy()\n",
    "test_acc_metric = metrics.CategoricalAccuracy()\n",
    "softmax = layers.Activation('softmax')\n",
    "\n",
    "for layer in topic_model.layers:\n",
    "    layer.trainable = True\n",
    "topic_model.layers[1].trainable = False\n",
    "topic_model.layers[-1].trainable = False\n",
    "\n",
    "@tf.function\n",
    "def train_step(x_in, y_in, x_out=None, thres=None):\n",
    "    #tf.keras.applications.inception_v3.preprocess_input(x_in)\n",
    "    f_in = feature_model(x_in)\n",
    "\n",
    "    obj_terms = {} # terms in the objective function\n",
    "    with tf.GradientTape() as tape:\n",
    "        f_in_recov, logits_in, topic_vec_n = topic_model(f_in, training=True)\n",
    "        pred_in = softmax(logits_in) # class prediction using concept scores\n",
    "\n",
    "        # total loss\n",
    "        CE_IN = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_in, pred_in))\n",
    "        loss = CE_IN\n",
    "        obj_terms['[ID] CE'] = CE_IN\n",
    "    \n",
    "    train_acc_metric.update_state(y_in, logits_in)\n",
    "    print(obj_terms)\n",
    "\n",
    "    # calculate the gradients using our tape and then update the model weights\n",
    "    print(topic_model.trainable_variables)\n",
    "    grads = tape.gradient(loss, topic_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, topic_model.trainable_variables))\n",
    "    #input()\n",
    "    return obj_terms\n",
    "\n",
    "os.makedirs(args.logdir, exist_ok=True)\n",
    "df_obj_terms = pd.DataFrame()\n",
    "for epoch in range(20):\n",
    "    logger.info(f\"\\n[INFO] starting epoch {epoch}/{20} ---------------------------------\")\n",
    "    sys.stdout.flush()\n",
    "    epochStart = time.time()\n",
    "    \n",
    "    for step, (x_in, y_in) in enumerate(train_loader):\n",
    "        \n",
    "        step += 1 # starts from 1\n",
    "        if step > len(train_loader):\n",
    "            break\n",
    "        obj_terms = train_step(x_in, y_in)\n",
    "\n",
    "        # Log every 50 batches\n",
    "        if step % 20 == 0:\n",
    "            #print(topic_model.layers[0].get_weights()[0])\n",
    "            for term in obj_terms:\n",
    "                logger.info(f'[STEP{step}] {term}: {obj_terms[term]}')\n",
    "        for term in obj_terms:\n",
    "            obj_terms[term] = obj_terms[term].numpy()\n",
    "        obj_terms[\"epoch\"] = epoch\n",
    "        obj_terms[\"step\"] = step\n",
    "        df_obj = pd.Series(obj_terms)\n",
    "        df_obj_terms = pd.concat([df_obj_terms, pd.DataFrame(df_obj).T], axis=0)\n",
    "    \n",
    "    train_acc = train_acc_metric.result()\n",
    "    logger.info(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "    \n",
    "    # show timing information for the epoch\n",
    "    epochEnd = time.time()\n",
    "    elapsed = (epochEnd - epochStart) / 60.0\n",
    "    logger.info(\"Time taken: %.2f minutes\" % (elapsed))\n",
    "\n",
    "    df_obj_terms = df_obj_terms.reset_index(drop=True)\n",
    "    df_obj_terms_melt = pd.melt(df_obj_terms, id_vars=[\"epoch\", \"step\"], \n",
    "                                value_vars=[col for col in df_obj_terms.columns if col in \n",
    "                                            ['[ID] CE']],\n",
    "                                var_name=\"loss_term\", value_name=\"loss_value\")\n",
    "\n",
    "    plt.figure()\n",
    "    sns.lineplot(data=df_obj_terms_melt, x=\"epoch\", y=\"loss_value\", hue=\"loss_term\")\n",
    "    plt.savefig(args.logdir+\"/model_compl_finetune_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_state()\n",
    "    topic_model.save_weights(os.path.join(args.logdir, args.name,'topic_compl_finetune_epoch{}.weights.h5'.format(epoch)))\n",
    "\n",
    "    _, logits_val, _ = topic_model(feature_model.predict(val_loader), training=False)\n",
    "    val_acc_metric.update_state(y_val_, logits_val)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    logger.info(\"[EPOCH %d] Validation acc: %.4f\" % (epoch, float(val_acc)))\n",
    "    val_acc_metric.reset_state()\n",
    "    del logits_val\n",
    "\n",
    "    _, logits_test, _ = topic_model(feature_model.predict(in_loader), training=False)\n",
    "    test_acc_metric.update_state(y_test_, logits_test)\n",
    "    test_acc = test_acc_metric.result()\n",
    "    logger.info(\"[EPOCH %d] Test acc: %.4f\" % (epoch, float(test_acc)))\n",
    "    test_acc_metric.reset_state()\n",
    "    del logits_test\n",
    "\n",
    "    logger.flush()\n",
    "\n",
    "for layer in topic_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a913e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute completeness scores\n",
    "_, logits_recov, _ = topic_model(in_test_features)\n",
    "in_test_yhat_recov = tf.math.argmax(logits_recov, axis=1).numpy()\n",
    "compute_completeness(y_test, in_test_yhat, in_test_yhat_recov, N_CLASSES, logger)\n",
    "# compute_detection_completeness(auroc, auroc_recov, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d1a9a-65c2-439e-9f2f-17fe2c08c9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
