{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17493425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:18:05.770456: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-01 17:18:05.787766: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-01 17:18:05.807730: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-01 17:18:05.813763: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-01 17:18:05.827826: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-01 17:18:07.290846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "import copy\n",
    "import pandas as pd\n",
    "from scipy.special import comb\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sns.set_style(\"whitegrid\") #darkgrid\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "SMALL_SIZE=12\n",
    "MEDIUM_SIZE=15\n",
    "BIGGER_SIZE=20\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "#plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "#plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.metrics as metrics\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "import concept_model\n",
    "import helper\n",
    "# from test_baselines import run_eval\n",
    "\n",
    "\n",
    "from utils.test_utils import arg_parser, prepare_data, get_measures\n",
    "from utils.test_utils import ConceptProfiles\n",
    "from utils.test_utils import get_recovered_features\n",
    "from utils.ood_utils import run_ood_over_batch\n",
    "from utils.stat_utils import hellinger, compute_pval, bayes_posterior, FLD, multivar_separa\n",
    "from utils.plot_utils import plot_stats, plot_per_class_stats, plot_score_distr\n",
    "from utils import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03108c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.in_data = \"data/AwA2/test\"\n",
    "        self.out_data = \"Places\" # Places SUN Textures MSCOCO\n",
    "        self.workers = 4\n",
    "        \n",
    "        self.batch_size = 256\n",
    "        self.name = \"test\"\n",
    "        self.model = \"InceptionV3\"\n",
    "        self.model_path = \"results/AwA2/inceptionv3_AwA2_e20.weights.h5\"\n",
    "        self.concept_sim_thr = 0.95\n",
    "        \n",
    "        self.gpu = \"0\"\n",
    "        self.result_dir = f\"results/AwA2_1_feat_l2_0.1_ood_1_sep_50_s0/epoch_40_{self.concept_sim_thr}\" # \"results/AwA2_2_feat_l2_0.1_ood_1_sep_50_s0_thr_0.2/epoch_40\"\n",
    "        self.logdir = self.result_dir+\"/logs\"\n",
    "        \n",
    "        self.visualize = True # True False\n",
    "        self.visualize_with_ood = True # True False\n",
    "        self.shap = True\n",
    "        self.separate = True\n",
    "        self.explain = True\n",
    "        self.plot = True\n",
    "        self.out_data_dim = 224\n",
    "        self.score = \"energy\"\n",
    "        self.temperature_energy = 1\n",
    "        self.temperature_odin = 1000\n",
    "        \n",
    "\n",
    "        self.opt = \"adam\"\n",
    "\n",
    "args = ARGS()\n",
    "softmax = layers.Activation('softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee29317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_concepts(topic_vec, return_mapping=False, thr=0.95):\n",
    "    # Remove one concept vector if there are two vectors where the dot product is over 0.95\n",
    "    # topic_vec: dim=(dim_features, n_concepts) (2048, 70)\n",
    "    # print(np.shape(topic_vec))\n",
    "    n_concept = topic_vec.shape[1]\n",
    "    topic_vec_n = topic_vec/(np.linalg.norm(topic_vec,axis=0,keepdims=True)+1e-9)\n",
    "\n",
    "    topic_vec_n_dot = np.transpose(topic_vec_n) @ topic_vec_n - np.eye(n_concept)\n",
    "    dict_similar_topic = {}\n",
    "    idx_delete = set()\n",
    "    for i in range(n_concept):\n",
    "        ith_redundant_concepts = [j for j in range(n_concept) if topic_vec_n_dot[i][j] >= thr]\n",
    "        dict_similar_topic[i] = ith_redundant_concepts\n",
    "        \n",
    "        ith_redundant_concepts = [x for x in ith_redundant_concepts if x > i]\n",
    "        idx_delete.update(ith_redundant_concepts)\n",
    "    idx_delete = list(idx_delete)\n",
    "\n",
    "    topic_vec_r = np.delete(topic_vec, idx_delete, axis=1)\n",
    "\n",
    "\n",
    "    dict_topic_mapping = {}\n",
    "    count = 0\n",
    "    for i in range(n_concept):\n",
    "        if i in idx_delete:\n",
    "            dict_topic_mapping[i] = None\n",
    "        else:\n",
    "            dict_topic_mapping[i] = count\n",
    "            count += 1\n",
    "    print('concept mapping between before/after duplicate removal......')\n",
    "    print(dict_topic_mapping)\n",
    "    if return_mapping:\n",
    "        return topic_vec_r, dict_similar_topic, dict_topic_mapping\n",
    "    else:\n",
    "        return topic_vec_r, dict_similar_topic\n",
    "\n",
    "def visualize_nn(test_loader, topic_vec, f_test, save_dir, logger, out_data=None, dir=\"concepts\"):\n",
    "    num_concept = topic_vec.shape[1]\n",
    "\n",
    "    f_test_n = f_test/(np.linalg.norm(f_test,axis=3,keepdims=True)+1e-9)\n",
    "    topic_vec_n = topic_vec/(np.linalg.norm(topic_vec,axis=0,keepdims=True)+1e-9)\n",
    "    topic_prob = np.matmul(f_test_n,topic_vec_n)\n",
    "    n_size = np.shape(f_test)[1]\n",
    "    for i in range(num_concept):\n",
    "      savepath = os.path.join(save_dir, dir, 'concept'+str(i))\n",
    "      os.makedirs(savepath, exist_ok=True)\n",
    "        \n",
    "      neighbors_num = 15\n",
    "      ind = np.argpartition(topic_prob[:,:,:,i].flatten(), -neighbors_num)[-neighbors_num:]\n",
    "      sim_list = topic_prob[:,:,:,i].flatten()[ind]\n",
    "      logger.info(f'[ID TEST: CONCEPT {i}] top-{neighbors_num} scores: {sim_list}')\n",
    "      for jc,j in enumerate(ind):\n",
    "        j_int = int(np.floor(j/(n_size*n_size)))\n",
    "        a = int((j-j_int*(n_size*n_size))/n_size)\n",
    "        b = int((j-j_int*(n_size*n_size))%n_size)\n",
    "        \n",
    "        if not out_data:\n",
    "            f1 = savepath+'/concept_full_{}_{}_sim_{}.png'.format(i,jc, round(sim_list[jc], 3))\n",
    "            f2 = savepath+'/concept_{}_{}_sim_{}.png'.format(i,jc, round(sim_list[jc], 3)) \n",
    "        else:\n",
    "            f1 = savepath+'/{}_concept_full_{}_{}_sim_{}.png'.format(out_data, i,jc, round(sim_list[jc], 3))\n",
    "            f2 = savepath+'/{}_concept_{}_{}_sim_{}.png'.format(out_data, i,jc, round(sim_list[jc], 3))\n",
    "            \n",
    "        # if sim_list[jc]>0.70:\n",
    "        x_test_filename = test_loader.filepaths[j_int]\n",
    "        helper.copy_save_image(x_test_filename,f1,f2,a,b)\n",
    "        \n",
    "\n",
    "def compute_concept_scores(topic_vec, feature, predict_model=None):\n",
    "    # topic_vec: concept vectors (dim= (feature_dim, n_concepts))\n",
    "    # feature: features extracted from an intermediate layer of trained model\n",
    "\n",
    "    feature_n = tf.math.l2_normalize(feature, axis=3)\n",
    "    topic_vec_n = tf.math.l2_normalize(topic_vec, axis=0)\n",
    "\n",
    "    topic_prob = tf.matmul(feature_n, topic_vec_n) # K.dot\n",
    "\n",
    "    prob_max = tf.math.reduce_max(topic_prob, axis=(1,2))\n",
    "    prob_max_abs = tf.math.reduce_max(tf.abs(topic_prob), axis=(1,2))\n",
    "    concept_scores = tf.where(prob_max == prob_max_abs, prob_max, -prob_max_abs)\n",
    "\n",
    "    \"\"\"\n",
    "    ##for debugging\n",
    "    n_concept = np.shape(concept_scores)[1]\n",
    "    print(tf.reduce_mean(input_tensor=tf.nn.top_k(K.transpose(K.reshape(topic_prob,(-1,n_concept))),k=10,sorted=True).values))\n",
    "    print(tf.reduce_mean(input_tensor=K.dot(K.transpose(K.variable(value=topic_vec_n)), K.variable(value=topic_vec_n)) - np.eye(n_concept)))\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if predict_model: # in eager execution\n",
    "        pred = softmax(predict_model(feature))\n",
    "        #pred = tf.math.argmax(pred, axis=1)\n",
    "        return concept_scores.numpy(), pred.numpy()\n",
    "    else:\n",
    "        return concept_scores\n",
    "\n",
    "def prepare_profiles(feature_model, topic_vec, num_classes, args, logger):\n",
    "    # profiling using validation data\n",
    "    #profile_path = \"{}/AwA2_train_concept_dict.pkl\".format(args.result_dir)\n",
    "    profile_path = \"{}/AwA2_val_concept_dict.pkl\".format(args.result_dir)\n",
    "    if not os.path.exists(profile_path):\n",
    "        logger.info(\"Profiling the distribution of concept scores from train set...\")\n",
    "\n",
    "        tf.random.set_seed(0)\n",
    "        datagen = ImageDataGenerator(rescale=1./255.)\n",
    "                                                #rotation_range=40,\n",
    "                                                #width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                                #shear_range=0.2, zoom_range=0.2,\n",
    "                                                #horizontal_flip=True)\n",
    "        data_loader = datagen.flow_from_directory(\"data/AwA2/val\", \\\n",
    "                                                batch_size=350, target_size=(224,224), \\\n",
    "                                                class_mode='categorical', \\\n",
    "                                                shuffle=False)\n",
    "\n",
    "        ConceptP = ConceptProfiles()\n",
    "        ConceptP.setUp(num_classes, data_loader)\n",
    "        ConceptP.prepare_concept_dict(feature_model, topic_vec)\n",
    "        concept_dict = ConceptP.concept_dict\n",
    "\n",
    "        #LOAD_DIR = 'data/Animals_with_Attributes2'\n",
    "        #y_train = np.load(LOAD_DIR+'/y_train.npy')\n",
    "        #y_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "        logger.info(\"Saving concept profiles of AwA2 train set in {}\".format(profile_path))\n",
    "        with open(profile_path,'wb') as f:\n",
    "            pickle.dump(concept_dict, f)\n",
    "\n",
    "    else:\n",
    "        logger.info(\"Loading concept profiles of AwA2 train set from {}\".format(profile_path))\n",
    "        with open(profile_path,'rb') as f:\n",
    "            concept_dict = pickle.load(f)\n",
    "\n",
    "    return concept_dict\n",
    "\n",
    "\n",
    "def compute_coherency(feature, topic_vec):\n",
    "    \"\"\"\n",
    "    compute coherency across top-k nearest neighbors for each concept\n",
    "    :param topic_vec: concept vectors, dim=(feature_dim, num_concept)\n",
    "    :param feature: features extracted from an intermediate layer of trained model\n",
    "    \"\"\"\n",
    "\n",
    "    # normalize\n",
    "    feature_n = tf.math.l2_normalize(feature, axis=3)\n",
    "    topic_vec_n = tf.math.l2_normalize(topic_vec, axis=0)\n",
    "    \n",
    "    topic_prob = tf.matmul(feature_n, topic_vec_n) # normalized concept scores, dim=(num_data, num_concept)\n",
    "    num_concept = topic_prob.shape[1]\n",
    "    coher = tf.reduce_mean(tf.nn.top_k(K.transpose(K.reshape(topic_prob,(-1,num_concept))),k=10,sorted=True).values)\n",
    "    return coher.numpy()\n",
    "\n",
    "def compute_redundancy(topic_vec):\n",
    "    \"\"\"\n",
    "    compute similarity between concept vectors\n",
    "    :param topic_vec: normalized concept vectors, dim=(dim_feat, num_concept)\n",
    "    \"\"\"\n",
    "    num_concept = topic_vec.shape[-1]\n",
    "\n",
    "    topic_vec_n = tf.math.l2_normalize(topic_vec, axis=0)\n",
    "    redun = tf.reduce_mean(K.dot(K.transpose(topic_vec_n), topic_vec_n) - np.eye(num_concept))\n",
    "    return redun.numpy()\n",
    "\n",
    "def compute_completeness(y, yhat, yhat_recov, num_class, logger=None, label=None):\n",
    "    \"\"\"\n",
    "    compute completeness score by Yeh et al.\n",
    "    :param y: groundtruth class labels, dim=(N,)\n",
    "    :param yhat: predicted class labels, dim=(N,)\n",
    "    :param yhat_recov: predicted class labels using recovered features, dim=(N,).\n",
    "                       If label is not None, per-class predicted labels, dim=(N',) where N' <= N\n",
    "    \"\"\"\n",
    "\n",
    "    acc = np.sum(y == yhat)/len(y)\n",
    "    if logger:\n",
    "        logger.info(f'[ID TEST] accuracy with original features: {acc}')\n",
    "    \n",
    "    if label is not None:\n",
    "        acc_recov = np.sum(y[y==label] == yhat_recov)/len(yhat_recov)\n",
    "        if logger:\n",
    "            logger.info(f'[ID TEST] per-class accuracy with recovered features: {acc_recov}')\n",
    "        acc_random = 1/num_class #0.5 #NOTE: check a_r = 0.5?\n",
    "    else:\n",
    "        acc_recov = np.sum(y == yhat_recov)/len(y)\n",
    "        if logger:\n",
    "            logger.info(f'[ID TEST] accuracy with recovered features: {acc_recov}')\n",
    "        acc_random = 1/num_class\n",
    "    \n",
    "    # compute completeness\n",
    "    completeness = (acc_recov - acc_random) / (acc - 1/num_class)\n",
    "    if logger:\n",
    "        logger.info(f'[ID TEST] completeness score: {completeness}')\n",
    "    return completeness\n",
    "\n",
    "def compute_detection_completeness(auroc, auroc_recov, logger=None):\n",
    "    \"\"\"\n",
    "    compute detection completeness score\n",
    "    \"\"\"\n",
    "    # compute completeness\n",
    "    auroc_random = 1/2\n",
    "    completeness = (auroc_recov - auroc_random) / (auroc - auroc_random)\n",
    "    if logger:\n",
    "        logger.info(f'[DETECTION] auroc with original features: {auroc}')\n",
    "        logger.info(f'[DETECTION] auroc with recovered features: {auroc_recov}')\n",
    "        logger.info(f'[DETECTION] completeness score: {completeness}')\n",
    "    return completeness\n",
    "\n",
    "\n",
    "def compute_conceptSHAP(concept_mask, topic_vec, \n",
    "                        feat_in, feat_out, y, yhat_in, yhat_out, auroc,\n",
    "                        in_loader, out_loader,\n",
    "                        topic_model, feature_model, args, logger, \n",
    "                        finetune=False, labels=None):\n",
    "\n",
    "    assert labels is not None\n",
    "\n",
    "    num_class = 50\n",
    "    num_concept = topic_vec.shape[1]\n",
    "\n",
    "    ## modify topic model\n",
    "    logger.info(f'[ConceptSHAP] using concept mask: {concept_mask}.....')\n",
    "    #topic_vec_temp = np.random.rand(topic_vec.shape[0], topic_vec.shape[1]) \n",
    "    topic_vec_temp = copy.copy(topic_vec)\n",
    "    topic_vec_temp[:,np.array(concept_mask)==0] = 0\n",
    "    #print(topic_model.layers[0].get_weights())\n",
    "    topic_model.layers[0].set_weights([topic_vec_temp])\n",
    "    #print(topic_model.layers[0].get_weights())\n",
    "\n",
    "    _, logits_in, _ = topic_model(feat_in)\n",
    "    _, logits_out, _ = topic_model(feat_out)\n",
    "\n",
    "\n",
    "    compl_class, compl_detect = np.array([]), np.array([])\n",
    "    compl_class_2, compl_detect_2 = np.array([]), np.array([])\n",
    "    for label in labels:\n",
    "        # compute classification completeness\n",
    "        _, logits, _ = topic_model(feat_in[np.where(y == label)[0]])\n",
    "        #print(logits)\n",
    "        yhat_in_recov = tf.math.argmax(logits, axis=1)\n",
    "        _compl_class = compute_completeness(y, yhat_in, yhat_in_recov, num_class, logger, label)\n",
    "        compl_class = np.append(compl_class, _compl_class) \n",
    "        \n",
    "        # compute detection completeness\n",
    "        idx_in = np.where(tf.math.argmax(logits_in, axis=1).numpy() == label)[0]\n",
    "        idx_out = np.where(tf.math.argmax(logits_out, axis=1).numpy() == label)[0]\n",
    "        logger.info(f'[ConceptSHAP CLASS {label}] number of ID: {len(idx_in)} | number of OOD: {len(idx_out)}')\n",
    "        if len(idx_in) == 0 or len(idx_out) == 0:\n",
    "            compl_detect = np.append(compl_detect, None)\n",
    "            continue\n",
    "\n",
    "        s_in = run_ood_over_batch(None, feature_model, topic_model, args, num_class, feat_in[idx_in])\n",
    "        s_out = run_ood_over_batch(None, feature_model, topic_model, args, num_class, feat_out[idx_out])\n",
    "        #s_in, s_out = np.random.rand(len(idx_in)), np.random.rand(len(idx_out))\n",
    "        auroc_recov, aupr_in, aupr_out, fpr95, thres95 = get_measures(s_in[:,None],s_out[:,None])\n",
    "        _compl_detect = compute_detection_completeness(auroc, auroc_recov, logger)\n",
    "        compl_detect = np.append(compl_detect, _compl_detect) \n",
    "        logger.info(f'[ConceptSHAP CLASS {label}] auroc: {auroc_recov} | aupr_in: {aupr_in} | aupr_out: {aupr_out} | fpr95: {fpr95} | thres95: {thres95}')\n",
    "        logger.info(f'[ConceptSHAP CLASS {label}] (before finetuning) classification completeness: {_compl_class} | detection completeness: {_compl_detect}')\n",
    "\n",
    "        if finetune:\n",
    "            target_size = (224, 224)\n",
    "            batch_size = args.batch_size\n",
    "            train_datagen = ImageDataGenerator(rescale=1. / 255.,\n",
    "                                           rotation_range=40,\n",
    "                                           width_shift_range=0.2,\n",
    "                                           height_shift_range=0.2,\n",
    "                                           shear_range=0.2,\n",
    "                                           zoom_range=0.2,\n",
    "                                           horizontal_flip=True)\n",
    "            train_loader = train_datagen.flow_from_directory('data/AwA2/train',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    target_size=target_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "            # datagen = ImageDataGenerator(rescale=1.0 / 255.)\n",
    "            # ood_loader = datagen.flow_from_directory(\"./data/MSCOCO\",\n",
    "            #                                     batch_size=batch_size,\n",
    "            #                                     target_size=target_size,\n",
    "            #                                     class_mode=None, shuffle=True)\n",
    "    \n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            optimizer_state = [optimizer.iterations, optimizer.learning_rate, optimizer.beta_1, optimizer.beta_2, optimizer.weight_decay]\n",
    "            optimizer_reset = tf.compat.v1.variables_initializer(optimizer_state)\n",
    "            softmax = layers.Activation('softmax')\n",
    "            #train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "            #test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "        \n",
    "            COEFF_CONCEPT = 10.0\n",
    "        \n",
    "            train_step_signature = [\n",
    "            tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, None), dtype=tf.float32),\n",
    "            #tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32), \n",
    "            ]\n",
    "            @tf.function(input_signature=train_step_signature)\n",
    "            def train_step(x_in, y_in): #, x_out=None):\n",
    "                f_in = feature_model(x_in)\n",
    "                f_in_n = K.l2_normalize(f_in,axis=(3))\n",
    "            \n",
    "                #f_out = feature_model(x_out)\n",
    "                #f_out_n = K.l2_normalize(f_out,axis=(3))\n",
    "\n",
    "                obj_terms = {} # terms in the objective function\n",
    "                with tf.GradientTape() as tape:\n",
    "                    f_in_recov, logits_in, topic_vec_n = topic_model(f_in, training=True)\n",
    "                    pred_in = softmax(logits_in) # class prediction using concept scores\n",
    "                    topic_prob_in_n = K.dot(f_in_n, topic_vec_n) # normalized concept scores\n",
    "\n",
    "                    #_, logits_out, _ = topic_model(f_out, training=True)\n",
    "                    #topic_prob_out_n = K.dot(f_out_n, topic_vec_n)\n",
    "\n",
    "                    # baseline\n",
    "                    CE_IN = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_in, pred_in))\n",
    "                    loss_coherency = tf.reduce_mean(tf.nn.top_k(K.transpose(K.reshape(topic_prob_in_n,(-1,num_concept))),k=10,sorted=True).values)\n",
    "                    loss_similarity = tf.reduce_mean(K.dot(K.transpose(topic_vec_n), topic_vec_n) - tf.eye(num_concept))\n",
    "                    loss = CE_IN - COEFF_CONCEPT*loss_coherency + COEFF_CONCEPT*loss_similarity\n",
    "                    obj_terms['[ID] CE'] = CE_IN\n",
    "                    obj_terms['[ID] concept coherency'] = loss_coherency\n",
    "                    obj_terms['[ID] concept similarity'] = loss_similarity\n",
    "\n",
    "                grads = tape.gradient(loss, topic_model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, topic_model.trainable_variables))\n",
    "                return obj_terms\n",
    "\n",
    "            for layer in topic_model.layers:\n",
    "                layer.trainable = True\n",
    "                \n",
    "            for step, (x_in, y_in) in enumerate(train_loader):\n",
    "                step += 1\n",
    "                if step == len(train_loader): # >100\n",
    "                    break\n",
    "                #x_out = ood_loader.__next__()\n",
    "                obj_terms = train_step(x_in, y_in) #, x_out)\n",
    "                if step % 20 == 0:\n",
    "                    for term in obj_terms:\n",
    "                        print(f'[STEP{step}] {term}: {obj_terms[term]}')\n",
    "\n",
    "            for layer in topic_model.layers:\n",
    "                layer.trainable = False\n",
    "            #train_acc = train_acc_metric.result()\n",
    "            #logger.info(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "            # compute classification completeness\n",
    "            _, logits, _ = topic_model(feat_in[np.where(y == label)[0]])\n",
    "            #print(logits)\n",
    "            yhat_in_recov = tf.math.argmax(logits, axis=1)\n",
    "            _compl_class = compute_completeness(y, yhat_in, yhat_in_recov, num_class, logger, label)\n",
    "            compl_class_2 = np.append(compl_class_2, _compl_class)\n",
    "\n",
    "            # compute detection completeness\n",
    "            idx_in = np.where(tf.math.argmax(logits_in, axis=1).numpy() == label)[0]\n",
    "            idx_out = np.where(tf.math.argmax(logits_out, axis=1).numpy() == label)[0]\n",
    "            s_in = run_ood_over_batch(None, feature_model, topic_model, args, num_class, feat_in[idx_in])\n",
    "            s_out = run_ood_over_batch(None, feature_model, topic_model, args, num_class, feat_out[idx_out])\n",
    "            auroc_recov, aupr_in, aupr_out, fpr95, thres95 = get_measures(s_in[:,None],s_out[:,None])\n",
    "            _compl_detect = compute_detection_completeness(auroc, auroc_recov, logger)\n",
    "            compl_detect_2 = np.append(compl_detect_2, _compl_detect)\n",
    "            logger.info(f'[ConceptSHAP CLASS {label}] auroc: {auroc_recov} | aupr_in: {aupr_in} | aupr_out: {aupr_out} | fpr95: {fpr95} | thres95: {thres95}')\n",
    "            logger.info(f'[ConceptSHAP CLASS {label}] (after finetuning) classification completeness: {_compl_class} | detection completeness: {_compl_detect}')\n",
    "\n",
    "        logger.info('--------------------------------------------------------')\n",
    "\n",
    "    topic_model.layers[0].set_weights([topic_vec])\n",
    "    if finetune:\n",
    "        return compl_class_2, compl_detect_2\n",
    "    else:\n",
    "        assert len(compl_class) == len(labels)\n",
    "        assert len(compl_detect) == len(labels)\n",
    "        return compl_class, compl_detect\n",
    "\n",
    "\n",
    "def compute_separability(in_concept, out_concept, in_yhat, out_yhat, num_classes, logger=None):\n",
    "    # compute Multivariate Separability (global)\n",
    "    separa = {'global': multivar_separa(in_concept, out_concept).numpy()}\n",
    "\n",
    "    # compute per-class separability\n",
    "    # num_classes = 50\n",
    "    num_concepts = in_concept.shape[1]\n",
    "    for i in range(num_classes):\n",
    "        idx_in = np.where(in_yhat == i)[0]\n",
    "        idx_out = np.where(out_yhat == i)[0]\n",
    "        if logger:\n",
    "            logger.info(f'class {i}: num IN - {len(idx_in)}, num OUT - {len(idx_out)}')\n",
    "\n",
    "        ## explanation using groundtruth ID/OOD labels\n",
    "        #sep_concept_ith = FLD(in_concept[idx_in,:], out_concept[idx_out,:], optimal=False)\n",
    "        sep_concept_ith = multivar_separa(in_concept[idx_in,:], out_concept[idx_out,:]).numpy()\n",
    "        if logger:\n",
    "            logger.info(f'[CLASS {i}: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: {sep_concept_ith}')\n",
    "\n",
    "        separa['class'+str(i)] = sep_concept_ith\n",
    "\n",
    "    return separa\n",
    "\n",
    "\n",
    "def explain_topK(scores, top_k, separa, figname=None):\n",
    "    \"\"\"\n",
    "    Plot bar graph of top-k largest average concept scores\n",
    "    :param scores: concept scores, dim=(N,num_concepts)\n",
    "    :param top_k: interested in printing top-k highest concept scores\n",
    "    :param separa: separability score averaged across concepts or per-class multivariate separability\n",
    "    \"\"\"\n",
    "    s_mean = np.mean(scores, axis=0)\n",
    "    concept_idx = np.argsort(np.abs(s_mean))[::-1][:top_k] \n",
    "    \n",
    "    num_types = 1 \n",
    "    num_concepts = top_k\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(num_concepts) * bar_width * (num_types + 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3*top_k/5,3))\n",
    "    bar = ax.bar(index + 0 * bar_width, s_mean[concept_idx],\n",
    "            bar_width, yerr=np.std(scores[:,concept_idx],axis=0))\n",
    "    ax.set_title('Top-{0} concept scores, separability: {1:.5f}'.format(top_k, separa))\n",
    "    ax.set_ylabel('Concept score')\n",
    "    ax.set_xticks(index + num_types * bar_width / 2)\n",
    "    ax.set_xticklabels(['concept {}'.format(c) for c in concept_idx], rotation=45)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(figname)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def explain_relative(scores, labels, separa, shap_class_i, figname, figname_dist, top_k=6):\n",
    "    \"\"\"\n",
    "    scores: dictionary of concept scores of groundtruth ID, groundtruth OOD, ID -> ID, ID -> OOD, OOD -> ID, OOD -> OOD\n",
    "    labels: labels for different types of scores\n",
    "    separa: separability scores, dim=(num_concepts,)\n",
    "    \"\"\"\n",
    "    # concepts with top-k separability scores\n",
    "    concept_idx = np.argsort(shap_class_i)[::-1][:top_k] # top K: from largest to smallest value\n",
    "    # concept_idx = np.arange(top_k)\n",
    "    num_types = len(labels)\n",
    "    num_concepts = top_k\n",
    "    bar_width = 0.35\n",
    "    # create location for each bar. scale by an appropriate factor to ensure \n",
    "    # the final plot doesn't have any parts overlapping\n",
    "    index = np.arange(num_concepts) * bar_width * (num_types + 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3*top_k/2,5))\n",
    "    for i in range(num_types):\n",
    "        bar = ax.bar(index + i * bar_width, np.mean(scores[labels[i]][:,concept_idx],axis=0),\n",
    "                bar_width, yerr=np.std(scores[labels[i]][:,concept_idx],axis=0), \n",
    "                label=f\"{labels[i]}, num={len(scores[labels[i]])}\")\n",
    "    ax.set_title('Concept scores for each concept and ID/OOD data, separability: {1:.5f}'.format(top_k, separa))\n",
    "    ax.set_ylabel('Concept score')\n",
    "    ax.set_xticks(index + num_types * bar_width / 2)\n",
    "    ax.set_xticklabels([f'concept {c}\\nshap={round(shap_class_i[c], 3)}' for c in concept_idx], rotation=45)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(figname)\n",
    "    plt.close()\n",
    "\n",
    "def save_images(filepaths, figname, k=5):\n",
    "\n",
    "    fig, axes = plt.subplots(1,k)\n",
    "    count = 0\n",
    "    np.random.shuffle(filepaths)\n",
    "    for f in filepaths:\n",
    "        img = Image.open(f).resize((100,100), Image.LANCZOS)\n",
    "        axes[count].imshow(img)\n",
    "        #ax2.set_title(\"ID image\", size=10, color='b')\n",
    "        axes[count].axis('off')\n",
    "    \n",
    "        count += 1\n",
    "        if count >= k:\n",
    "            break\n",
    "\n",
    "    fig.savefig(figname)\n",
    "    plt.close()\n",
    "\n",
    "def run_eval(feature_model, predict_model, in_loader, out_loader, logger, args, num_classes):\n",
    "    in_scores = np.array([])\n",
    "    for i, (x, y) in tqdm(enumerate(in_loader)):\n",
    "        if i == len(in_loader):\n",
    "            break\n",
    "        score = run_ood_over_batch(x, feature_model, predict_model, args, num_classes).numpy()\n",
    "        in_scores = np.concatenate([in_scores, score])\n",
    "    out_scores = np.array([])\n",
    "    for i, x in tqdm(enumerate(out_loader)):\n",
    "        if i == len(in_loader):\n",
    "            break\n",
    "        score = run_ood_over_batch(x, feature_model, predict_model, args, num_classes).numpy()\n",
    "        out_scores = np.concatenate([out_scores, score])\n",
    "    in_examples = np.expand_dims(in_scores, axis=1)\n",
    "    out_examples = np.expand_dims(out_scores, axis=1)\n",
    "    auroc, aupr_in, aupr_out, fpr, thres95 = get_measures(in_examples, out_examples)\n",
    "    return in_scores, out_scores, auroc, fpr, thres95\n",
    "\n",
    "def get_class_labels(loader, savepath):\n",
    "    \"\"\"\n",
    "    extract groundtruth class labels from data loader\n",
    "    :param loader: data loader\n",
    "    :param savepath: path to the numpy file\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(savepath):\n",
    "        y = np.load(savepath)\n",
    "    else:\n",
    "        num_data = len(loader.filenames)\n",
    "        y = []\n",
    "        for (_, y_batch), _ in zip(loader, range(len(loader))):\n",
    "            y.extend(y_batch)\n",
    "       \n",
    "        np.save(savepath, y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f81a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:18:10,369 [INFO] utils.log: <__main__.ARGS object at 0x7fc190553f90>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3772 images belonging to 50 classes.\n",
      "Found 10000 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:18:10,990 [INFO] utils.log: Using an in-distribution set.\n",
      "2024-08-01 17:18:10,992 [INFO] utils.log: Using an out-of-distribution set.\n",
      "2024-08-01 17:18:10,995 [INFO] utils.log: Loading model from results/AwA2/inceptionv3_AwA2_e20.weights.h5\n",
      "2024-08-01 17:18:11.115883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30835 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "original model to be trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,850</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_2 (\u001b[38;5;33mInputLayer\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m12,850\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">537,394</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m537,394\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">537,394</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m537,394\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722525511.034128 3331225 service.cc:146] XLA service 0x7fc060067a10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722525511.034192 3331225 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-08-01 17:18:31.179879: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-01 17:18:32.004187: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/15\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 125ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722525521.152585 3331225 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 6s/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "\n",
    "# with tf.device('/CPU:0'):\n",
    "\n",
    "logger = log.setup_logger(args, filename=\"eval_{}.log\".format(args.score))\n",
    "LOAD_DIR = 'data/AwA2'\n",
    "TOPIC_PATH = os.path.join(args.result_dir,'topic_vec_inceptionv3.npy')\n",
    "INPUT_SHAPE = (args.out_data_dim, args.out_data_dim)\n",
    "TRAIN_DIR = \"data/AwA2/train\"\n",
    "N_CLASSES = 50\n",
    "N_CONCEPTS_ORIG = 100 #np.shape(topic_vec_orig)[-1]\n",
    "_ = 0\n",
    "\n",
    "if args.score == 'ODIN':\n",
    "    args.batch_size = 200\n",
    "\n",
    "if not os.path.exists(os.path.join(args.result_dir, 'plots')):\n",
    "    os.makedirs(os.path.join(args.result_dir, 'plots'))\n",
    "if not os.path.exists(os.path.join(args.result_dir, 'explanations')):\n",
    "    os.makedirs(os.path.join(args.result_dir, 'explanations'))\n",
    "if not os.path.exists(os.path.join(args.result_dir, 'explanations', args.out_data+'_'+args.score)):\n",
    "    os.makedirs(os.path.join(args.result_dir, 'explanations', args.out_data+'_'+args.score))\n",
    "explain_dir = os.path.join(args.result_dir, 'explanations', args.out_data+'_'+args.score)\n",
    "\n",
    "in_loader, out_loader = prepare_data(args, logger)\n",
    "\n",
    "## load trained_model\n",
    "logger.info(f\"Loading model from {args.model_path}\")\n",
    "feature_model, predict_model = helper.load_model_inception_new(_, in_loader, batch_size=args.batch_size, \n",
    "                                    input_size=INPUT_SHAPE, pretrain=True, modelname=args.model_path)\n",
    "\n",
    "in_test_features = feature_model.predict(in_loader)\n",
    "out_test_features = feature_model.predict(out_loader, steps=len(in_loader))\n",
    "N_IN = in_test_features.shape[0]\n",
    "N_OUT = out_test_features.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df63228-80ec-4518-9c59-a75a95175e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/AwA2_1_feat_l2_0.1_ood_1_sep_50_s0/epoch_40_0.95'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add30f49-65c0-4576-a101-9869005355fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load topic model\n",
    "topic_model = concept_model.TopicModel(in_test_features, N_CONCEPTS_ORIG, thres=0.0, predict=predict_model)\n",
    "for layer in topic_model.layers:\n",
    "    layer.trainable = False\n",
    "topic_model(in_test_features)\n",
    "topic_model.load_weights(os.path.dirname(args.result_dir)+f\"/topic_epoch{os.path.dirname(args.logdir).split('_')[-2]}.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58911223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:21:12,857 [INFO] utils.log: Number of concepts before removing duplicate ones: 100\n",
      "2024-08-01 17:21:12,962 [INFO] utils.log: Number of concepts after removing duplicate ones: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept mapping between before/after duplicate removal......\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41, 42: 42, 43: 43, 44: 44, 45: 45, 46: 46, 47: 47, 48: 48, 49: 49, 50: 50, 51: 51, 52: 52, 53: 53, 54: 54, 55: 55, 56: 56, 57: 57, 58: 58, 59: 59, 60: 60, 61: 61, 62: 62, 63: 63, 64: 64, 65: 65, 66: 66, 67: 67, 68: 68, 69: 69, 70: 70, 71: 71, 72: 72, 73: 73, 74: 74, 75: 75, 76: 76, 77: 77, 78: 78, 79: 79, 80: 80, 81: 81, 82: 82, 83: 83, 84: 84, 85: 85, 86: 86, 87: 87, 88: 88, 89: 89, 90: 90, 91: 91, 92: 92, 93: 93, 94: 94, 95: 95, 96: 96, 97: 97, 98: 98, 99: 99}\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/CPU:0'):\n",
    "\n",
    "## load topic_vec\n",
    "topic_vec_orig = topic_model.layers[0].get_weights()[0]\n",
    "np.save(args.result_dir+'/topic_vec_orig.npy', topic_vec_orig)\n",
    "logger.info(f'Number of concepts before removing duplicate ones: {str(N_CONCEPTS_ORIG)}')\n",
    "\n",
    "topic_vec, dict_dupl_topic = remove_duplicate_concepts(topic_vec_orig, thr=args.concept_sim_thr)\n",
    "N_CONCEPTS = np.shape(topic_vec)[-1] # 25\n",
    "logger.info(f'Number of concepts after removing duplicate ones: {str(N_CONCEPTS)}')\n",
    "\n",
    "in_test_concepts, in_test_logits = compute_concept_scores(topic_vec, in_test_features, predict_model)\n",
    "out_test_concepts, out_test_logits = compute_concept_scores(topic_vec, out_test_features, predict_model)\n",
    "in_test_yhat = np.argmax(in_test_logits, axis=1) \n",
    "out_test_yhat = np.argmax(out_test_logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43d63dc-25b6-4fc1-845e-3add7b4b7b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:21:21,436 [INFO] utils.log: [ID TEST: CONCEPT 0] top-15 scores: [0.45152792 0.45862487 0.46110255 0.49014467 0.51228577 0.5523987\n",
      " 0.46972466 0.47861457 0.5301192  0.4796937  0.46721125 0.4797986\n",
      " 0.504055   0.48481265 0.48405084]\n",
      "2024-08-01 17:21:26,165 [INFO] utils.log: [ID TEST: CONCEPT 1] top-15 scores: [0.6304304  0.6331361  0.6341492  0.6353236  0.6371572  0.63552415\n",
      " 0.63614357 0.6376035  0.6521664  0.64973444 0.6451061  0.6446297\n",
      " 0.6485232  0.64401424 0.6449207 ]\n",
      "2024-08-01 17:21:30,597 [INFO] utils.log: [ID TEST: CONCEPT 2] top-15 scores: [0.65197545 0.6887013  0.7079197  0.66306525 0.6690536  0.68143666\n",
      " 0.669877   0.6678786  0.67387056 0.66507936 0.6640856  0.6521214\n",
      " 0.6549403  0.6639621  0.6630484 ]\n",
      "2024-08-01 17:21:35,364 [INFO] utils.log: [ID TEST: CONCEPT 3] top-15 scores: [0.34795347 0.35415214 0.35709196 0.35532004 0.35355115 0.36192697\n",
      " 0.45660254 0.36787367 0.4083135  0.3979601  0.3634828  0.45006996\n",
      " 0.36654097 0.395466   0.37411305]\n",
      "2024-08-01 17:21:39,256 [INFO] utils.log: [ID TEST: CONCEPT 4] top-15 scores: [0.4769069  0.47911084 0.48063272 0.48015413 0.48476356 0.48736602\n",
      " 0.4971376  0.485003   0.49163485 0.49585772 0.49639347 0.48645288\n",
      " 0.50227326 0.49316517 0.50393176]\n",
      "2024-08-01 17:21:44,130 [INFO] utils.log: [ID TEST: CONCEPT 5] top-15 scores: [0.60791236 0.60837007 0.60881174 0.61048675 0.6101452  0.61325806\n",
      " 0.63318074 0.62303984 0.62208736 0.61426187 0.6312756  0.6581076\n",
      " 0.61934817 0.6364999  0.6165093 ]\n",
      "2024-08-01 17:21:47,881 [INFO] utils.log: [ID TEST: CONCEPT 6] top-15 scores: [0.79651    0.79680985 0.79741246 0.7986289  0.7999011  0.7990439\n",
      " 0.7999035  0.8035172  0.8039557  0.8058176  0.80913603 0.8097078\n",
      " 0.80399835 0.80696815 0.81075543]\n",
      "2024-08-01 17:21:52,917 [INFO] utils.log: [ID TEST: CONCEPT 7] top-15 scores: [0.79685366 0.7992306  0.7998955  0.8008912  0.8013259  0.8023235\n",
      " 0.80630004 0.8041308  0.8025633  0.80633533 0.80641514 0.8067518\n",
      " 0.8077902  0.81515324 0.81356376]\n",
      "2024-08-01 17:21:57,353 [INFO] utils.log: [ID TEST: CONCEPT 8] top-15 scores: [0.56356543 0.56377596 0.5659294  0.5661597  0.5664401  0.56626123\n",
      " 0.5683626  0.5755322  0.57128865 0.56893945 0.58527654 0.5835388\n",
      " 0.5865432  0.5689729  0.5702004 ]\n",
      "2024-08-01 17:22:02,066 [INFO] utils.log: [ID TEST: CONCEPT 9] top-15 scores: [0.5056531  0.508454   0.50940067 0.5164411  0.544533   0.5463265\n",
      " 0.5217689  0.5527679  0.52280366 0.5602721  0.5474429  0.65385246\n",
      " 0.58484745 0.60621667 0.5328034 ]\n",
      "2024-08-01 17:22:07,529 [INFO] utils.log: [ID TEST: CONCEPT 10] top-15 scores: [0.71248615 0.7147841  0.71649873 0.71891326 0.72176707 0.7250838\n",
      " 0.7210403  0.71901643 0.7249927  0.7297804  0.73098475 0.74194324\n",
      " 0.737343   0.738856   0.7338809 ]\n",
      "2024-08-01 17:22:14,845 [INFO] utils.log: [ID TEST: CONCEPT 11] top-15 scores: [0.7237613  0.7262219  0.73101413 0.7359362  0.72933733 0.72961473\n",
      " 0.7362673  0.74365425 0.7397797  0.74453485 0.7603663  0.751622\n",
      " 0.7592982  0.7658195  0.75910246]\n",
      "2024-08-01 17:22:19,802 [INFO] utils.log: [ID TEST: CONCEPT 12] top-15 scores: [0.64739585 0.64838743 0.6485729  0.65596884 0.6502907  0.6557988\n",
      " 0.65691984 0.66482675 0.6652758  0.6638001  0.64966226 0.65086395\n",
      " 0.6662384  0.6812309  0.67280424]\n",
      "2024-08-01 17:22:25,520 [INFO] utils.log: [ID TEST: CONCEPT 13] top-15 scores: [0.2933112  0.29793447 0.30314904 0.31189013 0.42194843 0.31327587\n",
      " 0.33083802 0.38436007 0.3639183  0.30582348 0.3050158  0.33712393\n",
      " 0.396608   0.30533892 0.3499766 ]\n",
      "2024-08-01 17:22:29,506 [INFO] utils.log: [ID TEST: CONCEPT 14] top-15 scores: [0.65290266 0.6530845  0.65318525 0.6716287  0.65752196 0.67508435\n",
      " 0.67619157 0.6589649  0.6581353  0.67193913 0.6875802  0.68371356\n",
      " 0.6624299  0.6660352  0.6590158 ]\n",
      "2024-08-01 17:22:34,800 [INFO] utils.log: [ID TEST: CONCEPT 15] top-15 scores: [0.7529322  0.7590327  0.7644396  0.76246095 0.77817446 0.77916306\n",
      " 0.7866165  0.766345   0.7608992  0.7708691  0.7697241  0.7910475\n",
      " 0.768546   0.75926316 0.77598596]\n",
      "2024-08-01 17:22:39,415 [INFO] utils.log: [ID TEST: CONCEPT 16] top-15 scores: [0.7301106  0.73150206 0.7317816  0.73197514 0.73392284 0.73414814\n",
      " 0.7390921  0.73573697 0.738237   0.74069595 0.7475543  0.74368846\n",
      " 0.7610606  0.7523334  0.74617803]\n",
      "2024-08-01 17:22:43,388 [INFO] utils.log: [ID TEST: CONCEPT 17] top-15 scores: [0.76761925 0.76782966 0.7689321  0.78506523 0.77266675 0.76869833\n",
      " 0.7750102  0.76918966 0.76983577 0.7791301  0.7687179  0.7788738\n",
      " 0.7702215  0.7710966  0.7696833 ]\n",
      "2024-08-01 17:22:50,275 [INFO] utils.log: [ID TEST: CONCEPT 18] top-15 scores: [0.6980213  0.6985992  0.69906884 0.70391345 0.70694983 0.7012327\n",
      " 0.70845926 0.71174675 0.718652   0.7190146  0.7139258  0.7108015\n",
      " 0.7197784  0.71768534 0.71329707]\n",
      "2024-08-01 17:22:56,778 [INFO] utils.log: [ID TEST: CONCEPT 19] top-15 scores: [0.7589422  0.7602856  0.7644216  0.7619027  0.76537573 0.77338517\n",
      " 0.7708627  0.77290773 0.7791593  0.7852804  0.7663426  0.76610535\n",
      " 0.7848691  0.7744558  0.76795334]\n",
      "2024-08-01 17:23:01,437 [INFO] utils.log: [ID TEST: CONCEPT 20] top-15 scores: [0.78461456 0.7847097  0.7899065  0.7860606  0.7869526  0.7856266\n",
      " 0.7904444  0.7884781  0.7862479  0.7935854  0.79528344 0.8043068\n",
      " 0.8018123  0.79980046 0.80086935]\n",
      "2024-08-01 17:23:08,355 [INFO] utils.log: [ID TEST: CONCEPT 21] top-15 scores: [0.72146326 0.73887074 0.72428226 0.74232    0.73961985 0.7337177\n",
      " 0.72514236 0.7501773  0.7255473  0.74032426 0.7286097  0.72517556\n",
      " 0.7217418  0.72257173 0.7295284 ]\n",
      "2024-08-01 17:23:15,544 [INFO] utils.log: [ID TEST: CONCEPT 22] top-15 scores: [0.74342954 0.7472271  0.7521764  0.77542025 0.75086474 0.75596464\n",
      " 0.7517247  0.7449615  0.74593866 0.74531007 0.7660059  0.7490457\n",
      " 0.7588432  0.75251114 0.76628315]\n",
      "2024-08-01 17:23:20,391 [INFO] utils.log: [ID TEST: CONCEPT 23] top-15 scores: [0.77857065 0.7792721  0.7885708  0.78044796 0.7818645  0.7798754\n",
      " 0.78357947 0.7826071  0.7885356  0.78314734 0.7840308  0.78684056\n",
      " 0.78140473 0.78261685 0.78638744]\n",
      "2024-08-01 17:23:25,188 [INFO] utils.log: [ID TEST: CONCEPT 24] top-15 scores: [0.6706647  0.6723368  0.6728395  0.6733331  0.6737786  0.6738602\n",
      " 0.6887493  0.6940159  0.6743304  0.6778657  0.6763965  0.67733645\n",
      " 0.70939434 0.693811   0.6806297 ]\n",
      "2024-08-01 17:23:30,335 [INFO] utils.log: [ID TEST: CONCEPT 25] top-15 scores: [0.7471571  0.74799013 0.74883175 0.7503475  0.7527996  0.7587602\n",
      " 0.75733685 0.77054954 0.7721477  0.7593576  0.77464694 0.76183265\n",
      " 0.7600393  0.75347763 0.7530035 ]\n",
      "2024-08-01 17:23:34,857 [INFO] utils.log: [ID TEST: CONCEPT 26] top-15 scores: [0.39812624 0.3984369  0.39950806 0.40025443 0.40171564 0.40343106\n",
      " 0.40520793 0.45144582 0.40532318 0.41032338 0.41020477 0.4052906\n",
      " 0.43563762 0.40545022 0.4074186 ]\n",
      "2024-08-01 17:23:39,120 [INFO] utils.log: [ID TEST: CONCEPT 27] top-15 scores: [0.4344169  0.43918726 0.43705082 0.4398172  0.44887158 0.4549795\n",
      " 0.45513985 0.44612265 0.45773464 0.4654709  0.51368785 0.52781874\n",
      " 0.4958939  0.519225   0.47647333]\n",
      "2024-08-01 17:23:43,267 [INFO] utils.log: [ID TEST: CONCEPT 28] top-15 scores: [0.73336774 0.7335271  0.73419595 0.7455679  0.75767756 0.7471025\n",
      " 0.74301726 0.74115    0.74248445 0.7511912  0.7538297  0.75331247\n",
      " 0.73734653 0.7398841  0.7408111 ]\n",
      "2024-08-01 17:23:48,523 [INFO] utils.log: [ID TEST: CONCEPT 29] top-15 scores: [0.73905766 0.73983717 0.7398592  0.74859816 0.7588124  0.740191\n",
      " 0.74380875 0.7657114  0.7574947  0.75080734 0.7408215  0.7455763\n",
      " 0.7455827  0.74534947 0.7444943 ]\n",
      "2024-08-01 17:23:53,040 [INFO] utils.log: [ID TEST: CONCEPT 30] top-15 scores: [0.31910893 0.3207094  0.32111758 0.33129686 0.37771016 0.35434002\n",
      " 0.36698702 0.3823889  0.4240703  0.33790427 0.34352797 0.32156542\n",
      " 0.3587714  0.33003473 0.39823264]\n",
      "2024-08-01 17:23:58,078 [INFO] utils.log: [ID TEST: CONCEPT 31] top-15 scores: [0.690097   0.69118845 0.6916167  0.6978674  0.6979648  0.70189977\n",
      " 0.703125   0.7184987  0.70096195 0.7031036  0.71335846 0.70329976\n",
      " 0.70112747 0.7220268  0.6982991 ]\n",
      "2024-08-01 17:24:02,432 [INFO] utils.log: [ID TEST: CONCEPT 32] top-15 scores: [0.2942714  0.3011693  0.30156654 0.30815095 0.3091001  0.3362893\n",
      " 0.37720504 0.32631505 0.38335735 0.31911072 0.3896672  0.32860848\n",
      " 0.3404541  0.35574353 0.32110423]\n",
      "2024-08-01 17:24:06,656 [INFO] utils.log: [ID TEST: CONCEPT 33] top-15 scores: [0.6808167  0.68110627 0.68717253 0.68922895 0.68350387 0.6902851\n",
      " 0.69369954 0.7004913  0.70372784 0.7154491  0.6910888  0.69257176\n",
      " 0.70609367 0.7012334  0.6942367 ]\n",
      "2024-08-01 17:24:12,440 [INFO] utils.log: [ID TEST: CONCEPT 34] top-15 scores: [0.6866165  0.6867615  0.6868686  0.68765676 0.70085275 0.6995417\n",
      " 0.7058306  0.68979824 0.6908901  0.6919867  0.6972085  0.6904129\n",
      " 0.6951109  0.7027014  0.68922544]\n",
      "2024-08-01 17:24:16,325 [INFO] utils.log: [ID TEST: CONCEPT 35] top-15 scores: [0.7127966  0.7153918  0.73290396 0.7238864  0.72211444 0.7208078\n",
      " 0.72121537 0.71735644 0.74084795 0.7187809  0.7210411  0.730502\n",
      " 0.7321126  0.7239248  0.71696806]\n",
      "2024-08-01 17:24:21,985 [INFO] utils.log: [ID TEST: CONCEPT 36] top-15 scores: [0.65276957 0.6527847  0.65694976 0.6558411  0.6601293  0.66526896\n",
      " 0.66313314 0.665059   0.6678855  0.6730082  0.6897627  0.6694697\n",
      " 0.6694446  0.6726593  0.6816033 ]\n",
      "2024-08-01 17:24:28,172 [INFO] utils.log: [ID TEST: CONCEPT 37] top-15 scores: [0.81367445 0.81559896 0.8160758  0.8170669  0.8179014  0.81737554\n",
      " 0.81711257 0.8182677  0.82027817 0.8157512  0.8216362  0.8250135\n",
      " 0.8228486  0.82339907 0.82577306]\n",
      "2024-08-01 17:24:33,955 [INFO] utils.log: [ID TEST: CONCEPT 38] top-15 scores: [0.7438607  0.74391544 0.76198775 0.7555329  0.74599457 0.7530861\n",
      " 0.75626963 0.74454486 0.7544464  0.75411105 0.75971323 0.75629884\n",
      " 0.7514123  0.7529452  0.7535043 ]\n",
      "2024-08-01 17:24:37,711 [INFO] utils.log: [ID TEST: CONCEPT 39] top-15 scores: [0.7645019  0.7668101  0.77039635 0.7647245  0.77053416 0.772824\n",
      " 0.7817454  0.7826376  0.77474654 0.77369845 0.77075976 0.77300483\n",
      " 0.78058326 0.7710608  0.78595006]\n",
      "2024-08-01 17:24:42,728 [INFO] utils.log: [ID TEST: CONCEPT 40] top-15 scores: [0.6880784  0.6926221  0.6915448  0.696235   0.6979251  0.7096666\n",
      " 0.7036282  0.7109879  0.7167717  0.71786773 0.70210207 0.70879966\n",
      " 0.7147522  0.71922934 0.69872296]\n",
      "2024-08-01 17:24:48,065 [INFO] utils.log: [ID TEST: CONCEPT 41] top-15 scores: [0.4643743  0.4679463  0.4761034  0.5112861  0.4889499  0.47712237\n",
      " 0.5131576  0.49501783 0.47874677 0.60179603 0.49527407 0.5118312\n",
      " 0.48711017 0.5257523  0.5380365 ]\n",
      "2024-08-01 17:24:52,028 [INFO] utils.log: [ID TEST: CONCEPT 42] top-15 scores: [0.7548717  0.75562245 0.75686795 0.7570168  0.75798887 0.75903136\n",
      " 0.75874406 0.76056814 0.7620952  0.75875604 0.7626128  0.76004636\n",
      " 0.7616689  0.7635113  0.7687845 ]\n",
      "2024-08-01 17:24:57,331 [INFO] utils.log: [ID TEST: CONCEPT 43] top-15 scores: [0.77273905 0.7749574  0.7751799  0.7776065  0.7917315  0.78692925\n",
      " 0.7805082  0.78548837 0.7775971  0.7843566  0.7969142  0.7786268\n",
      " 0.78031373 0.7759123  0.7870928 ]\n",
      "2024-08-01 17:25:01,820 [INFO] utils.log: [ID TEST: CONCEPT 44] top-15 scores: [0.8012663  0.80323887 0.80370665 0.8049303  0.8053997  0.80546665\n",
      " 0.8061325  0.8066877  0.8109302  0.8113189  0.8178511  0.8130433\n",
      " 0.81187445 0.8168982  0.8184663 ]\n",
      "2024-08-01 17:25:06,556 [INFO] utils.log: [ID TEST: CONCEPT 45] top-15 scores: [0.6413521  0.6433065  0.6610937  0.64863074 0.6688416  0.6532465\n",
      " 0.67096084 0.67223394 0.66351247 0.6662392  0.6635599  0.6755866\n",
      " 0.6596931  0.6550398  0.64727163]\n",
      "2024-08-01 17:25:11,691 [INFO] utils.log: [ID TEST: CONCEPT 46] top-15 scores: [0.7891576  0.7914387  0.79313064 0.79375494 0.79565537 0.7975681\n",
      " 0.8009758  0.80293906 0.81078136 0.80108047 0.79821205 0.8065469\n",
      " 0.79622793 0.7959502  0.80034924]\n",
      "2024-08-01 17:25:16,649 [INFO] utils.log: [ID TEST: CONCEPT 47] top-15 scores: [0.69511545 0.6970688  0.69805944 0.6992718  0.7000186  0.7036977\n",
      " 0.7060907  0.7062455  0.72721326 0.7248019  0.7137078  0.7068814\n",
      " 0.70815927 0.7064849  0.7277075 ]\n",
      "2024-08-01 17:25:22,436 [INFO] utils.log: [ID TEST: CONCEPT 48] top-15 scores: [0.79371977 0.7937621  0.7959889  0.7969337  0.7971076  0.79743344\n",
      " 0.80076146 0.79857165 0.8025683  0.81053793 0.8099889  0.8046657\n",
      " 0.807608   0.8060936  0.8069755 ]\n",
      "2024-08-01 17:25:29,421 [INFO] utils.log: [ID TEST: CONCEPT 49] top-15 scores: [0.7585578  0.7585812  0.7589423  0.7662945  0.7651385  0.76854277\n",
      " 0.7639482  0.7680104  0.76771694 0.76504445 0.7707669  0.7731253\n",
      " 0.77663076 0.77392375 0.7708474 ]\n",
      "2024-08-01 17:25:34,093 [INFO] utils.log: [ID TEST: CONCEPT 50] top-15 scores: [0.71189255 0.71219176 0.712468   0.7125264  0.7140856  0.7128469\n",
      " 0.7125109  0.7230227  0.7209544  0.72063684 0.71328485 0.7125097\n",
      " 0.71494347 0.72585607 0.72824657]\n",
      "2024-08-01 17:25:38,894 [INFO] utils.log: [ID TEST: CONCEPT 51] top-15 scores: [0.6005379  0.60262984 0.6028125  0.6037595  0.6104617  0.60699195\n",
      " 0.61219877 0.6133412  0.6155015  0.62417173 0.62616134 0.6239294\n",
      " 0.63142675 0.63558525 0.644851  ]\n",
      "2024-08-01 17:25:43,564 [INFO] utils.log: [ID TEST: CONCEPT 52] top-15 scores: [0.7817683  0.7820896  0.783334   0.78911144 0.7894837  0.78676283\n",
      " 0.7873105  0.79548573 0.79805183 0.7886091  0.785009   0.7842845\n",
      " 0.7857157  0.78973407 0.7945444 ]\n",
      "2024-08-01 17:25:48,686 [INFO] utils.log: [ID TEST: CONCEPT 53] top-15 scores: [0.67974734 0.6798173  0.6864281  0.6826762  0.6855045  0.67974967\n",
      " 0.6873066  0.69394857 0.69174695 0.6959199  0.7015908  0.6881376\n",
      " 0.68945193 0.70035285 0.7042123 ]\n",
      "2024-08-01 17:25:54,255 [INFO] utils.log: [ID TEST: CONCEPT 54] top-15 scores: [0.70129794 0.7027079  0.7028828  0.70394635 0.7095224  0.7109767\n",
      " 0.7115173  0.7150085  0.7251779  0.73343134 0.7186158  0.71920073\n",
      " 0.71897024 0.7283336  0.7369709 ]\n",
      "2024-08-01 17:26:01,350 [INFO] utils.log: [ID TEST: CONCEPT 55] top-15 scores: [0.7361933  0.7369076  0.7381243  0.7397681  0.7440237  0.74629223\n",
      " 0.78052735 0.75650465 0.74902326 0.75686705 0.7483777  0.7583633\n",
      " 0.7556329  0.7506332  0.7959107 ]\n",
      "2024-08-01 17:26:06,302 [INFO] utils.log: [ID TEST: CONCEPT 56] top-15 scores: [0.25898638 0.26233432 0.2723802  0.27043873 0.26680654 0.2725467\n",
      " 0.27938816 0.2739756  0.28045678 0.28204417 0.28637812 0.32908797\n",
      " 0.3817376  0.2941656  0.34066206]\n",
      "2024-08-01 17:26:11,826 [INFO] utils.log: [ID TEST: CONCEPT 57] top-15 scores: [0.60820043 0.6151537  0.6121291  0.6152853  0.61683196 0.61855894\n",
      " 0.6193852  0.6211189  0.6227272  0.63662124 0.63891613 0.622866\n",
      " 0.6377902  0.6354841  0.632548  ]\n",
      "2024-08-01 17:26:16,827 [INFO] utils.log: [ID TEST: CONCEPT 58] top-15 scores: [0.665027   0.6656183  0.6668445  0.66759026 0.66994387 0.6703808\n",
      " 0.6838306  0.67565256 0.7029878  0.67598146 0.6769805  0.6760924\n",
      " 0.6736526  0.6719445  0.67392486]\n",
      "2024-08-01 17:26:21,735 [INFO] utils.log: [ID TEST: CONCEPT 59] top-15 scores: [0.6371037  0.6530076  0.63907075 0.66006655 0.6417555  0.6474682\n",
      " 0.6513573  0.64027345 0.659721   0.64089847 0.6441201  0.6439858\n",
      " 0.6677588  0.6373688  0.63828135]\n",
      "2024-08-01 17:26:27,471 [INFO] utils.log: [ID TEST: CONCEPT 60] top-15 scores: [0.70690536 0.7075236  0.70758146 0.7124928  0.7089659  0.70847017\n",
      " 0.70770127 0.71333194 0.72104275 0.7160047  0.72582614 0.7198595\n",
      " 0.7282194  0.7451732  0.72633684]\n",
      "2024-08-01 17:26:32,499 [INFO] utils.log: [ID TEST: CONCEPT 61] top-15 scores: [0.7901088  0.7906035  0.79215795 0.7937921  0.7945367  0.79459405\n",
      " 0.7989233  0.79929984 0.7989595  0.798682   0.8005727  0.80015445\n",
      " 0.7961645  0.8028444  0.80372524]\n",
      "2024-08-01 17:26:38,120 [INFO] utils.log: [ID TEST: CONCEPT 62] top-15 scores: [0.626747   0.62765425 0.6296341  0.62880766 0.63026065 0.6395768\n",
      " 0.63419294 0.64957595 0.6429831  0.63659394 0.6452512  0.6541234\n",
      " 0.6544086  0.64764977 0.6453751 ]\n",
      "2024-08-01 17:26:42,675 [INFO] utils.log: [ID TEST: CONCEPT 63] top-15 scores: [0.779295   0.7797431  0.77990127 0.80157137 0.8020271  0.782898\n",
      " 0.78860366 0.81370926 0.8082751  0.78098094 0.7947537  0.7968149\n",
      " 0.78130627 0.7888213  0.79133445]\n",
      "2024-08-01 17:26:48,359 [INFO] utils.log: [ID TEST: CONCEPT 64] top-15 scores: [0.28531554 0.28957197 0.28614432 0.30812198 0.3141024  0.33115658\n",
      " 0.32103193 0.34962016 0.32088584 0.33146966 0.3769787  0.39675802\n",
      " 0.34504977 0.322847   0.35120207]\n",
      "2024-08-01 17:26:55,694 [INFO] utils.log: [ID TEST: CONCEPT 65] top-15 scores: [0.11812998 0.12016556 0.12175301 0.12323211 0.12238975 0.12175213\n",
      " 0.1261535  0.1289776  0.12205946 0.12283516 0.12933645 0.12471703\n",
      " 0.12631077 0.12216216 0.12433545]\n",
      "2024-08-01 17:27:01,625 [INFO] utils.log: [ID TEST: CONCEPT 66] top-15 scores: [0.48518175 0.48790076 0.48835525 0.49253958 0.49864814 0.49060285\n",
      " 0.50538015 0.49776778 0.5141468  0.5448159  0.52805007 0.5637535\n",
      " 0.52280784 0.539185   0.55428404]\n",
      "2024-08-01 17:27:06,916 [INFO] utils.log: [ID TEST: CONCEPT 67] top-15 scores: [0.7911407  0.7913085  0.791744   0.7920401  0.7923261  0.79622555\n",
      " 0.7973348  0.796043   0.79231346 0.79810476 0.8022934  0.8068586\n",
      " 0.8064008  0.80351305 0.8004886 ]\n",
      "2024-08-01 17:27:11,683 [INFO] utils.log: [ID TEST: CONCEPT 68] top-15 scores: [0.6278614  0.62956893 0.63018763 0.63142276 0.63033044 0.6322\n",
      " 0.6373176  0.6329248  0.6368507  0.635864   0.6324088  0.6336457\n",
      " 0.6389079  0.6419622  0.64254844]\n",
      "2024-08-01 17:27:17,026 [INFO] utils.log: [ID TEST: CONCEPT 69] top-15 scores: [0.65805495 0.65885407 0.6594109  0.659595   0.66113436 0.69077575\n",
      " 0.70009565 0.67084295 0.6837895  0.6617249  0.66174227 0.6694546\n",
      " 0.6683699  0.6634562  0.6780961 ]\n",
      "2024-08-01 17:27:20,470 [INFO] utils.log: [ID TEST: CONCEPT 70] top-15 scores: [0.7419723  0.743101   0.74316067 0.7469665  0.7443207  0.74226224\n",
      " 0.7476239  0.7531775  0.7500818  0.758024   0.75735545 0.75046104\n",
      " 0.75351167 0.7579063  0.7534342 ]\n",
      "2024-08-01 17:27:25,886 [INFO] utils.log: [ID TEST: CONCEPT 71] top-15 scores: [0.58036387 0.58122045 0.6130123  0.5962002  0.5873594  0.5821434\n",
      " 0.6065036  0.59411895 0.6245648  0.5854575  0.60659415 0.59654284\n",
      " 0.58147645 0.6116743  0.59893334]\n",
      "2024-08-01 17:27:30,907 [INFO] utils.log: [ID TEST: CONCEPT 72] top-15 scores: [0.26309118 0.2685628  0.26879147 0.2800529  0.27250987 0.36230713\n",
      " 0.2914087  0.2781611  0.3597433  0.27533528 0.28510636 0.28865975\n",
      " 0.32158148 0.3406882  0.32208467]\n",
      "2024-08-01 17:27:35,501 [INFO] utils.log: [ID TEST: CONCEPT 73] top-15 scores: [0.7674406  0.76802766 0.7700776  0.7798749  0.7791108  0.7836783\n",
      " 0.79177535 0.7829441  0.7761086  0.7721919  0.77347034 0.783664\n",
      " 0.7871443  0.7803245  0.7726082 ]\n",
      "2024-08-01 17:27:41,250 [INFO] utils.log: [ID TEST: CONCEPT 74] top-15 scores: [0.44541192 0.44616503 0.44818425 0.45040464 0.4621788  0.46923405\n",
      " 0.4539027  0.49840093 0.45973963 0.4539652  0.45858866 0.49777627\n",
      " 0.49892482 0.50190103 0.5033    ]\n",
      "2024-08-01 17:27:45,375 [INFO] utils.log: [ID TEST: CONCEPT 75] top-15 scores: [0.4770399  0.48418283 0.48845977 0.4814762  0.48928115 0.49154502\n",
      " 0.49225092 0.5160241  0.4990504  0.6226477  0.52032185 0.5267589\n",
      " 0.5171541  0.49375904 0.5287236 ]\n",
      "2024-08-01 17:27:49,025 [INFO] utils.log: [ID TEST: CONCEPT 76] top-15 scores: [0.6853024  0.6866879  0.6901294  0.7221234  0.70376426 0.7177229\n",
      " 0.69480217 0.70015013 0.7281774  0.69357663 0.7005769  0.7217742\n",
      " 0.72478724 0.7017547  0.69627583]\n",
      "2024-08-01 17:27:54,528 [INFO] utils.log: [ID TEST: CONCEPT 77] top-15 scores: [0.7108936  0.7125522  0.71394587 0.71800363 0.72047067 0.7291229\n",
      " 0.73891807 0.7140931  0.72989494 0.7204348  0.7243768  0.71588314\n",
      " 0.71772254 0.74364275 0.72228324]\n",
      "2024-08-01 17:27:59,985 [INFO] utils.log: [ID TEST: CONCEPT 78] top-15 scores: [0.727918   0.72794473 0.7291411  0.72822976 0.728106   0.7314881\n",
      " 0.73127425 0.73574567 0.743369   0.7407868  0.7411784  0.74972904\n",
      " 0.7579122  0.73813057 0.7432151 ]\n",
      "2024-08-01 17:28:08,416 [INFO] utils.log: [ID TEST: CONCEPT 79] top-15 scores: [0.50798476 0.5135704  0.5335953  0.50801736 0.520828   0.5122106\n",
      " 0.51447845 0.5338491  0.5450471  0.54653883 0.5435544  0.54497993\n",
      " 0.5460098  0.54460204 0.5482611 ]\n",
      "2024-08-01 17:28:12,606 [INFO] utils.log: [ID TEST: CONCEPT 80] top-15 scores: [0.65649974 0.65694773 0.65713125 0.6627335  0.66429627 0.66392565\n",
      " 0.6584956  0.6627785  0.65903735 0.6593169  0.6667862  0.6678028\n",
      " 0.69135964 0.6702184  0.6739124 ]\n",
      "2024-08-01 17:28:17,414 [INFO] utils.log: [ID TEST: CONCEPT 81] top-15 scores: [0.7276416  0.7293559  0.7296202  0.7298378  0.73701954 0.7339245\n",
      " 0.733623   0.7349894  0.73497766 0.73744017 0.73933566 0.738996\n",
      " 0.738207   0.7428638  0.7487515 ]\n",
      "2024-08-01 17:28:23,522 [INFO] utils.log: [ID TEST: CONCEPT 82] top-15 scores: [0.6624377  0.6632956  0.6637523  0.6660261  0.6677569  0.6694738\n",
      " 0.66987836 0.6753676  0.6699626  0.67761254 0.6854186  0.70264006\n",
      " 0.70814764 0.68826336 0.6892594 ]\n",
      "2024-08-01 17:28:30,093 [INFO] utils.log: [ID TEST: CONCEPT 83] top-15 scores: [0.8031558  0.8038124  0.8038391  0.80429757 0.80570304 0.81224275\n",
      " 0.8125608  0.80973285 0.81078887 0.81048626 0.81042755 0.81431246\n",
      " 0.80941606 0.8152046  0.80762815]\n",
      "2024-08-01 17:28:35,107 [INFO] utils.log: [ID TEST: CONCEPT 84] top-15 scores: [0.74428153 0.7549077  0.76223665 0.758031   0.7525089  0.75155914\n",
      " 0.7461743  0.74755424 0.75760233 0.7502165  0.7623589  0.7628808\n",
      " 0.76607037 0.7689828  0.7682743 ]\n",
      "2024-08-01 17:28:44,109 [INFO] utils.log: [ID TEST: CONCEPT 85] top-15 scores: [0.4563683  0.46741152 0.495718   0.5145375  0.486702   0.47689554\n",
      " 0.5063331  0.49252582 0.5316607  0.48991662 0.4885766  0.48878977\n",
      " 0.4802147  0.47270113 0.5265591 ]\n",
      "2024-08-01 17:28:48,091 [INFO] utils.log: [ID TEST: CONCEPT 86] top-15 scores: [0.804227   0.80700374 0.80467355 0.80550206 0.8063631  0.8045655\n",
      " 0.8084903  0.8250771  0.81488276 0.8157385  0.8330247  0.8178513\n",
      " 0.8139299  0.8097019  0.81980073]\n",
      "2024-08-01 17:28:52,913 [INFO] utils.log: [ID TEST: CONCEPT 87] top-15 scores: [0.7665709  0.7674421  0.76840067 0.76892775 0.7701536  0.77022386\n",
      " 0.76990575 0.7704288  0.77069473 0.78112704 0.7779572  0.7710619\n",
      " 0.77488315 0.7712349  0.77103746]\n",
      "2024-08-01 17:28:57,649 [INFO] utils.log: [ID TEST: CONCEPT 88] top-15 scores: [0.73696864 0.7390458  0.74015063 0.75768137 0.7453172  0.7511314\n",
      " 0.7423733  0.7556179  0.74049765 0.76982    0.7496562  0.748363\n",
      " 0.772411   0.7451978  0.7693018 ]\n",
      "2024-08-01 17:29:02,870 [INFO] utils.log: [ID TEST: CONCEPT 89] top-15 scores: [0.6523546  0.6556008  0.65880454 0.6608368  0.66306865 0.6609163\n",
      " 0.66180223 0.66312027 0.6704719  0.66691816 0.68274605 0.71801364\n",
      " 0.7239126  0.6716159  0.66668004]\n",
      "2024-08-01 17:29:05,604 [INFO] utils.log: [ID TEST: CONCEPT 90] top-15 scores: [0.6731695  0.6732436  0.6733612  0.674752   0.67655927 0.6774956\n",
      " 0.6749225  0.68014014 0.68127304 0.68469906 0.6916703  0.6911843\n",
      " 0.6898937  0.6894561  0.6878524 ]\n",
      "2024-08-01 17:29:11,382 [INFO] utils.log: [ID TEST: CONCEPT 91] top-15 scores: [0.32652128 0.3276208  0.33305755 0.3340445  0.3348227  0.36958843\n",
      " 0.4769913  0.35455182 0.34267712 0.44292167 0.3890658  0.3415193\n",
      " 0.37012583 0.3430145  0.3673895 ]\n",
      "2024-08-01 17:29:15,356 [INFO] utils.log: [ID TEST: CONCEPT 92] top-15 scores: [0.71485245 0.7530855  0.7236396  0.7236239  0.7156344  0.7377089\n",
      " 0.72330636 0.7505421  0.7278213  0.7478402  0.73507535 0.7153103\n",
      " 0.7201485  0.74139655 0.71968746]\n",
      "2024-08-01 17:29:23,491 [INFO] utils.log: [ID TEST: CONCEPT 93] top-15 scores: [0.70952106 0.71304333 0.7141559  0.71546596 0.716337   0.72284496\n",
      " 0.7340119  0.71927327 0.7245714  0.71689945 0.73129326 0.73037195\n",
      " 0.7176927  0.72107404 0.7179355 ]\n",
      "2024-08-01 17:29:30,983 [INFO] utils.log: [ID TEST: CONCEPT 94] top-15 scores: [0.28523463 0.2935944  0.29627147 0.29282755 0.29703212 0.35171142\n",
      " 0.382407   0.37645274 0.4439363  0.3329639  0.30194336 0.3144097\n",
      " 0.347794   0.36323157 0.4149845 ]\n",
      "2024-08-01 17:29:35,051 [INFO] utils.log: [ID TEST: CONCEPT 95] top-15 scores: [0.71008897 0.71158665 0.71321386 0.7152823  0.71308553 0.7152312\n",
      " 0.71664536 0.72827494 0.7248886  0.7175553  0.73535436 0.73037755\n",
      " 0.72492826 0.7403276  0.71842134]\n",
      "2024-08-01 17:29:41,129 [INFO] utils.log: [ID TEST: CONCEPT 96] top-15 scores: [0.7749357  0.7757515  0.77580404 0.7833788  0.77666    0.7846637\n",
      " 0.7794523  0.7837268  0.7830231  0.7828399  0.78735405 0.78940374\n",
      " 0.7963263  0.79000837 0.7897336 ]\n",
      "2024-08-01 17:29:46,400 [INFO] utils.log: [ID TEST: CONCEPT 97] top-15 scores: [0.7352342  0.7354192  0.75132495 0.7393388  0.73601496 0.7625724\n",
      " 0.7515143  0.75771457 0.7369217  0.74427694 0.7359413  0.74684584\n",
      " 0.7607674  0.7494911  0.7653686 ]\n",
      "2024-08-01 17:29:52,600 [INFO] utils.log: [ID TEST: CONCEPT 98] top-15 scores: [0.6358399  0.6358947  0.63610095 0.65283644 0.65305936 0.64340806\n",
      " 0.6409868  0.6422262  0.6392902  0.63628936 0.64578056 0.65407085\n",
      " 0.6608472  0.6857935  0.67437917]\n",
      "2024-08-01 17:29:59,009 [INFO] utils.log: [ID TEST: CONCEPT 99] top-15 scores: [0.46495593 0.46764052 0.46967995 0.48367566 0.4875614  0.49864858\n",
      " 0.50375444 0.5526345  0.5134345  0.529      0.535552   0.5057971\n",
      " 0.5451745  0.49286938 0.48667407]\n",
      "2024-08-01 17:30:04,848 [INFO] utils.log: [ID TEST: CONCEPT 0] top-15 scores: [0.44916552 0.44938326 0.45058823 0.45088822 0.47183657 0.46288753\n",
      " 0.45213577 0.45266008 0.46607858 0.46083924 0.48564672 0.49518472\n",
      " 0.49004763 0.49058044 0.5261958 ]\n",
      "2024-08-01 17:30:07,638 [INFO] utils.log: [ID TEST: CONCEPT 1] top-15 scores: [0.3186996  0.34146696 0.33988732 0.32624465 0.32667363 0.3208484\n",
      " 0.3432114  0.33488628 0.3284872  0.33652323 0.33572674 0.35510236\n",
      " 0.3506645  0.3346802  0.3590929 ]\n",
      "2024-08-01 17:30:10,632 [INFO] utils.log: [ID TEST: CONCEPT 2] top-15 scores: [0.39840758 0.42522514 0.44107383 0.43162525 0.4415297  0.44413278\n",
      " 0.44880202 0.45080936 0.47865963 0.46552148 0.51752627 0.4569484\n",
      " 0.5013262  0.44992122 0.46029773]\n",
      "2024-08-01 17:30:13,736 [INFO] utils.log: [ID TEST: CONCEPT 3] top-15 scores: [0.32949376 0.33084226 0.33634847 0.3315729  0.35586226 0.3450883\n",
      " 0.3645025  0.3665293  0.35815603 0.36504757 0.3310241  0.35951966\n",
      " 0.37506336 0.37645677 0.37546295]\n",
      "2024-08-01 17:30:16,193 [INFO] utils.log: [ID TEST: CONCEPT 4] top-15 scores: [0.30982375 0.31170493 0.31788427 0.34556013 0.3140043  0.34393868\n",
      " 0.3558983  0.337409   0.34677178 0.3322294  0.32847533 0.36122042\n",
      " 0.36340287 0.398802   0.38431776]\n",
      "2024-08-01 17:30:18,680 [INFO] utils.log: [ID TEST: CONCEPT 5] top-15 scores: [0.41805404 0.42011058 0.45907748 0.42535418 0.42636606 0.4356109\n",
      " 0.42998534 0.45072255 0.43597838 0.43188348 0.4298494  0.4550072\n",
      " 0.42610112 0.42107925 0.44556785]\n",
      "2024-08-01 17:30:21,480 [INFO] utils.log: [ID TEST: CONCEPT 6] top-15 scores: [0.51592654 0.52613735 0.55893123 0.5756048  0.6513198  0.57933164\n",
      " 0.58124924 0.5795324  0.69000125 0.71925485 0.7148069  0.6939517\n",
      " 0.72854334 0.7012577  0.71663404]\n",
      "2024-08-01 17:30:24,105 [INFO] utils.log: [ID TEST: CONCEPT 7] top-15 scores: [0.38224244 0.39110917 0.42180598 0.42807257 0.55979335 0.58391273\n",
      " 0.5953321  0.5227584  0.64696085 0.52012837 0.46317613 0.47259182\n",
      " 0.55075085 0.5131397  0.470834  ]\n",
      "2024-08-01 17:30:26,323 [INFO] utils.log: [ID TEST: CONCEPT 8] top-15 scores: [0.40518916 0.40985715 0.41028884 0.41103172 0.43784642 0.42661148\n",
      " 0.41782904 0.42367524 0.41363674 0.44827557 0.4117502  0.42587167\n",
      " 0.4927012  0.46577427 0.44012251]\n",
      "2024-08-01 17:30:28,807 [INFO] utils.log: [ID TEST: CONCEPT 9] top-15 scores: [0.45381764 0.45489126 0.46014768 0.46366102 0.46418422 0.46497792\n",
      " 0.46671367 0.4715572  0.4698795  0.474691   0.51177144 0.47983274\n",
      " 0.48388624 0.47284693 0.53283507]\n",
      "2024-08-01 17:30:31,959 [INFO] utils.log: [ID TEST: CONCEPT 10] top-15 scores: [0.30013466 0.30083632 0.30191404 0.30586848 0.3071515  0.30716476\n",
      " 0.308622   0.34994775 0.34111032 0.33122668 0.37535334 0.3247879\n",
      " 0.3289165  0.31371933 0.32853156]\n",
      "2024-08-01 17:30:34,847 [INFO] utils.log: [ID TEST: CONCEPT 11] top-15 scores: [0.4932866  0.5036242  0.5409327  0.5473435  0.5807698  0.56828856\n",
      " 0.5928979  0.6314585  0.59831846 0.62295824 0.64055777 0.656065\n",
      " 0.66903245 0.66309625 0.6761472 ]\n",
      "2024-08-01 17:30:36,553 [INFO] utils.log: [ID TEST: CONCEPT 12] top-15 scores: [0.27195626 0.33336213 0.2905636  0.28214803 0.275993   0.30163246\n",
      " 0.28022158 0.30050653 0.27657026 0.31857684 0.28868505 0.27869922\n",
      " 0.27286    0.30418086 0.2725669 ]\n",
      "2024-08-01 17:30:38,845 [INFO] utils.log: [ID TEST: CONCEPT 13] top-15 scores: [0.5038092  0.5038846  0.5104688  0.51160264 0.51474994 0.52370346\n",
      " 0.5456865  0.55019766 0.52638906 0.5665169  0.590803   0.57536703\n",
      " 0.5817343  0.57562363 0.6119075 ]\n",
      "2024-08-01 17:30:41,257 [INFO] utils.log: [ID TEST: CONCEPT 14] top-15 scores: [0.24074224 0.25955564 0.25556898 0.25617984 0.25557777 0.26292282\n",
      " 0.2694409  0.26723224 0.27020064 0.29445687 0.30229235 0.29842806\n",
      " 0.27639225 0.3020581  0.32317173]\n",
      "2024-08-01 17:30:43,330 [INFO] utils.log: [ID TEST: CONCEPT 15] top-15 scores: [0.3730908  0.37882543 0.38309538 0.3938511  0.39717293 0.3993497\n",
      " 0.40081668 0.4057672  0.40587002 0.44768482 0.4210315  0.40829048\n",
      " 0.45784533 0.40975374 0.41659907]\n",
      "2024-08-01 17:30:45,775 [INFO] utils.log: [ID TEST: CONCEPT 16] top-15 scores: [0.49420896 0.50006425 0.5103202  0.51651967 0.5165516  0.511436\n",
      " 0.51216584 0.51932967 0.5179333  0.5462386  0.54811925 0.55052984\n",
      " 0.55319095 0.54957956 0.55107045]\n",
      "2024-08-01 17:30:49,066 [INFO] utils.log: [ID TEST: CONCEPT 17] top-15 scores: [0.20658046 0.20922093 0.2319276  0.22068429 0.24843922 0.23850885\n",
      " 0.23573706 0.20986643 0.22182998 0.22513995 0.21276629 0.22745687\n",
      " 0.21568489 0.23004907 0.23596272]\n",
      "2024-08-01 17:30:52,811 [INFO] utils.log: [ID TEST: CONCEPT 18] top-15 scores: [0.2074187  0.2081398  0.20899914 0.22243002 0.23110153 0.2126632\n",
      " 0.21031265 0.21916775 0.23147061 0.24058756 0.2385581  0.23446593\n",
      " 0.24097332 0.2478852  0.24469   ]\n",
      "2024-08-01 17:30:54,974 [INFO] utils.log: [ID TEST: CONCEPT 19] top-15 scores: [0.22426847 0.22479945 0.22582859 0.22629717 0.22766185 0.22854747\n",
      " 0.230269   0.23957512 0.23256354 0.23842882 0.2360402  0.24606699\n",
      " 0.24307434 0.276569   0.23842213]\n",
      "2024-08-01 17:30:57,347 [INFO] utils.log: [ID TEST: CONCEPT 20] top-15 scores: [0.2207285  0.22192788 0.22740316 0.2279634  0.2414184  0.25962943\n",
      " 0.25583923 0.26590914 0.27933943 0.24718922 0.27579564 0.24819504\n",
      " 0.2613464  0.24910203 0.24921371]\n",
      "2024-08-01 17:31:00,218 [INFO] utils.log: [ID TEST: CONCEPT 21] top-15 scores: [0.30014598 0.30586958 0.30610582 0.3022051  0.30612594 0.31126797\n",
      " 0.31169012 0.31223392 0.31510568 0.32363695 0.33090192 0.35225385\n",
      " 0.34024394 0.32697487 0.352598  ]\n",
      "2024-08-01 17:31:02,918 [INFO] utils.log: [ID TEST: CONCEPT 22] top-15 scores: [0.3200487  0.33065686 0.33238715 0.35669112 0.353931   0.34203994\n",
      " 0.39771295 0.3445071  0.37094244 0.3807663  0.3691843  0.41625625\n",
      " 0.37538692 0.37369996 0.37083352]\n",
      "2024-08-01 17:31:05,150 [INFO] utils.log: [ID TEST: CONCEPT 23] top-15 scores: [0.6954306  0.7017191  0.70448846 0.7202761  0.75767356 0.7575625\n",
      " 0.76362574 0.76621205 0.7328757  0.7238029  0.7556182  0.74526024\n",
      " 0.7712817  0.7366916  0.7552466 ]\n",
      "2024-08-01 17:31:07,651 [INFO] utils.log: [ID TEST: CONCEPT 24] top-15 scores: [0.34022275 0.340483   0.34857464 0.44051647 0.41804844 0.3744018\n",
      " 0.3964324  0.45636022 0.37105513 0.35521466 0.35665804 0.47757918\n",
      " 0.38655472 0.46008575 0.40104678]\n",
      "2024-08-01 17:31:09,487 [INFO] utils.log: [ID TEST: CONCEPT 25] top-15 scores: [0.43385342 0.44958168 0.45191416 0.4520067  0.46216744 0.49137652\n",
      " 0.5068423  0.52671385 0.50857085 0.5091541  0.51035404 0.53958935\n",
      " 0.58115125 0.57956827 0.55191106]\n",
      "2024-08-01 17:31:12,655 [INFO] utils.log: [ID TEST: CONCEPT 26] top-15 scores: [0.37724409 0.37790406 0.37887603 0.38017952 0.390222   0.38935468\n",
      " 0.38384876 0.38765818 0.3907111  0.38300568 0.39425102 0.43939036\n",
      " 0.41165513 0.3969495  0.40118998]\n",
      "2024-08-01 17:31:15,040 [INFO] utils.log: [ID TEST: CONCEPT 27] top-15 scores: [0.33446977 0.3371385  0.3403569  0.34160262 0.34556687 0.3559404\n",
      " 0.35916963 0.3758437  0.536853   0.38214362 0.4605344  0.3878767\n",
      " 0.4798892  0.38423717 0.38511097]\n",
      "2024-08-01 17:31:19,196 [INFO] utils.log: [ID TEST: CONCEPT 28] top-15 scores: [0.37424117 0.3772508  0.37874648 0.39389324 0.4144407  0.4033865\n",
      " 0.38943076 0.4154478  0.39124802 0.38446516 0.3844459  0.42045766\n",
      " 0.46301368 0.4416812  0.44089663]\n",
      "2024-08-01 17:31:21,833 [INFO] utils.log: [ID TEST: CONCEPT 29] top-15 scores: [0.3195588  0.32315776 0.35704893 0.33727944 0.37710583 0.33556128\n",
      " 0.3315954  0.32995027 0.39233002 0.33809602 0.34318718 0.33214945\n",
      " 0.3330625  0.37892702 0.33291224]\n",
      "2024-08-01 17:31:24,126 [INFO] utils.log: [ID TEST: CONCEPT 30] top-15 scores: [0.46822485 0.49396494 0.5027031  0.60243    0.49528837 0.5461554\n",
      " 0.5509955  0.47285777 0.55760777 0.53426903 0.48599964 0.51617634\n",
      " 0.5287338  0.5234105  0.4758326 ]\n",
      "2024-08-01 17:31:26,557 [INFO] utils.log: [ID TEST: CONCEPT 31] top-15 scores: [0.26779586 0.26872504 0.27241728 0.27296084 0.27604    0.28394368\n",
      " 0.28863764 0.3917557  0.31675407 0.30787832 0.28897074 0.31566182\n",
      " 0.2927832  0.29677176 0.33421168]\n",
      "2024-08-01 17:31:28,672 [INFO] utils.log: [ID TEST: CONCEPT 32] top-15 scores: [0.496426   0.49890158 0.5248138  0.50675654 0.5094381  0.5025351\n",
      " 0.51678216 0.53909034 0.5816711  0.57501715 0.54704124 0.5739588\n",
      " 0.57322097 0.58497715 0.61427   ]\n",
      "2024-08-01 17:31:31,142 [INFO] utils.log: [ID TEST: CONCEPT 33] top-15 scores: [0.25695482 0.2597217  0.26175278 0.265045   0.2705043  0.27361774\n",
      " 0.29031205 0.30985326 0.2890927  0.27545944 0.29716286 0.2786376\n",
      " 0.3122324  0.3840558  0.3326999 ]\n",
      "2024-08-01 17:31:35,682 [INFO] utils.log: [ID TEST: CONCEPT 34] top-15 scores: [0.42502493 0.42685148 0.51370853 0.49631867 0.429667   0.46975076\n",
      " 0.46371946 0.49760884 0.47488654 0.48515782 0.46143273 0.46681374\n",
      " 0.44863057 0.46580744 0.49217072]\n",
      "2024-08-01 17:31:38,800 [INFO] utils.log: [ID TEST: CONCEPT 35] top-15 scores: [0.24401236 0.25085378 0.2603026  0.24822706 0.24776316 0.24756294\n",
      " 0.27415103 0.32572493 0.3228907  0.31248727 0.3510996  0.3447465\n",
      " 0.3305781  0.33116162 0.33249688]\n",
      "2024-08-01 17:31:43,703 [INFO] utils.log: [ID TEST: CONCEPT 36] top-15 scores: [0.26690993 0.27287015 0.27727506 0.3012287  0.27780432 0.2889545\n",
      " 0.30269337 0.3364165  0.35689092 0.39677727 0.3551094  0.41390586\n",
      " 0.4529306  0.4602031  0.41797125]\n",
      "2024-08-01 17:31:48,198 [INFO] utils.log: [ID TEST: CONCEPT 37] top-15 scores: [0.33947605 0.33977112 0.34881234 0.36549067 0.4870295  0.36804146\n",
      " 0.51857114 0.4074818  0.37694293 0.5019413  0.41283035 0.42619038\n",
      " 0.49203655 0.396848   0.37486503]\n",
      "2024-08-01 17:31:51,007 [INFO] utils.log: [ID TEST: CONCEPT 38] top-15 scores: [0.2965036  0.3038835  0.30043644 0.305252   0.30933112 0.30952835\n",
      " 0.31062767 0.3201752  0.36184675 0.36289662 0.35740024 0.33540615\n",
      " 0.33792967 0.35456768 0.3286183 ]\n",
      "2024-08-01 17:31:53,863 [INFO] utils.log: [ID TEST: CONCEPT 39] top-15 scores: [0.6459117  0.65257263 0.6802228  0.6959071  0.68554914 0.6982926\n",
      " 0.7334579  0.75040543 0.75246215 0.7503998  0.7361661  0.74731576\n",
      " 0.71684605 0.73011994 0.7168388 ]\n",
      "2024-08-01 17:31:56,806 [INFO] utils.log: [ID TEST: CONCEPT 40] top-15 scores: [0.33205682 0.33281383 0.33384138 0.339616   0.363846   0.36433274\n",
      " 0.36926225 0.38100392 0.37317646 0.3704927  0.39762574 0.42091644\n",
      " 0.40082088 0.43012297 0.41771752]\n",
      "2024-08-01 17:31:59,468 [INFO] utils.log: [ID TEST: CONCEPT 41] top-15 scores: [0.44986916 0.45030534 0.4558772  0.45599428 0.45620704 0.461287\n",
      " 0.4623512  0.4668154  0.49898845 0.5079291  0.5061664  0.4974413\n",
      " 0.46872878 0.5179232  0.47200656]\n",
      "2024-08-01 17:32:01,846 [INFO] utils.log: [ID TEST: CONCEPT 42] top-15 scores: [0.20350811 0.20547187 0.20747489 0.20965526 0.21341822 0.22046098\n",
      " 0.23424163 0.22690839 0.21161437 0.217388   0.21491751 0.23084423\n",
      " 0.21862032 0.21469694 0.22534871]\n",
      "2024-08-01 17:32:05,008 [INFO] utils.log: [ID TEST: CONCEPT 43] top-15 scores: [0.55257607 0.5680481  0.5582415  0.60500807 0.7244172  0.7276429\n",
      " 0.7224849  0.64441013 0.7245797  0.72512686 0.7160901  0.6470802\n",
      " 0.61228424 0.7132172  0.7155083 ]\n",
      "2024-08-01 17:32:07,390 [INFO] utils.log: [ID TEST: CONCEPT 44] top-15 scores: [0.5196853  0.56202996 0.54545414 0.5821568  0.60684526 0.6154935\n",
      " 0.5857588  0.6653978  0.7231173  0.7128072  0.7116561  0.73257685\n",
      " 0.71707296 0.70864475 0.7305819 ]\n",
      "2024-08-01 17:32:10,774 [INFO] utils.log: [ID TEST: CONCEPT 45] top-15 scores: [0.340999   0.3410736  0.35215178 0.3640232  0.36358756 0.34585607\n",
      " 0.3642605  0.39846307 0.3896271  0.44419792 0.37896955 0.42426568\n",
      " 0.40638584 0.38332516 0.3903383 ]\n",
      "2024-08-01 17:32:12,588 [INFO] utils.log: [ID TEST: CONCEPT 46] top-15 scores: [0.5108807  0.5481712  0.5938148  0.5537324  0.5686829  0.5656824\n",
      " 0.6066864  0.6636162  0.71500957 0.7191363  0.69729567 0.70198226\n",
      " 0.71893287 0.7154223  0.6944252 ]\n",
      "2024-08-01 17:32:15,166 [INFO] utils.log: [ID TEST: CONCEPT 47] top-15 scores: [0.50349486 0.50782746 0.68066186 0.63130295 0.63571477 0.6365141\n",
      " 0.6021236  0.5403719  0.69029355 0.51430017 0.6820234  0.51544225\n",
      " 0.6429954  0.65220875 0.617941  ]\n",
      "2024-08-01 17:32:19,047 [INFO] utils.log: [ID TEST: CONCEPT 48] top-15 scores: [0.38152254 0.39973947 0.5305183  0.5728749  0.488335   0.49865416\n",
      " 0.3985509  0.41932297 0.6084182  0.6401459  0.5272318  0.39875734\n",
      " 0.54828197 0.5374433  0.38866478]\n",
      "2024-08-01 17:32:21,448 [INFO] utils.log: [ID TEST: CONCEPT 49] top-15 scores: [0.33360535 0.3357688  0.3401653  0.37224472 0.38232815 0.433043\n",
      " 0.4078489  0.4763753  0.43345878 0.49023327 0.50083846 0.5261755\n",
      " 0.5897492  0.5254583  0.5536855 ]\n",
      "2024-08-01 17:32:24,112 [INFO] utils.log: [ID TEST: CONCEPT 50] top-15 scores: [0.261188   0.26487392 0.2787136  0.2791605  0.28519788 0.29282498\n",
      " 0.32457495 0.32673877 0.287569   0.32518595 0.3325026  0.33837426\n",
      " 0.36782938 0.34233338 0.36012134]\n",
      "2024-08-01 17:32:26,781 [INFO] utils.log: [ID TEST: CONCEPT 51] top-15 scores: [0.23213975 0.23299633 0.23260799 0.23585413 0.23693684 0.24520814\n",
      " 0.24602203 0.25359428 0.24857962 0.26780233 0.2784145  0.24602348\n",
      " 0.26762432 0.27281782 0.24743555]\n",
      "2024-08-01 17:32:29,067 [INFO] utils.log: [ID TEST: CONCEPT 52] top-15 scores: [0.21396093 0.21856382 0.22012296 0.22042385 0.22099745 0.2219925\n",
      " 0.22337699 0.22451213 0.22592863 0.22420365 0.22718318 0.24864046\n",
      " 0.24806666 0.23317389 0.22811344]\n",
      "2024-08-01 17:32:31,607 [INFO] utils.log: [ID TEST: CONCEPT 53] top-15 scores: [0.27726412 0.27783397 0.39411908 0.3240791  0.3905369  0.28342342\n",
      " 0.3360427  0.28062683 0.43110448 0.28487188 0.2798344  0.30482468\n",
      " 0.4357866  0.36188194 0.31780168]\n",
      "2024-08-01 17:32:33,968 [INFO] utils.log: [ID TEST: CONCEPT 54] top-15 scores: [0.49610698 0.49678284 0.58900404 0.53226936 0.6074274  0.5848737\n",
      " 0.58103967 0.497647   0.6187872  0.6129478  0.5923394  0.55694395\n",
      " 0.5053869  0.5342933  0.4982635 ]\n",
      "2024-08-01 17:32:36,749 [INFO] utils.log: [ID TEST: CONCEPT 55] top-15 scores: [0.46599942 0.48271096 0.47684884 0.4829428  0.51862323 0.49104467\n",
      " 0.52499354 0.51073205 0.49477875 0.52803355 0.52754223 0.51635647\n",
      " 0.50961053 0.5037875  0.52741915]\n",
      "2024-08-01 17:32:38,862 [INFO] utils.log: [ID TEST: CONCEPT 56] top-15 scores: [0.38590544 0.39831018 0.4145936  0.42606333 0.4178049  0.42351848\n",
      " 0.42842582 0.41501075 0.43245628 0.4353603  0.44991207 0.5082803\n",
      " 0.50570524 0.4669326  0.46091112]\n",
      "2024-08-01 17:32:40,981 [INFO] utils.log: [ID TEST: CONCEPT 57] top-15 scores: [0.45976374 0.46029902 0.46368372 0.47648242 0.48646206 0.5167775\n",
      " 0.5258605  0.56485134 0.5275787  0.5510646  0.58251524 0.5924701\n",
      " 0.58670044 0.58346397 0.59605193]\n",
      "2024-08-01 17:32:42,788 [INFO] utils.log: [ID TEST: CONCEPT 58] top-15 scores: [0.37206662 0.3759805  0.37555903 0.37658197 0.39103675 0.39818665\n",
      " 0.38645402 0.39525795 0.38851827 0.44790828 0.39348325 0.41029635\n",
      " 0.4027386  0.38730592 0.4173899 ]\n",
      "2024-08-01 17:32:44,947 [INFO] utils.log: [ID TEST: CONCEPT 59] top-15 scores: [0.24793243 0.24820542 0.25341183 0.25577813 0.26134783 0.2631683\n",
      " 0.2612568  0.26709995 0.26851422 0.26942348 0.27578348 0.32680163\n",
      " 0.36202225 0.3266138  0.278624  ]\n",
      "2024-08-01 17:32:47,186 [INFO] utils.log: [ID TEST: CONCEPT 60] top-15 scores: [0.23888682 0.28069484 0.23945907 0.26625404 0.2803876  0.26334482\n",
      " 0.28169578 0.24685231 0.24558404 0.24052136 0.24231638 0.27376378\n",
      " 0.2409687  0.26970708 0.24395603]\n",
      "2024-08-01 17:32:49,302 [INFO] utils.log: [ID TEST: CONCEPT 61] top-15 scores: [0.5088911  0.5117339  0.5628809  0.5810526  0.53596985 0.6873057\n",
      " 0.6402747  0.56159127 0.5757583  0.7005755  0.69753444 0.70665085\n",
      " 0.72020006 0.72032523 0.71375406]\n",
      "2024-08-01 17:32:51,908 [INFO] utils.log: [ID TEST: CONCEPT 62] top-15 scores: [0.4484535  0.45129633 0.4526263  0.4603619  0.46949112 0.47685927\n",
      " 0.45225823 0.47473615 0.4545098  0.46814436 0.46249354 0.46552342\n",
      " 0.46250623 0.45570973 0.4719341 ]\n",
      "2024-08-01 17:32:54,436 [INFO] utils.log: [ID TEST: CONCEPT 63] top-15 scores: [0.35032788 0.3792853  0.39397612 0.542939   0.49551177 0.42134976\n",
      " 0.5441224  0.48886612 0.43067056 0.5361297  0.5592509  0.4150983\n",
      " 0.58092767 0.6435439  0.60480976]\n",
      "2024-08-01 17:32:57,145 [INFO] utils.log: [ID TEST: CONCEPT 64] top-15 scores: [0.496628   0.49938822 0.4994101  0.50015056 0.56418157 0.5011818\n",
      " 0.5042953  0.56171227 0.59679496 0.5661912  0.51261514 0.5276345\n",
      " 0.57112443 0.5616865  0.5436498 ]\n",
      "2024-08-01 17:32:59,608 [INFO] utils.log: [ID TEST: CONCEPT 65] top-15 scores: [0.12159711 0.12218454 0.12416306 0.12401392 0.12370174 0.12267362\n",
      " 0.12527475 0.12354109 0.12276248 0.12574387 0.12726033 0.1287068\n",
      " 0.12673837 0.12847319 0.12637843]\n",
      "2024-08-01 17:33:01,789 [INFO] utils.log: [ID TEST: CONCEPT 66] top-15 scores: [0.39434445 0.3950704  0.39559522 0.39973634 0.40959716 0.4096691\n",
      " 0.40976113 0.55359125 0.5230911  0.43638575 0.42040733 0.41368908\n",
      " 0.45934603 0.49028912 0.46299094]\n",
      "2024-08-01 17:33:03,920 [INFO] utils.log: [ID TEST: CONCEPT 67] top-15 scores: [0.34598416 0.35161528 0.35749564 0.37597734 0.37035388 0.37976998\n",
      " 0.40587348 0.49899548 0.42262304 0.43636417 0.413888   0.39233655\n",
      " 0.51511407 0.51173925 0.5269433 ]\n",
      "2024-08-01 17:33:06,808 [INFO] utils.log: [ID TEST: CONCEPT 68] top-15 scores: [0.21527131 0.219917   0.21972862 0.22041818 0.22233474 0.21594417\n",
      " 0.22736144 0.21567133 0.22065213 0.22234836 0.22194356 0.2212756\n",
      " 0.23097527 0.22392076 0.21737859]\n",
      "2024-08-01 17:33:09,043 [INFO] utils.log: [ID TEST: CONCEPT 69] top-15 scores: [0.28004268 0.28141224 0.29793864 0.39579147 0.39789045 0.33570182\n",
      " 0.40595716 0.3958608  0.31364936 0.31285816 0.34901688 0.35793996\n",
      " 0.34497538 0.29855448 0.30594623]\n",
      "2024-08-01 17:33:11,359 [INFO] utils.log: [ID TEST: CONCEPT 70] top-15 scores: [0.42673433 0.43122694 0.43580928 0.44469133 0.4741664  0.47707576\n",
      " 0.441594   0.49384898 0.5060308  0.5301403  0.56989384 0.5099767\n",
      " 0.5140471  0.53991985 0.5640668 ]\n",
      "2024-08-01 17:33:13,890 [INFO] utils.log: [ID TEST: CONCEPT 71] top-15 scores: [0.46514764 0.4687326  0.4689886  0.47118682 0.47173795 0.47214913\n",
      " 0.48955184 0.48397946 0.4805001  0.47529328 0.4774429  0.4722992\n",
      " 0.4991697  0.5021774  0.52513313]\n",
      "2024-08-01 17:33:16,193 [INFO] utils.log: [ID TEST: CONCEPT 72] top-15 scores: [0.4342473  0.4358507  0.43659684 0.47802937 0.45311812 0.48384\n",
      " 0.44622913 0.4401763  0.50862336 0.52111447 0.5306318  0.47187036\n",
      " 0.44497192 0.48338977 0.44767722]\n",
      "2024-08-01 17:33:18,150 [INFO] utils.log: [ID TEST: CONCEPT 73] top-15 scores: [0.21831839 0.2215327  0.22219148 0.22536984 0.23052752 0.22930658\n",
      " 0.2348505  0.23821422 0.23619863 0.23372535 0.23948634 0.2566773\n",
      " 0.24919175 0.25007048 0.24252251]\n",
      "2024-08-01 17:33:20,481 [INFO] utils.log: [ID TEST: CONCEPT 74] top-15 scores: [0.34087995 0.34789947 0.34217557 0.37851328 0.38050163 0.38440782\n",
      " 0.34097642 0.4220181  0.36644143 0.4471485  0.360742   0.34965006\n",
      " 0.50906336 0.37110466 0.47116953]\n",
      "2024-08-01 17:33:22,658 [INFO] utils.log: [ID TEST: CONCEPT 75] top-15 scores: [0.45231783 0.4655889  0.48169053 0.46088934 0.45842558 0.5061958\n",
      " 0.4844865  0.47475135 0.4679814  0.4608149  0.46745968 0.461317\n",
      " 0.51234466 0.46567458 0.51325274]\n",
      "2024-08-01 17:33:24,956 [INFO] utils.log: [ID TEST: CONCEPT 76] top-15 scores: [0.2763104  0.27643228 0.2772965  0.32291383 0.28439295 0.30832672\n",
      " 0.29663956 0.30569938 0.33847737 0.28907934 0.31257555 0.28234386\n",
      " 0.30765194 0.32097998 0.27745157]\n",
      "2024-08-01 17:33:27,491 [INFO] utils.log: [ID TEST: CONCEPT 77] top-15 scores: [0.39381987 0.39567757 0.4037622  0.3941589  0.40983474 0.43788415\n",
      " 0.46020934 0.4133361  0.42034236 0.4509105  0.425664   0.45353296\n",
      " 0.4531165  0.4160167  0.45304614]\n",
      "2024-08-01 17:33:29,882 [INFO] utils.log: [ID TEST: CONCEPT 78] top-15 scores: [0.2835874  0.29157692 0.29720697 0.28428566 0.30988055 0.30258554\n",
      " 0.283756   0.29301006 0.31326365 0.33446288 0.34349012 0.332707\n",
      " 0.33848375 0.31619757 0.31657824]\n",
      "2024-08-01 17:33:32,635 [INFO] utils.log: [ID TEST: CONCEPT 79] top-15 scores: [0.56745225 0.569451   0.5723094  0.5738872  0.5752232  0.5766144\n",
      " 0.5910488  0.58010185 0.5977084  0.5829756  0.5839981  0.59350336\n",
      " 0.59807163 0.58319616 0.57925695]\n",
      "2024-08-01 17:33:34,731 [INFO] utils.log: [ID TEST: CONCEPT 80] top-15 scores: [0.4250672  0.4336418  0.43048465 0.43490583 0.5274523  0.52369916\n",
      " 0.47880927 0.47330427 0.4417437  0.46433645 0.43747634 0.45509607\n",
      " 0.43581116 0.51637924 0.5175947 ]\n",
      "2024-08-01 17:33:37,506 [INFO] utils.log: [ID TEST: CONCEPT 81] top-15 scores: [0.53357095 0.5449785  0.6320788  0.68035865 0.6770305  0.6774986\n",
      " 0.6788484  0.6226435  0.6858511  0.6744525  0.66662395 0.66812617\n",
      " 0.5531367  0.56180984 0.55555046]\n",
      "2024-08-01 17:33:39,769 [INFO] utils.log: [ID TEST: CONCEPT 82] top-15 scores: [0.48115182 0.4921777  0.49951756 0.49707842 0.5011096  0.5117104\n",
      " 0.54010165 0.5139537  0.5706938  0.59407496 0.60480607 0.6059503\n",
      " 0.57180333 0.5820219  0.60310894]\n",
      "2024-08-01 17:33:42,391 [INFO] utils.log: [ID TEST: CONCEPT 83] top-15 scores: [0.70724136 0.70884013 0.7140771  0.7467086  0.7551998  0.7448059\n",
      " 0.7463515  0.72217333 0.718422   0.723014   0.7639738  0.76532334\n",
      " 0.7785655  0.7745236  0.76808846]\n",
      "2024-08-01 17:33:44,788 [INFO] utils.log: [ID TEST: CONCEPT 84] top-15 scores: [0.2878806  0.28790247 0.2910512  0.2973423  0.30573714 0.30736\n",
      " 0.34818575 0.3044301  0.32095015 0.31698543 0.31129932 0.31237394\n",
      " 0.31405807 0.32186133 0.3480417 ]\n",
      "2024-08-01 17:33:47,093 [INFO] utils.log: [ID TEST: CONCEPT 85] top-15 scores: [0.363119   0.367396   0.36837414 0.36918336 0.43028226 0.3720689\n",
      " 0.41027942 0.37320662 0.40689355 0.39546567 0.4363038  0.48222184\n",
      " 0.39469874 0.54609007 0.46117365]\n",
      "2024-08-01 17:33:49,364 [INFO] utils.log: [ID TEST: CONCEPT 86] top-15 scores: [0.51386225 0.51489383 0.54872954 0.55930114 0.56872237 0.70032936\n",
      " 0.642367   0.6897322  0.58116287 0.72255385 0.5749527  0.68266344\n",
      " 0.71898746 0.70632493 0.7232529 ]\n",
      "2024-08-01 17:33:51,792 [INFO] utils.log: [ID TEST: CONCEPT 87] top-15 scores: [0.64116764 0.6546583  0.6738057  0.67476237 0.6940432  0.7391702\n",
      " 0.7453722  0.73931897 0.6997831  0.7532143  0.7438206  0.73874784\n",
      " 0.74536073 0.720724   0.7197978 ]\n",
      "2024-08-01 17:33:54,143 [INFO] utils.log: [ID TEST: CONCEPT 88] top-15 scores: [0.4475902  0.450492   0.45234108 0.45740706 0.46578792 0.47979063\n",
      " 0.48022282 0.51003456 0.5437292  0.51284236 0.5531476  0.5101404\n",
      " 0.51965016 0.5239018  0.51577425]\n",
      "2024-08-01 17:33:56,473 [INFO] utils.log: [ID TEST: CONCEPT 89] top-15 scores: [0.35122088 0.3572185  0.36529452 0.38900137 0.43886173 0.42214915\n",
      " 0.42478585 0.42125022 0.43412852 0.42509896 0.41899788 0.4000718\n",
      " 0.45777577 0.41938728 0.42722476]\n",
      "2024-08-01 17:33:58,832 [INFO] utils.log: [ID TEST: CONCEPT 90] top-15 scores: [0.27711552 0.27746892 0.2813245  0.3043123  0.28423437 0.28579593\n",
      " 0.31335926 0.307827   0.31939864 0.2880303  0.2909111  0.32404494\n",
      " 0.3732556  0.3578282  0.33842742]\n",
      "2024-08-01 17:34:01,056 [INFO] utils.log: [ID TEST: CONCEPT 91] top-15 scores: [0.31381282 0.31408492 0.34907135 0.36406663 0.31576344 0.34675932\n",
      " 0.35158798 0.32369265 0.31843227 0.34361902 0.33726814 0.32914612\n",
      " 0.32482535 0.3337564  0.32123452]\n",
      "2024-08-01 17:34:03,296 [INFO] utils.log: [ID TEST: CONCEPT 92] top-15 scores: [0.50817525 0.5087447  0.5158915  0.5201269  0.6525742  0.63067997\n",
      " 0.700107   0.6837877  0.62019944 0.5405278  0.64095813 0.64483553\n",
      " 0.63431454 0.60880685 0.6865126 ]\n",
      "2024-08-01 17:34:06,058 [INFO] utils.log: [ID TEST: CONCEPT 93] top-15 scores: [0.34864897 0.35419655 0.36170012 0.36108875 0.3750322  0.37732446\n",
      " 0.3788189  0.3869429  0.3947664  0.38617164 0.3807938  0.39651108\n",
      " 0.39669487 0.43412045 0.42624277]\n",
      "2024-08-01 17:34:08,276 [INFO] utils.log: [ID TEST: CONCEPT 94] top-15 scores: [0.45923287 0.46103323 0.46142375 0.4688574  0.47153208 0.47264802\n",
      " 0.4690095  0.4943121  0.5591124  0.5252542  0.5528228  0.51149803\n",
      " 0.5203807  0.5197236  0.53207886]\n",
      "2024-08-01 17:34:10,596 [INFO] utils.log: [ID TEST: CONCEPT 95] top-15 scores: [0.44544244 0.4527434  0.46663898 0.45938483 0.47346854 0.48499438\n",
      " 0.5374775  0.47718453 0.48433903 0.5437319  0.51559365 0.48768747\n",
      " 0.5311835  0.54981345 0.589216  ]\n",
      "2024-08-01 17:34:13,188 [INFO] utils.log: [ID TEST: CONCEPT 96] top-15 scores: [0.21992646 0.22082247 0.22200555 0.22457515 0.2263506  0.22862312\n",
      " 0.22401898 0.22922584 0.23165287 0.25141713 0.24232592 0.25111127\n",
      " 0.2352181  0.24660125 0.24200705]\n",
      "2024-08-01 17:34:15,593 [INFO] utils.log: [ID TEST: CONCEPT 97] top-15 scores: [0.3190168  0.32007483 0.32271606 0.33219066 0.33349085 0.3209596\n",
      " 0.3346384  0.3648374  0.3373835  0.3536408  0.3456807  0.3849752\n",
      " 0.37078965 0.33697876 0.3521617 ]\n",
      "2024-08-01 17:34:17,885 [INFO] utils.log: [ID TEST: CONCEPT 98] top-15 scores: [0.41305417 0.41611058 0.42396024 0.43385595 0.43155512 0.43826088\n",
      " 0.4328149  0.43282753 0.42660087 0.45036227 0.42433766 0.41822338\n",
      " 0.4317839  0.43765628 0.43567267]\n",
      "2024-08-01 17:34:20,391 [INFO] utils.log: [ID TEST: CONCEPT 99] top-15 scores: [0.34399867 0.34648174 0.34980536 0.35724607 0.35866764 0.3781862\n",
      " 0.38079572 0.49174452 0.538636   0.43804163 0.43528938 0.4044052\n",
      " 0.47680578 0.41267735 0.38334537]\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "## Visualize the nearest neighbors\n",
    "if args.visualize:\n",
    "    visualize_nn(in_loader, topic_vec, in_test_features, args.result_dir, logger)\n",
    "if args.visualize_with_ood:\n",
    "    visualize_nn(out_loader, topic_vec, out_test_features, args.result_dir, logger, args.out_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a51a599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:34:22,693 [INFO] utils.log: [ID TEST] performance of target OOD detector with test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817aa417a10c4c509d8efb47338b52ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1722526467.546862 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.604248 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.605810 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.607302 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.609410 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.611499 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.613234 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.615149 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.617394 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.620331 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.622496 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.625267 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.628391 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.631850 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.635278 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.641235 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.647770 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.665628 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.670626 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.675768 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.681213 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.686658 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.692718 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.699245 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.706871 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.714086 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.721585 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.729302 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.738065 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.747285 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.755578 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.764896 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.775008 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.789033 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.806351 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.824726 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.845455 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.858577 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.869397 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.906205 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.960121 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.973036 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526467.980955 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.067046 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.079000 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.087559 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.096884 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.106204 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.115406 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.126028 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.138037 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.150767 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.163784 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.177117 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.190814 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.207022 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.227629 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.247991 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.268803 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.304929 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.345220 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.362067 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.413847 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.423120 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.433304 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.442693 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.455886 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.472990 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.485925 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.500059 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.514633 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.528880 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.543457 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.559071 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.577691 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.597208 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.619926 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.638271 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.659600 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.670736 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.692795 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.718451 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.739701 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.764054 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.787230 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.816815 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.819438 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.820659 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.821854 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.823351 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.824710 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.826574 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.828457 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.830352 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.832079 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.833733 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.835381 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.836993 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.838812 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.840843 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.843271 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.845682 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.848051 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.850251 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.852504 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.855471 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.887283 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.888837 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.890391 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.891910 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.893767 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.895582 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.898232 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.900897 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.903655 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.906022 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.908335 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.910645 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.912888 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.915343 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.918198 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.921611 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.925025 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.928196 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.931360 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.934562 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.938838 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.953147 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.954018 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.954924 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.955759 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.956582 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.958531 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.960509 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.964096 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.966187 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.968271 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.970467 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.972613 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.974752 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.977500 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.981871 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.986360 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.989290 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.992303 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526468.995760 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.000010 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.007782 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.087108 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.087944 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.088771 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.089562 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.090346 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.091189 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.092017 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.092869 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.093686 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.094576 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.095472 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.096425 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.097386 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.098298 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.099328 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.100277 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.101490 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.103094 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.112438 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.117574 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.123037 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.128607 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.134960 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.140633 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.147025 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.153085 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.159423 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.167365 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.173596 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.179288 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.186326 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.194932 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.203787 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.211621 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.220139 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.228724 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.254769 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.255728 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.256632 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.257615 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.258583 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.259555 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.260553 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.261503 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.262449 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.263325 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.265297 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.266613 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.268561 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.269756 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.270986 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.272232 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.273689 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.274779 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.286088 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.287093 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.287982 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.288969 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.289866 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.290945 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.291985 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.292958 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.294919 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.296852 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.297883 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.299419 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.300378 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.302091 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.303536 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.304637 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.306059 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.307271 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.327634 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.328839 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.330344 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.331623 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.332824 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.334149 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.335558 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.336881 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.339501 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.342091 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.343501 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.345306 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.346538 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.348258 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.349935 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.351715 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.353632 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.355518 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.357175 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.365266 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.366414 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.367539 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.368807 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.370117 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.371431 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.372773 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.374045 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.375284 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.376763 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.379374 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.381004 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.383610 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.385258 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.386934 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.388597 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.390505 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.392292 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.394003 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.414973 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.416161 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.417596 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.418888 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.420241 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.421589 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.422966 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.424369 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.425703 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.427476 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.430450 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.432205 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.435165 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.436884 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.438640 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.440572 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.442569 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.444699 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.446748 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.458118 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.459374 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.460745 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.462123 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.463571 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.465017 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.466436 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.468251 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.469716 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.471009 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.473112 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.475161 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.477000 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.479294 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.481432 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.483137 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.485112 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.486886 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.489849 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.510656 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.512031 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.513580 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.515079 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.516777 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.518466 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.519791 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.521580 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.523056 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.524557 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.526647 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.528705 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.530696 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.533001 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.535132 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.537134 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.539375 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.541425 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.544500 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.554428 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.555759 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.557088 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.558583 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.560143 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.561708 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.563273 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.564683 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.566157 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.567920 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.570982 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.572950 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.575998 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.577984 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.580031 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.582000 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.584306 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.586437 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.588487 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.635326 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.636845 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.638496 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.640214 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.642034 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.643854 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.645703 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.647329 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.649064 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.651128 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.654647 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.656958 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.660470 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.662812 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.665274 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.667591 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.670231 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.672851 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.675254 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.688533 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.690087 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.692207 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.693945 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.695600 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.697414 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.699373 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.701171 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.704697 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.708194 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.710155 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.712670 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.714392 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.716791 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.719099 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.721720 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.724407 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.727018 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.729373 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.771678 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.772311 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.772921 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.773544 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.774114 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.774695 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.775258 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.775855 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.776431 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.777089 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.777918 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.778671 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.779362 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.780138 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.780979 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.781727 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.782649 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.783495 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.921416 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.933993 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.934946 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.935851 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.936780 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.937694 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.938611 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.939516 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.940461 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.941411 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.942328 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.943161 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.944086 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.945133 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.946266 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.947391 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.948518 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.949800 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.950837 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.952221 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.975871 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.977689 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.980652 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.983429 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.985973 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.988443 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.990880 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.992534 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.994659 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.996416 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526469.998719 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.000923 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.003117 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.004943 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.006602 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.008661 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.011326 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.014130 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.017952 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.021756 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.047330 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.048121 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.048782 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.049484 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.050226 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.051219 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.051949 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.052650 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.053357 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.053997 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.054779 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.055837 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.056771 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.057746 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.058660 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.059616 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.060691 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.062573 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.072403 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.073105 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.073857 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.074608 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.075334 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.076037 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.076738 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.077452 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.078095 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.079107 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.080051 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.080827 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.081749 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.082666 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.083574 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.084732 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.085768 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526470.087685 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.827809 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.828993 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.830123 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.831231 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.832647 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.834036 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.835219 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.836524 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.838207 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.840347 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.841800 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.843773 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.845809 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.848047 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.850273 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.854058 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.858325 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.871107 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.874391 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.877728 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.881325 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.884921 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.889013 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.893424 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.898334 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.903579 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.908738 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.913843 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.920494 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.926383 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.932529 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.938542 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.945086 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.957728 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.969215 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.981896 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526547.996204 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.004479 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.012709 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.037990 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.079768 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.089435 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.095379 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.101344 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.110393 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.116798 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.123772 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.130843 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.137809 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.145710 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.154619 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.164073 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.173743 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.183795 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.194050 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.205739 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.223377 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.238170 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.253145 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.279109 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.310670 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.323575 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.350825 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.358819 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.366474 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.373688 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.383497 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.396087 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.405676 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.416150 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.426962 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.437532 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.448377 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.459915 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.473880 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.488247 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.504925 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.518465 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.534102 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.542720 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.558936 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.577989 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.593720 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.611712 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.620361 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.644077 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.645145 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.646160 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.647143 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.648302 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.649374 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.650852 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.652344 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.653834 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.655200 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.656524 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.657842 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.659138 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.660578 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.662186 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.664112 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.666033 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.668026 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.669867 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.671709 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.674773 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.697062 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.698377 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.699636 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.700879 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.702331 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.703838 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.705943 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.708026 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.710129 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.711983 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.713791 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.715586 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.717365 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.719286 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.721509 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.724078 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.726732 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.729148 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.731666 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.734154 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.738330 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.751116 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.751962 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.752700 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.754248 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.755956 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.757586 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.759276 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.760965 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.762558 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.763338 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.765026 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.767144 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.767898 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.770270 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.772568 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.775352 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.778845 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.781628 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.786224 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.789682 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.795626 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.868047 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.868732 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.869358 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.869979 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.870592 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.871302 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.872012 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.872744 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.873396 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.874195 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.874986 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.875775 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.876549 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.877361 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.878224 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.879020 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.880020 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.881324 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.890580 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.895014 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.898978 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.902795 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.907318 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.911719 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.916391 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.921016 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.925675 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.930330 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.936229 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.940466 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.945480 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.952348 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.958708 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.965051 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.970873 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.977389 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.998603 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526548.999453 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.000219 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.001015 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.001808 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.002609 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.003417 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.004202 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.005062 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.005791 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.007408 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.008538 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.010153 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.011125 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.012121 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.013266 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.014439 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.015375 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.026168 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.027049 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.027812 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.028628 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.029389 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.030205 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.031055 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.031865 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.033469 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.035055 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.035907 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.037203 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.038051 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.039404 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.040556 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.041461 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.042568 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.043543 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.062932 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.063992 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.065277 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.066306 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.067215 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.068307 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.069354 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.070340 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.072467 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.074582 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.075632 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.077139 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.078093 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.079470 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.080873 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.082303 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.083858 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.085318 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.086647 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.094352 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.095371 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.096288 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.097315 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.098294 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.099277 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.100296 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.101336 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.102298 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.103505 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.105649 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.107022 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.109154 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.110477 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.111803 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.113226 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.114711 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.116118 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.117501 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.137790 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.138899 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.139994 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.141083 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.142228 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.143331 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.144443 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.145634 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.146713 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.148118 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.150531 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.152000 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.154403 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.155742 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.157134 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.158782 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.160359 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.162038 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.163677 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.175156 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.176293 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.177428 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.178527 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.179725 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.180954 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.182016 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.183455 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.184684 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.185744 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.187315 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.188957 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.190403 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.192177 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.193810 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.195148 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.196663 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.198047 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.200455 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.220851 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.222025 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.223181 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.224285 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.225494 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.226701 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.227817 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.229250 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.230487 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.231674 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.233304 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.234915 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.236558 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.238350 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.239991 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.241544 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.243270 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.244889 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.247376 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.256159 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.257282 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.258327 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.259497 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.260633 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.261772 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.262937 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.264129 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.265243 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.266647 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.269141 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.270787 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.273276 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.274813 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.276369 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.278002 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.279763 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.281400 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.283010 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.328323 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.329555 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.330757 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.332090 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.333387 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.334681 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.336005 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.337371 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.338653 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.340272 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.343076 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.344946 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.347743 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.349565 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.351390 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.353311 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.355380 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.357298 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.359155 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.370802 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.372073 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.373739 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.375079 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.376298 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.377741 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.379136 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.380480 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.383294 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.386084 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.387484 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.389525 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.390828 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.392701 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.394525 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.396582 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.398747 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.400773 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.402637 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.443736 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.444392 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.444951 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.445505 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.446115 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.446688 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.447312 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.447889 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.448438 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.449050 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.449634 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.450221 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.450871 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.451519 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.452215 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.452870 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.453580 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.454272 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.455003 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.465751 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.466557 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.467274 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.468140 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.469024 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.469801 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.470538 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.471435 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.472196 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.472935 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.473789 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.474562 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.475496 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.476418 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.477312 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.478167 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.479046 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.480012 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.481064 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.500685 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.502144 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.504276 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.506431 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.508418 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.510370 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.512231 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.513545 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.514897 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.516480 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.517931 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.520117 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.522297 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.524003 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.525652 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.527303 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.529136 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.531162 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.534294 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.537401 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.558931 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.559736 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.560443 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.561130 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.561765 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.562426 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.563244 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.563827 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.564432 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.565178 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.565866 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.566658 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.567470 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.568236 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.568899 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.569619 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.570454 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.578183 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.578864 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.579516 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.580120 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.580787 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.581449 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.582107 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.582781 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.583421 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.584306 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.585078 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.585732 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.586497 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.587293 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.588066 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.588772 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.589560 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1722526549.591108 3331045 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b66b1e82f9429eaaee8a9ff4c51166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:36:41,273 [INFO] utils.log: [ID TEST] coherency: 0.8116610050201416\n",
      "2024-08-01 17:36:41,280 [INFO] utils.log: [CONCEPTS] redundancy: 0.012612447142601013\n",
      "2024-08-01 17:36:41,292 [INFO] utils.log: [ID TEST RECOVERED] performance of target OOD detector with test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c090b5ecf6c14796bf2f004cf76ff276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d5bfee6ae14dd99236a7210ec8fe01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:38:57,398 [INFO] utils.log: [ID TEST] accuracy with original features: 0.8822905620360552\n",
      "2024-08-01 17:38:57,401 [INFO] utils.log: [ID TEST] accuracy with recovered features: 0.866914103923648\n",
      "2024-08-01 17:38:57,404 [INFO] utils.log: [ID TEST] completeness score: 0.982167892367858\n",
      "2024-08-01 17:38:57,406 [INFO] utils.log: [DETECTION] auroc with original features: 0.9817866433589608\n",
      "2024-08-01 17:38:57,408 [INFO] utils.log: [DETECTION] auroc with recovered features: 0.9773495493107105\n",
      "2024-08-01 17:38:57,410 [INFO] utils.log: [DETECTION] completeness score: 0.990790334042232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# target OOD detector\n",
    "logger.info(\"[ID TEST] performance of target OOD detector with test set...\")\n",
    "in_test_scores, out_test_scores, auroc, fpr, thres95 = run_eval(feature_model, predict_model, in_loader, out_loader, logger, args, N_CLASSES)\n",
    "# in_test_scores, out_test_scores, thres95, auroc = np.random.rand(N_IN), np.random.rand(N_OUT), 0.5419758558273315, 0.955332290562036\n",
    "\n",
    "# Plot ID vs OOD scores by the target detector\n",
    "savefig = os.path.join(args.result_dir, 'plots', '{}_AwA2_test_{}_test.jpg'.format(args.score, args.out_data))\n",
    "plot_stats(in_test_scores, out_test_scores, savename=savefig)\n",
    "\n",
    "######################################\n",
    "## Evaluating coherency......\n",
    "coherency = compute_coherency(in_test_features, topic_vec)\n",
    "logger.info(f'[ID TEST] coherency: {coherency}')\n",
    "\n",
    "######################################\n",
    "## Evaluating redundancy.......\n",
    "redundancy = compute_redundancy(topic_vec)\n",
    "logger.info(f'[CONCEPTS] redundancy: {redundancy}')\n",
    "\n",
    "#######################################\n",
    "## Evaluating the difference between two worlds......\n",
    "y_test = np.argmax(np.load('data/AwA2/y_test.npy'), axis=1) # true labels\n",
    "\n",
    "logger.info(\"[ID TEST RECOVERED] performance of target OOD detector with test set...\")\n",
    "in_test_scores_recov, out_test_scores_recov, auroc_recov, fpr_recov, thres95_recov = run_eval(feature_model, topic_model, in_loader, out_loader, logger, args, N_CLASSES)\n",
    "savefig = os.path.join(args.result_dir, 'plots', '{}_recov_AwA2_test_{}_test.jpg'.format(args.score, args.out_data))\n",
    "plot_stats(in_test_scores_recov, out_test_scores_recov, savename=savefig)\n",
    "\n",
    "# compute completeness scores\n",
    "_, logits_recov, _ = topic_model(in_test_features)\n",
    "in_test_yhat_recov = tf.math.argmax(logits_recov, axis=1).numpy()\n",
    "compute_completeness(y_test, in_test_yhat, in_test_yhat_recov, N_CLASSES, logger)\n",
    "compute_detection_completeness(auroc, auroc_recov, logger)\n",
    "\n",
    "######################################\n",
    "## Compute Hellinger distance between original vs reconstructed classifier outputs\n",
    "in_test_logits_recov = softmax(logits_recov).numpy()\n",
    "H = np.array([hellinger(in_test_logits[i,:], in_test_logits_recov[i,:]) for i in range(in_test_logits.shape[0])])\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "sns.histplot(H, color='blue')\n",
    "ax.legend(['in-distribution (test)'])\n",
    "fig.savefig(os.path.join(args.result_dir, 'plots', 'classification_hellinger.jpg'))\n",
    "plt.close()\n",
    "\n",
    "######################################\n",
    "# Save results....\n",
    "results = {'in_yhat':in_test_yhat, 'out_yhat':out_test_yhat, \n",
    "        'in_yhat_recov':in_test_yhat_recov, \n",
    "        # 'out_yhat_recov':out_test_yhat_recov,\n",
    "        'in_logits':in_test_logits, 'in_logits_recov':in_test_logits_recov,\n",
    "        'in_concepts':in_test_concepts, 'out_concepts':out_test_concepts,\n",
    "        'in_scores':in_test_scores, 'out_scores':out_test_scores,\n",
    "        'thres':thres95,\n",
    "        'in_scores_recov':in_test_scores_recov, 'out_scores_recov':out_test_scores_recov}\n",
    "\n",
    "result_path = os.path.join(args.result_dir,'results_{}_{}.pkl'.format(args.score,args.out_data))\n",
    "with open(result_path,'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b9d6dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:38:58.362222: I tensorflow/core/util/cuda_solvers.cc:178] Creating GpuSolver handles for stream 0x8d437e0\n",
      "2024-08-01 17:38:58,387 [INFO] utils.log: class 0: num IN - 115, num OUT - 31\n",
      "2024-08-01 17:38:58,399 [INFO] utils.log: [CLASS 0: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 1.9156455993652344\n",
      "2024-08-01 17:38:58,405 [INFO] utils.log: class 1: num IN - 14, num OUT - 160\n",
      "2024-08-01 17:38:58,415 [INFO] utils.log: [CLASS 1: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.22074846923351288\n",
      "2024-08-01 17:38:58,417 [INFO] utils.log: class 2: num IN - 11, num OUT - 13\n",
      "2024-08-01 17:38:58,425 [INFO] utils.log: [CLASS 2: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -1385038.0\n",
      "2024-08-01 17:38:58,428 [INFO] utils.log: class 3: num IN - 0, num OUT - 0\n",
      "2024-08-01 17:38:58,437 [INFO] utils.log: [CLASS 3: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: nan\n",
      "2024-08-01 17:38:58,439 [INFO] utils.log: class 4: num IN - 64, num OUT - 26\n",
      "2024-08-01 17:38:58,450 [INFO] utils.log: [CLASS 4: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -85973.609375\n",
      "2024-08-01 17:38:58,452 [INFO] utils.log: class 5: num IN - 92, num OUT - 74\n",
      "2024-08-01 17:38:58,461 [INFO] utils.log: [CLASS 5: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 1.3578208684921265\n",
      "2024-08-01 17:38:58,463 [INFO] utils.log: class 6: num IN - 50, num OUT - 9\n",
      "2024-08-01 17:38:58,488 [INFO] utils.log: [CLASS 6: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 879620.1875\n",
      "2024-08-01 17:38:58,492 [INFO] utils.log: class 7: num IN - 65, num OUT - 23\n",
      "2024-08-01 17:38:58,501 [INFO] utils.log: [CLASS 7: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -117607.171875\n",
      "2024-08-01 17:38:58,505 [INFO] utils.log: class 8: num IN - 98, num OUT - 45\n",
      "2024-08-01 17:38:58,515 [INFO] utils.log: [CLASS 8: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.8122396469116211\n",
      "2024-08-01 17:38:58,531 [INFO] utils.log: class 9: num IN - 217, num OUT - 943\n",
      "2024-08-01 17:38:58,542 [INFO] utils.log: [CLASS 9: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.010592048987746239\n",
      "2024-08-01 17:38:58,544 [INFO] utils.log: class 10: num IN - 60, num OUT - 26\n",
      "2024-08-01 17:38:58,553 [INFO] utils.log: [CLASS 10: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 104998.3125\n",
      "2024-08-01 17:38:58,555 [INFO] utils.log: class 11: num IN - 139, num OUT - 94\n",
      "2024-08-01 17:38:58,562 [INFO] utils.log: [CLASS 11: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.3012036681175232\n",
      "2024-08-01 17:38:58,564 [INFO] utils.log: class 12: num IN - 113, num OUT - 105\n",
      "2024-08-01 17:38:58,572 [INFO] utils.log: [CLASS 12: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.15636447072029114\n",
      "2024-08-01 17:38:58,573 [INFO] utils.log: class 13: num IN - 122, num OUT - 14\n",
      "2024-08-01 17:38:58,581 [INFO] utils.log: [CLASS 13: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 1.9128520488739014\n",
      "2024-08-01 17:38:58,584 [INFO] utils.log: class 14: num IN - 67, num OUT - 7\n",
      "2024-08-01 17:38:58,595 [INFO] utils.log: [CLASS 14: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 2153783.25\n",
      "2024-08-01 17:38:58,598 [INFO] utils.log: class 15: num IN - 111, num OUT - 251\n",
      "2024-08-01 17:38:58,607 [INFO] utils.log: [CLASS 15: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.1320992261171341\n",
      "2024-08-01 17:38:58,609 [INFO] utils.log: class 16: num IN - 88, num OUT - 0\n",
      "2024-08-01 17:38:58,618 [INFO] utils.log: [CLASS 16: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: nan\n",
      "2024-08-01 17:38:58,620 [INFO] utils.log: class 17: num IN - 122, num OUT - 104\n",
      "2024-08-01 17:38:58,629 [INFO] utils.log: [CLASS 17: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.22050458192825317\n",
      "2024-08-01 17:38:58,632 [INFO] utils.log: class 18: num IN - 91, num OUT - 1\n",
      "2024-08-01 17:38:58,647 [INFO] utils.log: [CLASS 18: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 164073.984375\n",
      "2024-08-01 17:38:58,649 [INFO] utils.log: class 19: num IN - 95, num OUT - 41\n",
      "2024-08-01 17:38:58,660 [INFO] utils.log: [CLASS 19: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 1.0614967346191406\n",
      "2024-08-01 17:38:58,662 [INFO] utils.log: class 20: num IN - 82, num OUT - 34\n",
      "2024-08-01 17:38:58,671 [INFO] utils.log: [CLASS 20: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 1.1291718482971191\n",
      "2024-08-01 17:38:58,673 [INFO] utils.log: class 21: num IN - 68, num OUT - 89\n",
      "2024-08-01 17:38:58,685 [INFO] utils.log: [CLASS 21: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.8020591735839844\n",
      "2024-08-01 17:38:58,688 [INFO] utils.log: class 22: num IN - 192, num OUT - 239\n",
      "2024-08-01 17:38:58,699 [INFO] utils.log: [CLASS 22: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.0577738918364048\n",
      "2024-08-01 17:38:58,702 [INFO] utils.log: class 23: num IN - 90, num OUT - 168\n",
      "2024-08-01 17:38:58,714 [INFO] utils.log: [CLASS 23: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.1298947036266327\n",
      "2024-08-01 17:38:58,716 [INFO] utils.log: class 24: num IN - 21, num OUT - 6\n",
      "2024-08-01 17:38:58,727 [INFO] utils.log: [CLASS 24: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 6394804.0\n",
      "2024-08-01 17:38:58,729 [INFO] utils.log: class 25: num IN - 75, num OUT - 0\n",
      "2024-08-01 17:38:58,743 [INFO] utils.log: [CLASS 25: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: nan\n",
      "2024-08-01 17:38:58,746 [INFO] utils.log: class 26: num IN - 113, num OUT - 15\n",
      "2024-08-01 17:38:58,758 [INFO] utils.log: [CLASS 26: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 2.2403647899627686\n",
      "2024-08-01 17:38:58,761 [INFO] utils.log: class 27: num IN - 2, num OUT - 4\n",
      "2024-08-01 17:38:58,773 [INFO] utils.log: [CLASS 27: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 77958800.0\n",
      "2024-08-01 17:38:58,776 [INFO] utils.log: class 28: num IN - 62, num OUT - 544\n",
      "2024-08-01 17:38:58,790 [INFO] utils.log: [CLASS 28: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.09605389833450317\n",
      "2024-08-01 17:38:58,793 [INFO] utils.log: class 29: num IN - 1, num OUT - 3\n",
      "2024-08-01 17:38:58,808 [INFO] utils.log: [CLASS 29: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 148692128.0\n",
      "2024-08-01 17:38:58,812 [INFO] utils.log: class 30: num IN - 66, num OUT - 59\n",
      "2024-08-01 17:38:58,826 [INFO] utils.log: [CLASS 30: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 1.0238170623779297\n",
      "2024-08-01 17:38:58,829 [INFO] utils.log: class 31: num IN - 93, num OUT - 1\n",
      "2024-08-01 17:38:58,841 [INFO] utils.log: [CLASS 31: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -78807.8125\n",
      "2024-08-01 17:38:58,843 [INFO] utils.log: class 32: num IN - 73, num OUT - 27\n",
      "2024-08-01 17:38:58,854 [INFO] utils.log: [CLASS 32: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -27576.79296875\n",
      "2024-08-01 17:38:58,856 [INFO] utils.log: class 33: num IN - 63, num OUT - 26\n",
      "2024-08-01 17:38:58,868 [INFO] utils.log: [CLASS 33: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -73632.5625\n",
      "2024-08-01 17:38:58,870 [INFO] utils.log: class 34: num IN - 89, num OUT - 15\n",
      "2024-08-01 17:38:58,881 [INFO] utils.log: [CLASS 34: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 49.88197326660156\n",
      "2024-08-01 17:38:58,883 [INFO] utils.log: class 35: num IN - 112, num OUT - 3\n",
      "2024-08-01 17:38:58,893 [INFO] utils.log: [CLASS 35: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 9.229970932006836\n",
      "2024-08-01 17:38:58,896 [INFO] utils.log: class 36: num IN - 32, num OUT - 41\n",
      "2024-08-01 17:38:58,914 [INFO] utils.log: [CLASS 36: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -21636.7421875\n",
      "2024-08-01 17:38:58,916 [INFO] utils.log: class 37: num IN - 14, num OUT - 2\n",
      "2024-08-01 17:38:58,931 [INFO] utils.log: [CLASS 37: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -9399008.0\n",
      "2024-08-01 17:38:58,936 [INFO] utils.log: class 38: num IN - 80, num OUT - 17\n",
      "2024-08-01 17:38:58,946 [INFO] utils.log: [CLASS 38: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -15771.265625\n",
      "2024-08-01 17:38:58,948 [INFO] utils.log: class 39: num IN - 121, num OUT - 254\n",
      "2024-08-01 17:38:58,962 [INFO] utils.log: [CLASS 39: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.07161538302898407\n",
      "2024-08-01 17:38:58,964 [INFO] utils.log: class 40: num IN - 148, num OUT - 98\n",
      "2024-08-01 17:38:58,976 [INFO] utils.log: [CLASS 40: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.21713300049304962\n",
      "2024-08-01 17:38:58,979 [INFO] utils.log: class 41: num IN - 45, num OUT - 7\n",
      "2024-08-01 17:38:58,990 [INFO] utils.log: [CLASS 41: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -203217.3125\n",
      "2024-08-01 17:38:58,992 [INFO] utils.log: class 42: num IN - 18, num OUT - 0\n",
      "2024-08-01 17:38:59,003 [INFO] utils.log: [CLASS 42: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: nan\n",
      "2024-08-01 17:38:59,006 [INFO] utils.log: class 43: num IN - 21, num OUT - 29\n",
      "2024-08-01 17:38:59,017 [INFO] utils.log: [CLASS 43: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -404072.71875\n",
      "2024-08-01 17:38:59,020 [INFO] utils.log: class 44: num IN - 124, num OUT - 52\n",
      "2024-08-01 17:38:59,031 [INFO] utils.log: [CLASS 44: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 0.5270399451255798\n",
      "2024-08-01 17:38:59,033 [INFO] utils.log: class 45: num IN - 89, num OUT - 2\n",
      "2024-08-01 17:38:59,044 [INFO] utils.log: [CLASS 45: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 295260.625\n",
      "2024-08-01 17:38:59,047 [INFO] utils.log: class 46: num IN - 7, num OUT - 38\n",
      "2024-08-01 17:38:59,058 [INFO] utils.log: [CLASS 46: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 479725.125\n",
      "2024-08-01 17:38:59,060 [INFO] utils.log: class 47: num IN - 22, num OUT - 4\n",
      "2024-08-01 17:38:59,072 [INFO] utils.log: [CLASS 47: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: -34301304.0\n",
      "2024-08-01 17:38:59,074 [INFO] utils.log: class 48: num IN - 63, num OUT - 23\n",
      "2024-08-01 17:38:59,088 [INFO] utils.log: [CLASS 48: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 23613.5078125\n",
      "2024-08-01 17:38:59,090 [INFO] utils.log: class 49: num IN - 120, num OUT - 5\n",
      "2024-08-01 17:38:59,103 [INFO] utils.log: [CLASS 49: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: 5.230999946594238\n",
      "2024-08-01 17:38:59,106 [INFO] utils.log: [GLOBAL SEPARABILITY] multivariate separability: 0.002089481567963958\n",
      "2024-08-01 17:38:59,108 [INFO] utils.log: [PER-CLASS SEPARABILIRY] averaged separability: 4152896.516159597\n",
      "2024-08-01 17:38:59,126 [INFO] utils.log: [RELATIVE SEPARABILITY] relative separability: 1.1133884191513062\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "## Evaluating separability of concepts......\n",
    "#separa_path = os.path.join(args.result_dir, 'separability_AwA2_{}_raw.npy'.format(args.out_data))\n",
    "separa_path = os.path.join(args.result_dir, 'separability_{}_AwA2_{}_multiv.npy'.format(args.score, args.out_data))\n",
    "if args.separate:\n",
    "    idx_IN_IN = in_test_scores >= thres95\n",
    "    idx_IN_OUT = ~idx_IN_IN\n",
    "    idx_OUT_IN = out_test_scores >= thres95\n",
    "    idx_OUT_OUT = ~idx_OUT_IN\n",
    "    # separa = compute_separability(in_test_concepts, out_test_concepts, in_test_yhat, out_test_yhat, logger) # using groundtruth ID/OOD labels\n",
    "    in_detect_concepts = np.r_[in_test_concepts[idx_IN_IN], out_test_concepts[idx_OUT_IN]]\n",
    "    out_detect_concepts = np.r_[in_test_concepts[idx_IN_OUT], out_test_concepts[idx_OUT_OUT]]\n",
    "    in_detect_yhat = np.r_[in_test_yhat[idx_IN_IN], out_test_yhat[idx_OUT_IN]]\n",
    "    out_detect_yhat = np.r_[in_test_yhat[idx_IN_OUT], out_test_yhat[idx_OUT_OUT]]\n",
    "    separa = compute_separability(in_detect_concepts, out_detect_concepts, in_detect_yhat, out_detect_yhat, N_CLASSES, logger) # using detector's ID/OOD results in canonical world\n",
    "\n",
    "    separa_global = separa['global']\n",
    "    logger.info(f'[GLOBAL SEPARABILITY] multivariate separability: {separa_global}')\n",
    "    separa_class = np.array([separa['class'+str(i)] for i in range(N_CLASSES)], dtype=np.float64)\n",
    "    logger.info(f'[PER-CLASS SEPARABILIRY] averaged separability: {np.nanmean(separa_class)}')\n",
    "\n",
    "    rlt_dir_ = []\n",
    "    for p_ in args.result_dir.split(\"/\"):        \n",
    "        if \"AwA2\" in p_:\n",
    "            rlt_dir_ += [\"AwA2_1_baseline_s0\"]\n",
    "        elif \"epoch\" in p_:\n",
    "            rlt_dir_ += [f\"epoch_40_{args.concept_sim_thr}\"]\n",
    "        else:\n",
    "            rlt_dir_ += [p_]\n",
    "    baseline_folder = \"/\".join(rlt_dir_)\n",
    "\n",
    "    separa0_path = os.path.join(baseline_folder, 'separability_{}_AwA2_{}_multiv.npy'.format(args.score, args.out_data))\n",
    "    if os.path.exists(separa0_path):\n",
    "        import statistics \n",
    "        separa0 = np.load(separa0_path, allow_pickle=True).item()\n",
    "        rel_separa_list = []\n",
    "        for i in range(N_CLASSES):\n",
    "            if np.isnan(separa0['class'+str(i)]) or np.isnan(separa['class'+str(i)]):\n",
    "                continue\n",
    "            else:\n",
    "                rel_ = (separa['class'+str(i)] - separa0['class'+str(i)]) / separa0['class'+str(i)]\n",
    "                rel_separa_list.append(rel_)\n",
    "        rel_separa = statistics.median(rel_separa_list)\n",
    "        logger.info(f'[RELATIVE SEPARABILITY] relative separability: {rel_separa}')\n",
    "        separa['relative'] = rel_separa\n",
    "\n",
    "    np.save(separa_path, separa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c189e19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:38:59,172 [INFO] utils.log: classes with highest and lowest separabilities...: [29 27 24 14  6 46 45 18 10 48 34 35 49 26  0 13  5 20 19 30  8 21 44 11\n",
      "  1 17 40 12 15 23 28 39 22  9 38 36 32 33 31  4  7 41 43  2 37 47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shap values from file results/AwA2_1_feat_l2_0.1_ood_1_sep_50_s0/epoch_40_0.95/explanations/Places_energy/energy_SHAP.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating explanations.....\n",
    "classes = np.argsort(separa_class)[::-1]\n",
    "#classes = np.append(classes[:5],[c for c in classes[-9:] if separa_class[c]]) # omitting classes with separability==0\n",
    "classes = np.delete(classes, np.where(np.isnan(separa_class[classes]))[0])\n",
    "\n",
    "if args.explain:\n",
    "    logger.info(f'classes with highest and lowest separabilities...: {classes}')\n",
    "    k = 10\n",
    "    for i in range(N_CLASSES):\n",
    "\n",
    "        idx_in = np.where(in_test_yhat == i)[0]\n",
    "        idx_out = np.where(out_test_yhat == i)[0]\n",
    "        in_concepts_ith = in_test_concepts[idx_in,:] # concept scores of ID data classified as class i\n",
    "        out_concepts_ith = out_test_concepts[idx_out,:] # concept scores of OOD data classified as class i\n",
    "        \n",
    "        if len(idx_in) == 0 or len(idx_out) ==0:\n",
    "            continue\n",
    "\n",
    "        # indices for OOD detection results\n",
    "        idx_IN_IN = in_test_scores[idx_in] >= thres95   # ID detected as ID\n",
    "        idx_IN_OUT = ~idx_IN_IN                 # ID detected as OOD\n",
    "        idx_OUT_OUT = out_test_scores[idx_out] < thres95 # OOD detected as OOD\n",
    "        idx_OUT_IN = ~idx_OUT_OUT               # OOD detected as ID\n",
    "\n",
    "        # print(np.sum(idx_IN_IN))\n",
    "        # print(np.sum(idx_IN_OUT))\n",
    "        # print(np.sum(idx_OUT_OUT))\n",
    "        # print(np.sum(idx_OUT_IN))\n",
    "        \n",
    "        explain_topK(in_concepts_ith, top_k=k, separa=separa_class[i], \n",
    "                    figname=os.path.join(explain_dir,'class{}_AwA2_top{}.jpg'.format(i, k)))\n",
    "        explain_topK(out_concepts_ith, top_k=k, separa=separa_class[i],\n",
    "                    figname=os.path.join(explain_dir,'class{}_{}_top{}.jpg'.format(i, args.out_data, k)))\n",
    "\n",
    "\n",
    "        # # most prominent concepts for ID/OOD images\n",
    "        # explain_topK(np.r_[in_concepts_ith[idx_IN_IN], out_concepts_ith[idx_OUT_IN]], top_k=k, separa=separa_class[i],\n",
    "        #             figname=os.path.join(explain_dir,'class{}_AwA2_top{}_detected_{}.jpg'.format(i, k, args.score)))\n",
    "        # explain_topK(np.r_[in_concepts_ith[idx_IN_OUT], out_concepts_ith[idx_OUT_OUT]], top_k=k, separa=separa_class[i],\n",
    "        #             figname=os.path.join(explain_dir,'class{}_{}_top{}_detected_{}.jpg'.format(i, args.out_data, k, args.score)))\n",
    "        \n",
    "        \n",
    "        # visualize example ID/OOD images\n",
    "        in_files_ith = np.array(in_loader.filepaths)[idx_in]\n",
    "        out_files_ith = np.array(out_loader.filepaths)[idx_out]\n",
    "        if np.sum(idx_IN_IN)!=0:\n",
    "            save_images(in_files_ith[idx_IN_IN], figname=os.path.join(explain_dir,'class{}_{}_AwA2_IN.jpg'.format(i, args.score)))\n",
    "        if np.sum(idx_IN_OUT)!=0:\n",
    "            save_images(in_files_ith[idx_IN_OUT], figname=os.path.join(explain_dir,'class{}_{}_AwA2_OUT.jpg'.format(i, args.score)))\n",
    "        if np.sum(idx_OUT_OUT)!=0:\n",
    "            save_images(out_files_ith[idx_OUT_OUT], figname=os.path.join(explain_dir,'class{}_{}_{}_OUT.jpg'.format(i, args.score, args.out_data)))\n",
    "        if np.sum(idx_OUT_IN)!=0:\n",
    "            save_images(out_files_ith[idx_OUT_IN], figname=os.path.join(explain_dir,'class{}_{}_{}_IN.jpg'.format(i, args.score, args.out_data)))\n",
    "logger.flush()\n",
    "\n",
    "\n",
    "###########################################\n",
    "## Computing ConceptSHAP.............\n",
    "        \n",
    "if args.shap:\n",
    "\n",
    "    shap_path = os.path.join(explain_dir,'{}_SHAP.pkl'.format(args.score.lower()))\n",
    "    if os.path.exists(shap_path):\n",
    "        print(f\"Loading shap values from file {shap_path}\")\n",
    "        with open(shap_path,'rb') as f:\n",
    "            shap_expl = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        nc = N_CONCEPTS_ORIG # number of concepts before duplicate removal\n",
    "        #inputs = list(itertools.product([0, 1], repeat=N_CONCEPTS_ORIG)) #NOTE: computationally very expensive\n",
    "        inputs = np.ones((len(dict_dupl_topic),nc))\n",
    "        for d in dict_dupl_topic:\n",
    "            idx = [d] + dict_dupl_topic[d]\n",
    "            inputs[d,idx] = 0\n",
    "        inputs = np.unique([tuple(row) for row in inputs], axis=0)\n",
    "        # inputs = inputs[:2]\n",
    "\n",
    "        #classes = [1, 4]\n",
    "        outputs_class = np.array([])\n",
    "        outputs_detect = np.array([])\n",
    "        kernel = np.array([])\n",
    "        for concept_mask in inputs:\n",
    "            logger.info('======================================================')\n",
    "            compl_class, compl_detect = compute_conceptSHAP(concept_mask, topic_vec_orig,\n",
    "                                        in_test_features, out_test_features, y_test, in_test_yhat, out_test_yhat, auroc,\n",
    "                                        in_loader, out_loader,\n",
    "                                        topic_model, feature_model, args, logger,\n",
    "                                        finetune=False, labels=list(range(N_CLASSES)))\n",
    "            outputs_class = np.append(outputs_class, compl_class)\n",
    "            outputs_detect = np.append(outputs_detect, compl_detect)\n",
    "            k = np.sum(concept_mask)\n",
    "            kernel = np.append(kernel, (nc-1)*1.0/((nc-k)*k*comb(nc, k)))\n",
    "\n",
    "        outputs_class = outputs_class.reshape(-1,N_CLASSES)\n",
    "        outputs_detect = outputs_detect.reshape(-1,N_CLASSES)\n",
    "        kernel[kernel == np.inf] = 1e+4\n",
    "        x = np.array(inputs)\n",
    "        xkx = np.matmul(np.matmul(x.transpose(), np.diag(kernel)), x)\n",
    "        shap_expl = {'mask': inputs}\n",
    "        for i in range(N_CLASSES):\n",
    "            xky_class = np.matmul(np.matmul(x.transpose(), np.diag(kernel)), outputs_class[:,i])\n",
    "            shap_class = np.matmul(np.linalg.pinv(xkx), xky_class)\n",
    "            shap_expl[f'shap_class_class{i}'] = shap_class\n",
    "\n",
    "            idx = ~np.isnan(outputs_detect[:,i].astype(float))\n",
    "            xkx_detect = np.matmul(np.matmul(x[idx,:].T, np.diag(kernel[idx])), x[idx,:])\n",
    "            xky_detect = np.matmul(np.matmul(x[idx,:].T, np.diag(kernel[idx])), outputs_detect[idx,i])\n",
    "            shap_detect = np.matmul(np.linalg.pinv(xkx), xky_detect)\n",
    "            shap_expl[f'shap_detect_class{i}'] = shap_detect\n",
    "            shap_expl[f'mask_detect_class{i}'] = x[idx,:]\n",
    "\n",
    "        print(f\"Saving shap values to file {shap_path}\")\n",
    "        with open(shap_path,'wb') as f:\n",
    "            pickle.dump(shap_expl, f)\n",
    "\n",
    "# concept_dict = prepare_profiles(feature_model, topic_vec, N_CLASSES, args, logger)\n",
    "\n",
    "# if args.plot:\n",
    "#     log_path = '{}/{}'.format(args.logdir, args.name)\n",
    "#     plot_score_distr(concept_dict, in_test_concepts, in_test_yhat, out_test_concepts, out_test_yhat, save_plot=log_path)\n",
    "\n",
    "logger.flush()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23c859f5-7788-467b-96af-dab1d89b2dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mask': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class27': array([ 0.00327996,  0.35119053,  0.11925015, -0.11269022, -0.11269022,\n",
       "         0.11925015,  0.00327996,  0.00327996,  0.11925015,  0.00327996,\n",
       "        -0.11269022, -0.11269022,  0.35119053, -0.11269022, -0.22866041,\n",
       "        -0.11269022,  0.00327996,  0.00327996,  0.11925015,  0.00327996,\n",
       "        -0.11269022, -0.11269022,  0.11925015,  0.00327996,  0.00327996,\n",
       "         0.11925015,  0.00327996, -0.11269022,  0.00327996,  0.11925015,\n",
       "         0.11925015, -0.22866041, -0.11269022,  0.00327996, -0.11269022,\n",
       "        -0.11269022,  0.00327996,  0.00327996,  0.00327996, -0.11269022,\n",
       "        -0.11269022, -0.11269022,  0.00327996,  0.11925015,  0.11925015,\n",
       "         0.00327996, -0.11269022,  0.11925015,  0.11925015, -0.11269022,\n",
       "         0.00327996, -0.11269022,  0.00327996,  0.11925015,  0.00327996,\n",
       "         0.00327996, -0.11269022,  0.00327996,  0.11925015,  0.00327996,\n",
       "        -0.11269022,  0.00327996, -0.11269022,  0.11925015,  0.00327996,\n",
       "         0.00327996,  0.11925015,  0.00327996,  0.11925015, -0.11269022,\n",
       "        -0.11269022, -0.11269022,  0.11925015,  0.11925015,  0.11925015,\n",
       "         0.00327996,  0.23522034, -0.11269022,  0.00327996,  0.00327996,\n",
       "         0.11925015, -0.11269022,  0.00327996, -0.11269022,  0.00327996,\n",
       "         0.11925015,  0.00327996,  0.00327996,  0.00327996,  0.11925015,\n",
       "         0.00327996,  0.00327996,  0.11925015, -0.11269022,  0.00327996,\n",
       "         0.11925015,  0.00327996,  0.00327996,  0.00327996, -0.11269022]),\n",
       " 'shap_detect_class27': array([0.05241432485018609, 0.05241432485073609, 0.05241432485147784,\n",
       "        0.05241432485140648, 0.052414324850745486, 0.05241432485053062,\n",
       "        0.05241432485072991, 0.05241432485112047, 0.05241432485080869,\n",
       "        0.05241432485102933, 0.05241432485104968, 0.0524143248510309,\n",
       "        0.052414324851279594, 0.05241432485166504, 0.052414324851019455,\n",
       "        0.05241432485078923, 0.05241432485090953, -0.9853893071980805,\n",
       "        0.05241432485097292, 0.05241432485092765, 0.052414324850984496,\n",
       "        0.052414324850943564, 0.052414324850941746, 0.05241432485099636,\n",
       "        0.05241432485095024, 0.05241432485091841, 0.052414324850989104,\n",
       "        0.052414324850989825, 0.0524143248509046, 0.052414324850908106,\n",
       "        -0.9853893071981022, 0.052414324850992795, 0.052414324850955436,\n",
       "        0.052414324850929346, 0.0524143248509722, 0.05241432485099478,\n",
       "        0.05241432485094901, 0.05241432485094991, 0.05241432485097133,\n",
       "        0.052414324850997875, 0.052414324850947734, 0.05241432485093752,\n",
       "        0.05241432485099029, 0.052414324850997576, 0.05241432485094758,\n",
       "        0.05241432485094403, 0.0524143248510129, 0.05241432485097738,\n",
       "        0.05241432485095465, 0.05241432485095812, 0.052414324850966955,\n",
       "        0.05241432485100248, 0.05241432485093526, 0.052414324850954847,\n",
       "        0.052414324850983886, 0.05241432485097012, 0.052414324850936084,\n",
       "        0.05241432485096756, 0.05241432485097653, 0.052414324850967225,\n",
       "        -0.9853893071981105, 0.05241432485093476, 0.052414324850983934,\n",
       "        0.05241432485099588, 0.05241432485093269, 0.05241432485096744,\n",
       "        0.052414324850974976, 0.05241432485100136, 0.0524143248509287,\n",
       "        0.05241432485096997, 0.052414324850984136, -0.9853893071980412,\n",
       "        0.05241432485092842, 0.05241432485096834, 0.052414324850976295,\n",
       "        0.05241432485099564, 0.052414324850932184, 0.05241432485096543,\n",
       "        0.05241432485097876, 0.05241432485100037, 0.052414324850949406,\n",
       "        0.05241432485096991, 0.05241432485097826, 0.05241432485099317,\n",
       "        0.05241432485100459, 0.05241432485094877, 0.052414324850971444,\n",
       "        0.052414324850994586, 0.052414324851006874, 0.052414324850982484,\n",
       "        0.052414324851030376, 0.05241432485099281, 0.052414324851004536,\n",
       "        0.05241432485098396, 0.05241432485100992, 0.052414324850993975,\n",
       "        0.05241432485102982, -0.985389307198257, 0.05241432485059446,\n",
       "        0.05241432485076025], dtype=object),\n",
       " 'mask_detect_class27': array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1.]]),\n",
       " 'shap_class_class2': array([-0.0306911 ,  0.25923437,  0.08527909, -0.0306911 , -0.0306911 ,\n",
       "         0.20124928, -0.0306911 ,  0.02729399,  0.02729399, -0.0306911 ,\n",
       "        -0.0306911 , -0.0306911 ,  0.54915985, -0.0306911 , -0.14666129,\n",
       "         0.02729399,  0.02729399, -0.0306911 ,  0.08527909,  0.02729399,\n",
       "         0.02729399,  0.08527909, -0.0306911 , -0.0306911 , -0.0886762 ,\n",
       "        -0.0306911 , -0.0306911 ,  0.02729399, -0.0306911 , -0.0306911 ,\n",
       "         0.02729399,  0.08527909, -0.0306911 , -0.0306911 , -0.0306911 ,\n",
       "         0.08527909,  0.08527909, -0.0306911 ,  0.02729399,  0.02729399,\n",
       "        -0.0306911 ,  0.02729399, -0.0306911 ,  0.02729399, -0.0306911 ,\n",
       "         0.14326418, -0.0306911 , -0.0306911 , -0.0306911 ,  0.02729399,\n",
       "        -0.0886762 ,  0.02729399, -0.0306911 , -0.0306911 , -0.0306911 ,\n",
       "        -0.0306911 , -0.0306911 ,  0.02729399, -0.14666129, -0.0306911 ,\n",
       "        -0.0306911 ,  0.02729399, -0.0306911 , -0.0306911 , -0.0306911 ,\n",
       "        -0.0306911 , -0.0306911 , -0.0306911 ,  0.02729399,  0.08527909,\n",
       "        -0.0306911 , -0.0306911 , -0.0306911 ,  0.02729399, -0.0306911 ,\n",
       "        -0.0306911 , -0.0886762 ,  0.02729399, -0.0306911 , -0.0306911 ,\n",
       "        -0.0306911 , -0.0306911 ,  0.02729399, -0.0306911 ,  0.14326418,\n",
       "        -0.0306911 , -0.0306911 ,  0.08527909, -0.0306911 , -0.0886762 ,\n",
       "         0.02729399, -0.0306911 , -0.0306911 ,  0.02729399,  0.02729399,\n",
       "         0.08527909, -0.0306911 ,  0.02729399,  0.08527909,  0.02729399]),\n",
       " 'shap_detect_class2': array([-0.3398271028535105, 0.6979765292035809, 0.6979765292160791,\n",
       "        -0.3398271028427967, -0.33982710284247075, 0.6979765292087754,\n",
       "        -0.30837850793462274, 0.6979765292024328, -0.33982710284739515,\n",
       "        -0.3398271028472286, -0.3398271028446842, -0.33982710284593354,\n",
       "        0.6979765292025785, -0.33982710284807494, -0.3089400899868636,\n",
       "        0.6979765292050021, 0.697976529204098, -0.3398271028447163,\n",
       "        0.6979765292036291, 0.6979765292037977, -0.3398271028448785,\n",
       "        0.6979765292040135, -0.3398271028454799, -0.33982710284549755,\n",
       "        -0.32253037564403586, -0.33982710284458384, -0.31624065666241863,\n",
       "        0.6979765292035525, -0.33982710284462314, -0.33982710284458406,\n",
       "        0.6979765292035852, 0.6979765292036324, -0.3398271028447595,\n",
       "        -0.33982710284454765, -0.27064019404183304, 0.6979765292035238,\n",
       "        0.6979765292042441, 0.6979765292040787, 0.697976529203935,\n",
       "        -0.3398271028454499, -0.33982710284487205, 0.6979765292041592,\n",
       "        -0.3398271028455483, 0.6979765292035375, -0.3398271028449016,\n",
       "        -0.3398271028450226, -0.339827102845745, -0.3398271028453548,\n",
       "        -0.33982710284475914, 0.6979765292041941, -0.3398271028453954,\n",
       "        0.6979765292035125, -0.3398271028447257, -0.33982710284511286,\n",
       "        -0.339827102845374, -0.3398271028454608, -0.2879369212422622,\n",
       "        -0.3398271028448968, -0.1951635662567004, -0.33982710284547235,\n",
       "        0.6979765292042694, -0.33982710284475715, -0.33982710284539885,\n",
       "        -0.3398271028455656, -0.33982710284471584, -0.3398271028448929,\n",
       "        -0.31886137290499383, -0.3398271028455201, -0.3398271028447484,\n",
       "        0.6979765292041549, -0.3398271028453844, 0.6979765292035108,\n",
       "        0.697976529204249, 0.6979765292041437, -0.33982710284534645,\n",
       "        -0.3398271028455725, -0.29658528484268176, 0.6979765292041176,\n",
       "        -0.33982710284529916, -0.3398271028455353, -0.339827102845066,\n",
       "        -0.33982710284484174, -0.33982710284534334, 0.6979765292035388,\n",
       "        0.6979765292035265, -0.3398271028456097, -0.33982710284530493,\n",
       "        0.6979765292035548, -0.33982710284555795, -0.3398271028453955,\n",
       "        0.6979765292035486, -0.33982710284535367, -0.33982710284555795,\n",
       "        -0.3398271028453388, 0.6979765292037882, -0.3398271028453851,\n",
       "        -0.33982710284546425, -0.3398271028426936, 0.6979765292077525,\n",
       "        -0.33982710284148254], dtype=object),\n",
       " 'mask_detect_class2': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class31': array([-0.01115695,  0.035858  , -0.01115695, -0.01115695,  0.0045147 ,\n",
       "        -0.01115695, -0.01115695,  0.0045147 , -0.01115695, -0.01115695,\n",
       "         0.035858  , -0.07384354,  0.02018635,  0.0045147 , -0.01115695,\n",
       "        -0.01115695,  0.035858  ,  0.02018635,  0.02018635, -0.02682859,\n",
       "        -0.01115695, -0.01115695, -0.02682859,  0.0045147 , -0.01115695,\n",
       "        -0.01115695, -0.04250024, -0.01115695, -0.02682859,  0.035858  ,\n",
       "        -0.04250024,  0.035858  , -0.02682859, -0.02682859, -0.01115695,\n",
       "         0.0045147 , -0.01115695,  0.035858  , -0.01115695,  0.02018635,\n",
       "         0.02018635,  0.05152964,  0.05152964,  0.0045147 , -0.01115695,\n",
       "        -0.05817189, -0.02682859,  0.02018635, -0.01115695, -0.01115695,\n",
       "        -0.05817189,  0.035858  , -0.02682859, -0.02682859,  0.02018635,\n",
       "         0.02018635,  0.035858  , -0.01115695,  0.02018635, -0.01115695,\n",
       "         0.035858  ,  0.035858  , -0.01115695, -0.02682859,  0.035858  ,\n",
       "         0.035858  ,  0.035858  , -0.05817189, -0.04250024, -0.01115695,\n",
       "         0.035858  ,  0.035858  , -0.02682859, -0.01115695, -0.01115695,\n",
       "         0.035858  , -0.08951518,  0.99182848, -0.01115695, -0.12085848,\n",
       "        -0.04250024,  0.02018635,  0.0045147 ,  0.035858  , -0.05817189,\n",
       "        -0.01115695, -0.02682859,  0.05152964,  0.05152964,  0.02018635,\n",
       "        -0.01115695, -0.01115695,  0.02018635, -0.01115695,  0.035858  ,\n",
       "         0.035858  , -0.01115695,  0.08287294,  0.035858  ,  0.035858  ]),\n",
       " 'shap_detect_class31': array([-0.20949246924944964, 0.6120293974682667, -0.02517903750015693,\n",
       "        -0.13027786413600317, 0.03214216031388395, -0.1433786884414472,\n",
       "        -0.05273882766469473, 0.03876643881714448, -0.12411107565760804,\n",
       "        -0.09331765980746265, 0.07178746347333786, -0.06409551409444736,\n",
       "        -0.05298141850910698, -0.055910383755906956, 0.07900780414122754,\n",
       "        0.0020108935166104347, 0.23540291646821687, -0.10609365148984906,\n",
       "        0.038766438817068316, -0.1614562821136145, -0.147427742227196,\n",
       "        0.05520689239392218, -0.10133705150950645, 0.1261604288843422,\n",
       "        -0.08283479483732625, -0.06924985758006708, -0.0374803586396083,\n",
       "        0.06115043872401604, -0.06433562136051141, 0.0900735846710723,\n",
       "        -0.15854437517734155, 0.061828741751541294, 0.02045225707491438,\n",
       "        0.06841797116118786, 0.019508227088331664, -0.1065260696697955,\n",
       "        0.019508227088179897, 0.09122684219528743, 0.015468806260872103,\n",
       "        -0.07877691162288136, 0.12580803376297967, 0.468368872548949,\n",
       "        0.4294689826472513, -0.030420469986210286, -0.16268956034553073,\n",
       "        -0.15232121406831245, -0.17286410575760536, 0.008809220572374099,\n",
       "        -0.10101935652025762, 0.05160524663614863, 0.18405894730386507,\n",
       "        0.20151291747934186, -0.18693066174519002, -0.1687942875929035,\n",
       "        -0.23059607691698936, 0.7276914030709144, -0.0032121350636897805,\n",
       "        -0.10853472186101332, 0.08614443071493638, -0.10234745438565074,\n",
       "        0.045609100127138924, 0.09642219615301784, -0.023060160539034702,\n",
       "        -0.07983969055997353, 0.10795334762021025, 0.13101565055461273,\n",
       "        -0.1445052664171601, -0.06995584644518071, -0.1756477078045584,\n",
       "        0.026675522715397304, 0.004172984415486414, -0.0418249055031924,\n",
       "        -0.19785278929027628, -0.0018897859437387865, 0.13719729876397768,\n",
       "        0.10716713274757228, -0.09586754588129387, 0.6614486180463374,\n",
       "        -0.2153895527051375, -0.22526301463068377, -0.18445924807664238,\n",
       "        0.05701353564418721, -0.13558457136719226, 0.025375424210129394,\n",
       "        -0.1678243776561852, 0.049690687575525194, -0.11171508782993411,\n",
       "        0.11272485857243619, 0.02788310484815615, 0.11523618012606651,\n",
       "        -0.016300692679168782, 0.05160524663637012, 0.28308271052875034,\n",
       "        0.01546880626099445, 0.5779471763875791, -0.03810790429754052,\n",
       "        -0.14337868844037105, -0.35008150433069385, -0.04157964882592868,\n",
       "        -0.049221260422271484], dtype=object),\n",
       " 'mask_detect_class31': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class37': array([ 0.06740555,  0.2170445 ,  0.02999581, -0.04482367,  0.06740555,\n",
       "         0.10481529, -0.08223341, -0.00741393, -0.08223341, -0.04482367,\n",
       "        -0.11964315,  0.02999581, -0.15705288, -0.08223341,  0.14222502,\n",
       "        -0.2692821 ,  0.02999581, -0.00741393, -0.30669184,  0.02999581,\n",
       "        -0.08223341,  0.02999581,  0.17963476,  0.02999581,  0.02999581,\n",
       "        -0.08223341, -0.08223341, -0.00741393,  0.06740555, -0.19446262,\n",
       "         0.06740555, -0.15705288,  0.02999581,  0.02999581,  0.02999581,\n",
       "         0.02999581,  0.02999581,  0.02999581,  0.02999581, -0.04482367,\n",
       "         0.02999581,  0.02999581, -0.08223341,  0.02999581,  0.02999581,\n",
       "         0.06740555,  0.02999581,  0.02999581,  0.17963476, -0.11964315,\n",
       "         0.02999581, -0.08223341,  0.02999581,  0.06740555, -0.04482367,\n",
       "         0.02999581, -0.08223341, -0.08223341,  0.10481529,  0.06740555,\n",
       "        -0.04482367,  0.02999581, -0.08223341, -0.08223341,  0.02999581,\n",
       "        -0.00741393,  0.02999581, -0.00741393,  0.17963476,  0.06740555,\n",
       "        -0.08223341,  0.06740555,  0.02999581,  0.02999581, -0.08223341,\n",
       "        -0.08223341,  0.17963476,  0.02999581,  0.10481529,  0.02999581,\n",
       "        -0.00741393, -0.00741393, -0.00741393,  0.02999581,  0.02999581,\n",
       "         0.06740555,  0.02999581, -0.08223341, -0.04482367,  0.10481529,\n",
       "         0.14222502, -0.04482367, -0.08223341,  0.14222502, -0.04482367,\n",
       "         0.02999581,  0.06740555, -0.11964315, -0.00741393, -0.08223341]),\n",
       " 'shap_detect_class37': array([0.04193145988041049, 0.04193145988051924, 0.04193145988092483,\n",
       "        0.041931459880749984, 0.04193145988126038, 0.04193145988152269,\n",
       "        0.041931459880854706, 0.04193145988054482, 0.04193145988089603,\n",
       "        0.04193145988037526, 0.04193145988085223, 0.041931459880700954,\n",
       "        0.04193145988099625, 0.04193145988117143, 0.041931459880818256,\n",
       "        0.04193145988050388, 0.041931459880907546, 0.04193145988079304,\n",
       "        0.04193145988070727, 0.041931459880730465, 0.04193145988080329,\n",
       "        0.04193145988076704, 0.04193145988068571, 0.04193145988072615,\n",
       "        0.041931459880846206, 0.0419314598808314, 0.041931459880742025,\n",
       "        0.0419314598807186, 0.041931459880829795, 0.04193145988083395,\n",
       "        0.0419314598806872, 0.04193145988072088, 0.04193145988084814,\n",
       "        0.041931459880817055, 0.041931459880740506, 0.041931459880725074,\n",
       "        0.04193145988084716, 0.04193145988077308, 0.04193145988073955,\n",
       "        -0.9958721721683147, 0.041931459880752524, 0.041931459880779086,\n",
       "        0.04193145988074567, 0.0419314598807267, 0.04193145988074988,\n",
       "        0.04193145988076791, 0.04193145988076198, 0.041931459880729625,\n",
       "        0.04193145988084994, 0.04193145988080165, 0.0419314598807052,\n",
       "        0.04193145988070461, 0.041931459880774645, 0.04193145988077828,\n",
       "        0.041931459880715206, 0.04193145988069435, 0.041931459880774465,\n",
       "        0.04193145988080378, 0.04193145988069762, 0.041931459880693925,\n",
       "        -0.9958721721682813, 0.041931459880771564, -0.9958721721683269,\n",
       "        0.0419314598807005, 0.04193145988076137, 0.04193145988080386,\n",
       "        0.04193145988069733, 0.04193145988070204, 0.041931459880759324,\n",
       "        0.04193145988080473, -0.995872172168327, 0.04193145988070295,\n",
       "        0.041931459880759914, 0.041931459880803316, 0.041931459880698164,\n",
       "        0.04193145988069991, 0.04193145988076168, 0.04193145988080201,\n",
       "        0.04193145988069948, 0.04193145988070082, 0.04193145988076218,\n",
       "        0.041931459880803636, 0.0419314598806969, 0.04193145988070007,\n",
       "        0.04193145988072221, 0.04193145988069749, 0.041931459880697075,\n",
       "        0.04193145988070367, 0.04193145988069906, 0.04193145988068677,\n",
       "        0.04193145988078878, 0.04193145988070958, 0.041931459880700496,\n",
       "        0.041931459880689435, 0.041931459880777476, 0.04193145988070836,\n",
       "        0.04193145988071369, 0.04193145988098391, 0.041931459881070825,\n",
       "        0.04193145988118552], dtype=object),\n",
       " 'mask_detect_class37': array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]]),\n",
       " 'shap_class_class45': array([-6.29142557e-04, -6.29142556e-04, -6.29142557e-04, -6.29142556e-04,\n",
       "        -6.29142557e-04, -6.29142557e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142557e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142557e-04, -6.29142556e-04,\n",
       "        -6.29142557e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,  1.13301204e+00,\n",
       "        -6.29142556e-04, -6.29142557e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142557e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,  3.84619326e-02,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142556e-04, -6.29142556e-04,\n",
       "        -6.29142556e-04, -6.29142556e-04, -6.29142557e-04, -6.29142557e-04]),\n",
       " 'shap_detect_class45': array([-0.0994795040479336, 0.24247878084483704, 0.2544075582300613,\n",
       "        -0.2872673782557091, 0.17885863481825032, 0.2305500034635935,\n",
       "        0.24247878084517593, 0.24247878084544944, -0.08357446753781256,\n",
       "        -0.08357446753744385, 0.01980826975325356, 0.24247878084565377,\n",
       "        -0.08357446753794268, -0.06766943103162393, 0.24342766086365408,\n",
       "        -0.06766943103145051, -0.0597169127790067, -0.12333705880464435,\n",
       "        -0.0835744675383645, 0.23055000346494842, 0.17090611656539922,\n",
       "        0.24247878084475072, -0.234672314349884, 0.3259802225040757,\n",
       "        -0.06766943103213652, -0.24660109173021977, 0.09138093403314113,\n",
       "        -0.06766943103175566, 0.23055000346472915, -0.0676694310321061,\n",
       "        -0.08357446753812348, 0.24247878084499697, -0.09152698579184765,\n",
       "        -0.09071366006141446, 0.25440755822477057, 0.2305500034650556,\n",
       "        -0.08357446753861647, -0.059716912778697784, 0.2544075582247727,\n",
       "        -0.2283012627948408, -0.012001803259241717, -0.2585298691098785,\n",
       "        0.2544075582248663, -0.07562194928502142, -0.09152698579173163,\n",
       "        0.24247878084475383, 0.23055000346515692, -0.07562194928502364,\n",
       "        -0.08357446753859155, -0.08357446753846975, -0.07562194928500038,\n",
       "        -0.09152698579152146, -0.07562194928521931, -0.24063670304014695,\n",
       "        0.25440755822486527, -0.09152698579153501, -0.07562194928521604,\n",
       "        -0.08357446753844622, 0.23055000346508547, -0.24063670303996887,\n",
       "        -0.10743202229818671, 0.24247878084479157, -0.0835744675382577,\n",
       "        -0.06766943103180023, -0.06766943103193662, -0.07562194928520288,\n",
       "        -0.05971691277852631, -0.05971691277853469, -0.06766943103194911,\n",
       "        -0.08357446753844555, 0.24247878084497437, -0.24063670303995677,\n",
       "        -0.07562194928521504, -0.043811876272201566, -0.0915269857915062,\n",
       "        -0.08357446753830106, -0.2287079256602355, -0.07562194928520943,\n",
       "        0.27826511298460616, -0.44257386297066587, 0.25440755822467404,\n",
       "        -0.051764394525437185, 0.2424787808449817, 0.12830334020899997,\n",
       "        -0.07562194928508092, -0.07562194928504495, -0.09947950404476591,\n",
       "        0.1589773391858177, -0.08357446753833203, -0.07562194928512861,\n",
       "        -0.05971691277856206, -0.0915269857915521, -0.0835744675383463,\n",
       "        -0.08357446753836278, 0.2663363356046467, -0.08357446753831371,\n",
       "        -0.08357446753837833, 0.20669244870473974, -0.08357446753918324,\n",
       "        -0.07562194928609856], dtype=object),\n",
       " 'mask_detect_class45': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class18': array([-6.33629596e-04, -6.33629595e-04, -6.33629595e-04, -6.33629594e-04,\n",
       "        -6.33629595e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04,  1.25448010e-02, -6.33629595e-04,\n",
       "         1.25448010e-02, -6.33629594e-04, -1.38120602e-02, -6.33629594e-04,\n",
       "        -6.33629595e-04,  1.25448010e-02,  1.25448010e-02,  8.42785931e-01,\n",
       "        -6.33629594e-04,  1.25448010e-02, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629595e-04, -6.33629594e-04, -6.33629594e-04,  1.25448010e-02,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,  1.25448010e-02,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,  1.25448010e-02,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "         1.44329107e-01, -6.33629594e-04,  1.25448010e-02, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04,  1.25448010e-02, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04, -6.33629594e-04, -6.33629594e-04,\n",
       "         1.25448010e-02, -6.33629594e-04,  1.25448010e-02, -6.33629594e-04,\n",
       "        -6.33629594e-04,  1.25448010e-02, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04, -6.33629594e-04,  1.25448010e-02, -6.33629594e-04,\n",
       "        -6.33629594e-04, -1.38120602e-02, -6.33629594e-04, -6.33629594e-04,\n",
       "        -6.33629594e-04,  1.25448010e-02, -6.33629595e-04, -6.33629595e-04]),\n",
       " 'shap_detect_class18': array([0.05241432484998334, 0.05241432485056004, 0.05241432486095023,\n",
       "        -0.9853893072045318, 0.0524143248496932, 0.05241432484947319,\n",
       "        0.05241432484998384, 0.05241432485090853, 0.05241432485035102,\n",
       "        0.052414324850186864, 0.05241432485154016, 0.05241432485126554,\n",
       "        0.052414324851356324, 0.05241432485168106, 0.052414324851161535,\n",
       "        0.052414324851169286, 0.05241432485075901, 0.05241432485079141,\n",
       "        0.052414324851236184, 0.0524143248511384, 0.05241432485088595,\n",
       "        0.05241432485077337, 0.052414324851156574, 0.052414324851238474,\n",
       "        0.052414324850868194, 0.052414324850785086, 0.05241432485130502,\n",
       "        0.0524143248512545, 0.052414324850788, 0.05241432485079013,\n",
       "        0.05241432485115338, 0.05241432485125919, 0.05241432485087203,\n",
       "        0.052414324850835144, 0.05241432485124465, 0.05241432485123725,\n",
       "        0.05241432485086609, 0.05241432485078013, 0.052414324851243754,\n",
       "        0.052414324851240764, 0.05241432485078872, 0.05241432485074334,\n",
       "        0.052414324851222605, 0.05241432485124041, 0.05241432485078922,\n",
       "        0.052414324850773526, 0.05241432485126725, 0.05241432485121567,\n",
       "        0.05241432485087111, 0.052414324850748276, 0.05241432485116541,\n",
       "        0.05241432485116063, 0.052414324850725676, 0.05241432485078584,\n",
       "        0.05241432485110146, 0.05241432485114653, 0.05241432485072542,\n",
       "        0.052414324850756255, 0.052414324851086304, 0.05241432485114324,\n",
       "        0.052414324850721956, 0.052414324850748685, 0.05241432485109991,\n",
       "        0.05241432485115391, 0.052414324850726994, 0.05241432485075769,\n",
       "        0.052414324851085665, 0.05241432485115901, -0.9853893071983193,\n",
       "        0.05241432485076011, 0.052414324851100626, 0.05241432485115854,\n",
       "        0.052414324850721616, 0.05241432485075812, 0.05241432485108797,\n",
       "        0.052414324851154735, 0.05241432485072632, 0.05241432485075608,\n",
       "        0.052414324851089336, -0.9853893071978835, 0.05241432485077753,\n",
       "        0.05241432485075317, 0.05241432485108796, 0.052414324851159884,\n",
       "        0.052414324851139955, 0.05241432485115741, 0.05241432485109053,\n",
       "        0.052414324851160064, 0.052414324851280156, 0.05241432485126684,\n",
       "        0.052414324851161424, 0.052414324851174664, 0.05241432485127837,\n",
       "        -0.9853893071977755, 0.052414324851221474, 0.052414324851173914,\n",
       "        0.05241432485128255, 0.052414324850240515, -0.9853893071996446,\n",
       "        0.052414324849763716], dtype=object),\n",
       " 'mask_detect_class18': array([[1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 1.]]),\n",
       " 'shap_class_class36': array([ 0.00089208,  0.13470384, -0.02140988,  0.00089208,  0.045496  ,\n",
       "        -0.02140988, -0.02140988,  0.02319404,  0.02319404,  0.045496  ,\n",
       "        -0.02140988, -0.02140988, -0.11061772,  0.02319404,  0.26851559,\n",
       "        -0.0660138 ,  0.045496  ,  0.02319404,  0.02319404,  0.045496  ,\n",
       "        -0.02140988, -0.13291968,  0.35772343, -0.08831576,  0.02319404,\n",
       "         0.06779796,  0.00089208,  0.00089208,  0.00089208,  0.00089208,\n",
       "         0.00089208,  0.20160971,  0.02319404, -0.02140988,  0.00089208,\n",
       "         0.06779796,  0.045496  ,  0.045496  ,  0.00089208, -0.08831576,\n",
       "         0.045496  ,  0.00089208, -0.04371184,  0.045496  , -0.04371184,\n",
       "        -0.02140988,  0.02319404,  0.02319404,  0.02319404, -0.11061772,\n",
       "        -0.04371184,  0.00089208,  0.045496  , -0.0660138 , -0.11061772,\n",
       "        -0.04371184,  0.00089208,  0.00089208,  0.69225282, -0.0660138 ,\n",
       "        -0.02140988, -0.04371184, -0.02140988,  0.06779796,  0.045496  ,\n",
       "         0.02319404,  0.00089208, -0.02140988, -0.0660138 ,  0.00089208,\n",
       "        -0.04371184,  0.00089208,  0.00089208, -0.02140988, -0.04371184,\n",
       "         0.02319404, -0.02140988,  0.02319404,  0.02319404, -0.11061772,\n",
       "        -0.0660138 , -0.0660138 , -0.02140988,  0.045496  , -0.22212752,\n",
       "         0.045496  ,  0.045496  ,  0.02319404,  0.02319404,  0.00089208,\n",
       "         0.17930775,  0.02319404, -0.0660138 , -0.13291968, -0.04371184,\n",
       "         0.045496  ,  0.045496  , -0.13291968, -0.02140988,  0.02319404]),\n",
       " 'shap_detect_class36': array([-0.05219598463601405, 0.18415313019878987, -0.012893899283845767,\n",
       "        -0.0377795123965311, -0.05485619112123541, -0.014986821125449024,\n",
       "        -0.03559050841230149, -0.036681828712500475, 0.00453327080692334,\n",
       "        0.017513929118960547, -0.02272413890377878, -0.020845118106006755,\n",
       "        0.015937706324123502, -0.04361644584381008, 0.0358954684787407,\n",
       "        -0.021443498981737252, -0.035291742109839874,\n",
       "        -0.014112076149361719, -0.006110869008958408, -0.03136958174656401,\n",
       "        -0.055471489716470646, -0.03366877920089051, 0.207739576382994,\n",
       "        0.8574932946231951, -0.022883452961289685, 0.004533270806873491,\n",
       "        -0.032055959810188495, -0.03283011000454705, -0.032617541862220656,\n",
       "        0.13649888178958236, 0.03719142706027212, 0.14230620955304096,\n",
       "        -0.044467802391997546, -0.04661665925378333, -0.03445398549538048,\n",
       "        0.02787568268393492, 0.09500845924196888, -0.04941151941637656,\n",
       "        -0.022254481062998432, -0.02453170217032863, -0.030371213654259432,\n",
       "        -0.043712449880237814, -0.027602972594643616, 0.05442767619397881,\n",
       "        -0.02413164525538547, -0.004573382146689231, -0.03464941033900215,\n",
       "        -0.047714957026749105, -0.04781928920944789, 0.002114148121532211,\n",
       "        -0.024466579507756103, -0.03740970870552818, -0.031001281322354135,\n",
       "        -0.015047929797819326, -0.04303610750225395, -0.00368463125671159,\n",
       "        -0.035462890925491264, -0.025547993890144283, 0.9625058542369014,\n",
       "        0.0260713773335004, 0.030079206365010935, -0.007614932243768635,\n",
       "        -0.02402069180330657, 0.04634953436940081, -0.006110869008950637,\n",
       "        0.018049638827101977, -0.05381116017139065, -0.02193553432019235,\n",
       "        -0.024742483202342735, -0.011508429270176923, -0.043025651774658,\n",
       "        -0.010353870925396191, -0.018410763907382943, 0.026529729095850274,\n",
       "        -0.03573010120894016, -0.01898285204206307, -0.02569686892750256,\n",
       "        -0.04727007282062967, -0.00784054172893034, -0.0616716990125733,\n",
       "        -0.026073890126148136, -0.0032762882970458485,\n",
       "        -0.03722617717987098, 0.004533270807018264, -0.026207528477216302,\n",
       "        -0.0220770787326543, -0.034165316785806366, -0.03852068343164505,\n",
       "        0.009174610843075248, -0.022513671834129112, 0.040013736860035065,\n",
       "        -0.04458054557387792, -0.015797036241274376, 0.0024096862626297177,\n",
       "        -0.015253424815040328, 0.0577539698865035, 0.0018942278775695431,\n",
       "        -0.0009252624321334224, -0.021466126830601895,\n",
       "        -0.011277423887563032], dtype=object),\n",
       " 'mask_detect_class36': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class48': array([-0.0014057 , -0.0014057 , -0.02073406, -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.02073406, -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.02073406,  0.01792267, -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 ,  0.03725103, -0.0014057 , -0.02073406, -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.02073406, -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.02073406, -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.02073406, -0.02073406, -0.0014057 ,\n",
       "        -0.0014057 , -0.02073406, -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "         0.65575871, -0.0014057 , -0.02073406, -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "        -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 , -0.0014057 ,\n",
       "         0.65575871, -0.0014057 , -0.0014057 , -0.02073406, -0.0014057 ]),\n",
       " 'shap_detect_class48': array([-0.12523864250370975, 0.11208834806933077, 0.10933448748513941,\n",
       "        -0.011499557574198738, -0.06565816241727973, -0.0482551028766649,\n",
       "        -0.053648862913860174, -0.08480473475911066, -0.05565041283109173,\n",
       "        0.0800538088156908, 0.04039062402769866, 0.00611698584532927,\n",
       "        0.06464580470030312, -0.08743502551508753, -0.014730814304753648,\n",
       "        -0.06790192888211466, -0.09329633846659391, 0.0005202020055129486,\n",
       "        0.04840379708101206, 0.04874076819344042, -0.007920924360894088,\n",
       "        -0.05383102151375718, -0.0751268040636115, 0.11925197346859884,\n",
       "        -0.09633588622651001, -0.1176940781067135, -0.07612147057948015,\n",
       "        -0.09647913034412403, 0.04158350176551728, -0.0194683117090495,\n",
       "        0.05231266198519802, 0.172998865900586, -0.030890319545723854,\n",
       "        -0.033120466575886076, 0.0651002343143996, -0.021909999941636893,\n",
       "        0.12679527954214598, -0.03398304782150885, -0.017746224373658692,\n",
       "        0.037245764536574355, -0.05146096179740911, 0.06806538754896485,\n",
       "        -0.04564266324520161, -0.12787777127031408, -0.0240789955390861,\n",
       "        -0.015491110005872888, 0.05231266198520068, -0.05855409501361042,\n",
       "        -0.046972506579849194, -0.04864498812083995, -0.09765373210850503,\n",
       "        -0.05146096179737125, 0.016572180013317506, -0.0477365923893005,\n",
       "        -0.0975198883861137, -0.050050737691908376, -0.06875146683422395,\n",
       "        -0.06668435388222349, 0.11254268606530171, -0.0468674922989335,\n",
       "        -0.06307090549623173, -0.06311381930171922, 0.17399293068214172,\n",
       "        0.17738718466731374, 0.004007853018967444, 0.04260749219342508,\n",
       "        -0.031090280425658645, -0.012333949890906304,\n",
       "        -0.047852001183384174, 0.020111702481852012, 0.008666672756013516,\n",
       "        -0.09782328546920116, -0.023158498856302612, 0.016533069267882894,\n",
       "        0.08055084120652989, 0.040976953763204316, -0.070308430057618,\n",
       "        -0.0725351351685527, 0.17995731937214743, -0.1731476478118832,\n",
       "        1.1473811648798966, 0.0034799047378550885, -0.047619193788337344,\n",
       "        0.009315148039691912, -0.06723345633305344, -0.10888892666152494,\n",
       "        0.08005380881564528, 0.02369033569577561, 0.12440329900299896,\n",
       "        -0.08617283747567028, -0.005166876031421963, -0.04263366653633682,\n",
       "        0.10515581309530508, -0.00631512740584983, -0.07452326473190407,\n",
       "        0.8360400752651959, -0.08444662446522366, 0.03946924872875157,\n",
       "        -0.08932866578521093, -0.05185858771025664], dtype=object),\n",
       " 'mask_detect_class48': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class43': array([-0.00804372,  0.03061301, -0.00804372,  0.03061301,  0.03061301,\n",
       "        -0.04670045, -0.00804372,  0.1465832 ,  0.03061301,  0.03061301,\n",
       "         0.06926974, -0.00804372, -0.08535718,  0.03061301,  0.18523993,\n",
       "        -0.04670045, -0.04670045, -0.04670045,  0.03061301, -0.16267064,\n",
       "        -0.00804372, -0.04670045, -0.04670045,  0.03061301, -0.04670045,\n",
       "        -0.00804372,  0.10792647, -0.00804372,  0.06926974, -0.00804372,\n",
       "        -0.04670045,  0.03061301,  0.03061301,  0.03061301, -0.04670045,\n",
       "        -0.04670045,  0.06926974, -0.04670045,  0.03061301,  0.03061301,\n",
       "        -0.00804372, -0.00804372,  0.03061301,  0.03061301, -0.04670045,\n",
       "        -0.00804372,  0.06926974, -0.04670045, -0.04670045,  0.03061301,\n",
       "         0.10792647,  0.03061301, -0.04670045, -0.04670045, -0.04670045,\n",
       "         0.03061301, -0.00804372, -0.04670045,  0.10792647,  0.03061301,\n",
       "         0.53315049,  0.06926974, -0.04670045, -0.04670045,  0.03061301,\n",
       "         0.03061301, -0.04670045,  0.03061301, -0.04670045, -0.04670045,\n",
       "        -0.04670045, -0.04670045, -0.00804372, -0.00804372, -0.04670045,\n",
       "        -0.04670045,  0.03061301, -0.04670045, -0.00804372,  0.03061301,\n",
       "        -0.04670045, -0.04670045,  0.03061301, -0.04670045,  0.06926974,\n",
       "        -0.00804372, -0.04670045, -0.04670045,  0.10792647, -0.04670045,\n",
       "         0.06926974, -0.04670045, -0.04670045,  0.03061301, -0.04670045,\n",
       "         0.10792647,  0.06926974,  0.03061301,  0.1465832 , -0.00804372]),\n",
       " 'shap_detect_class43': array([-0.10442417313936092, 0.07404257110717727, -0.1532098139613236,\n",
       "        -0.07421509061086717, -0.1690999941143535, 0.2001164938183576,\n",
       "        -0.060073590572368496, -0.0030514129869970708, 0.30581871559959406,\n",
       "        0.06020518934635943, 0.04636780758802672, -0.08003135272651196,\n",
       "        -0.10436856112089132, 0.06574014205392753, 0.7382368956197048,\n",
       "        -0.1986691610893907, -0.10188985413421381, -0.0785529999740332,\n",
       "        0.13285144359140122, -0.20596735822207501, -0.01728414851158211,\n",
       "        -0.13300565968044686, -0.08175609760401636, 0.03253042582670196,\n",
       "        -0.033463241031649105, -0.07337876534131427, -0.01652938223381073,\n",
       "        -0.060073590571526614, -0.1642010452920496, 0.07297815712721079,\n",
       "        -0.07147802608862563, -0.008981719455234294, -0.05049386473702011,\n",
       "        -0.10584339177972046, -0.0860268944436281, -0.2046043125814052,\n",
       "        0.42238361630094534, -0.11329428965097943, 0.10402356492337661,\n",
       "        0.39230235160370075, -0.00020030410712035263,\n",
       "        -0.028141171123777564, 0.02474689858620549, 0.01177435318568365,\n",
       "        -0.15130907470767285, -0.000679290398919008, 0.03132717523886408,\n",
       "        -0.043318926046519546, -0.09001023380345907, 0.01869304406617578,\n",
       "        0.4080266490587925, -0.07421509061256004, -0.08431857570766288,\n",
       "        -0.08816229286337951, -0.14581805019955862, -0.014912025924113448,\n",
       "        -0.04866915505441771, -0.017694145008205875, 0.643891110888193,\n",
       "        -0.04011582841677086, 0.7382368956200841, 0.003125989585334721,\n",
       "        -0.08816229286352317, -0.179820163500238, 0.004855662305456199,\n",
       "        0.03253042582673871, -0.13990463919083695, 0.0048556623054601955,\n",
       "        -0.15979520349309018, -0.09777158575272127, -0.06894370708477582,\n",
       "        -0.1517314612082843, -0.16119291882246312, -0.10797221974292204,\n",
       "        -0.10188985413401408, -0.07147802608851583, 0.7382368956200994,\n",
       "        -0.057961658068306, -0.2995667364290783, -0.10979692942566177,\n",
       "        -0.1798201635001433, -0.12659946442071268, -0.067098722850082,\n",
       "        -0.13990463919061558, 0.07781640249795052, 0.19857900695450448,\n",
       "        -0.007444232593080136, -0.14581805019943528, 0.07781640249821675,\n",
       "        -0.08602689444343103, 0.7382368956202556, -0.04410738084768573,\n",
       "        -0.033463241031593594, 0.3058187155998585, -0.06894370708454234,\n",
       "        -0.1108751669655289, 0.24189602811865674, -0.008981719455032344,\n",
       "        0.014919212676714588, -0.028141171123408526], dtype=object),\n",
       " 'mask_detect_class43': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class10': array([-0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364,  0.51477042, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364,  0.90824071, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364,\n",
       "        -0.00295364, -0.00295364, -0.00295364, -0.00295364, -0.00295364]),\n",
       " 'shap_detect_class10': array([0.0016468160036899882, 0.0016468160045735036,\n",
       "        0.0016468160044116331, 0.001646816004973628, 0.001646816004067464,\n",
       "        0.0016468160046758662, 0.0016468160046114733, 0.004900118926681962,\n",
       "        0.0016468160046607672, 0.0016468160046572144,\n",
       "        0.0016468160047768965, 0.0016468160044047497, 0.006759149167628209,\n",
       "        0.005225449218968503, 0.0016468160045914892, 0.0016468160047211633,\n",
       "        0.0016468160044968982, 0.0061201075221890555, 0.005225449218588807,\n",
       "        0.0016468160046332336, 0.0016468160046521074, 0.001646816004589935,\n",
       "        0.0043996107846233645, 0.07371651267474544, 0.0016468160045928215,\n",
       "        0.005623075131212074, 0.0016468160045679525, 0.0016468160046572144,\n",
       "        0.0016468160045881586, 0.0016468160046165803,\n",
       "        0.0016468160046581026, 0.0016468160047440339,\n",
       "        0.0016468160047007352, 0.004032571480609759, 0.001646816004610141,\n",
       "        0.0016468160046736458, 0.0016468160046312352,\n",
       "        0.0016468160047362623, 0.005225449218579037, 0.0038834617633953794,\n",
       "        0.004202982586034798, 0.0016468160047315994, 0.0016468160046709812,\n",
       "        0.0056230751313082195, 0.004900118926381758, 0.0016468160045923774,\n",
       "        0.0016468160046634317, 0.004629010349694651, 0.0016468160047369285,\n",
       "        0.0016468160047167224, 0.0016468160046376745,\n",
       "        0.0016468160047258262, 0.0016468160046307911, 0.00462901034953056,\n",
       "        0.0016468160046871905, 0.0016468160047080627, 0.003883461763353413,\n",
       "        0.0016468160046523295, 0.0016468160047140579,\n",
       "        0.0016468160046980707, 0.003751894365751962, 0.001646816004690077,\n",
       "        0.0016468160046272384, 0.0016468160046432256, 0.00490011892645259,\n",
       "        0.001646816004665208, 0.0042029825860769865, 0.6935159040374181,\n",
       "        0.001646816004609697, 0.0016468160046956282, 0.0016468160046518854,\n",
       "        0.007510113360954529, 0.0016468160045837177, 0.004900118926453256,\n",
       "        0.006120107522168183, 0.004629010349617824, 0.00490011892645037,\n",
       "        0.001646816004669871, 0.004900118926527863, 0.001646816004694962,\n",
       "        0.0016468160046614333, 0.003751894365866759, 0.004900118926443486,\n",
       "        0.0016468160046831937, 0.0038834617633649593, 0.005225449218634992,\n",
       "        0.0036349455679118847, 0.0016468160046876346, 0.001646816004660101,\n",
       "        0.00562307513132998, 0.0016468160046871905, 0.0016468160046727576,\n",
       "        0.0016468160046534397, 0.0016468160047213853, 0.005623075131297339,\n",
       "        0.0016468160047011793, 0.004202982586107629, 0.0016468160045597369,\n",
       "        0.004900118926109087, 0.001646816004395646], dtype=object),\n",
       " 'mask_detect_class10': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class6': array([-0.00912089,  0.09085341, -0.04911061,  0.07085855,  0.01087397,\n",
       "        -0.02911575,  0.05086369, -0.02911575,  0.03086883,  0.05086369,\n",
       "         0.07085855,  0.03086883, -0.04911061, -0.00912089,  0.03086883,\n",
       "        -0.02911575, -0.00912089, -0.00912089, -0.02911575, -0.00912089,\n",
       "        -0.00912089, -0.02911575, -0.02911575, -0.02911575,  0.05086369,\n",
       "         0.05086369,  0.05086369, -0.02911575,  0.05086369, -0.06910547,\n",
       "        -0.06910547, -0.04911061, -0.00912089,  0.01087397,  0.05086369,\n",
       "        -0.02911575,  0.03086883,  0.03086883, -0.02911575, -0.02911575,\n",
       "         0.05086369, -0.02911575, -0.06910547,  0.07085855, -0.00912089,\n",
       "        -0.02911575, -0.02911575, -0.00912089,  0.03086883, -0.02911575,\n",
       "         0.03086883,  0.17083285, -0.00912089,  0.01087397,  0.01087397,\n",
       "        -0.02911575, -0.00912089,  0.01087397, -0.00912089,  0.15083799,\n",
       "         0.01087397,  0.05086369,  0.03086883,  0.03086883,  0.05086369,\n",
       "         0.03086883,  0.01087397, -0.02911575,  0.01087397, -0.02911575,\n",
       "         0.01087397,  0.07085855, -0.00912089, -0.02911575, -0.00912089,\n",
       "        -0.00912089, -0.02911575, -0.00912089,  0.01087397, -0.00912089,\n",
       "         0.01087397, -0.00912089, -0.00912089,  0.05086369,  0.11084827,\n",
       "         0.03086883,  0.01087397, -0.00912089, -0.02911575, -0.02911575,\n",
       "         0.01087397, -0.02911575,  0.03086883,  0.05086369,  0.05086369,\n",
       "         0.05086369,  0.07085855,  0.03086883, -0.02911575,  0.03086883]),\n",
       " 'shap_detect_class6': array([-0.05529555651591389, 0.9558977259979189, -0.04356340732228081,\n",
       "        -0.08190590604304349, -0.041207724395336376, -0.04598193416473939,\n",
       "        -0.0819059060451528, -0.06681058048707988, -0.08190590604390224,\n",
       "        -0.08190590604435255, -0.08190590604458914, -0.08190590604458703,\n",
       "        -0.02364324599939649, -0.06232470543988977, -0.08190590604473491,\n",
       "        -0.0638309516385156, -0.06624094556073556, -0.054231142522891185,\n",
       "        -0.04549174351630436, -0.08190590604430337, -0.08190590604439596,\n",
       "        -0.033859441597656637, -0.047638804986139704, -0.03578130017557357,\n",
       "        -0.08190590604441161, -0.08190590604431547, -0.08190590604436376,\n",
       "        -0.06232470543971591, 0.9558977260046981, -0.035575386756396266,\n",
       "        -0.05013640710405409, -0.0018165045170392968, -0.0427435048348791,\n",
       "        -0.05366635143073395, -0.08190590604428805, -0.07092385702802795,\n",
       "        -0.08190590604434922, -0.08190590604424886, -0.03491102459299522,\n",
       "        -0.055797638571492114, -0.08190590604429604, -0.047312451642522846,\n",
       "        0.007559924304603172, -0.08190590604441694, -0.051969262812117445,\n",
       "        -0.042743504834933166, -0.06909351552536025, -0.06593969632051322,\n",
       "        -0.0819059060442614, -0.03706253922724423, -0.08190590604449588,\n",
       "        0.9558977260046897, -0.0819059060443138, -0.06885177230790485,\n",
       "        -0.08190590604440717, -0.03385944159767129, -0.06885177230779149,\n",
       "        -0.06860073127444377, -0.049874929746658414, 0.9558977260046199,\n",
       "        -0.068600731274442, -0.08190590604421288, -0.04039376076244039,\n",
       "        -0.08190590604440329, -0.0819059060442775, -0.04039376076232459,\n",
       "        -0.06562663338485586, -0.042743504834955814, -0.081905906044342,\n",
       "        -0.055797638571318586, -0.041207724395417866, -0.08190590604433179,\n",
       "        -0.061948143889571705, -0.04927057170309734, -0.055295556504698196,\n",
       "        -0.06860073127455424, -0.0389623074767147, -0.06860073127444277,\n",
       "        -0.08190590604440018, -0.051649240386973716, -0.07050147052736155,\n",
       "        0.0626428080883743, -0.06593969632059526, -0.08190590604419279,\n",
       "        0.9558977260048559, -0.0819059060441516, -0.07192702496689718,\n",
       "        -0.06860073127434552, -0.06268732026533119, -0.049199367336985045,\n",
       "        -0.08190590604397507, -0.051156168798308976, -0.08190590604398662,\n",
       "        0.9558977260051329, -0.08190590604412262, -0.08190590604414172,\n",
       "        0.9558977260050825, -0.07597559957522515, -0.05775338515283146,\n",
       "        -0.08190590604411341], dtype=object),\n",
       " 'mask_detect_class6': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class4': array([-0.00897342,  0.02784251,  0.02784251,  0.02784251,  0.02784251,\n",
       "        -0.00897342,  0.02784251, -0.00897342,  0.00943455, -0.00897342,\n",
       "         0.02784251,  0.00943455,  0.00943455,  0.00943455,  0.00943455,\n",
       "         0.02784251, -0.00897342,  0.00943455,  0.02784251,  0.00943455,\n",
       "        -0.00897342,  0.00943455,  0.00943455,  0.02784251,  0.02784251,\n",
       "        -0.02738139,  0.00943455, -0.00897342, -0.00897342, -0.02738139,\n",
       "         0.00943455,  0.08306641, -0.00897342, -0.00897342,  0.11988235,\n",
       "        -0.00897342, -0.00897342,  0.02784251, -0.00897342,  0.02784251,\n",
       "         0.00943455, -0.00897342, -0.00897342,  0.00943455,  0.02784251,\n",
       "         0.02784251, -0.00897342,  0.02784251, -0.00897342,  0.00943455,\n",
       "         0.02784251, -0.00897342,  0.02784251,  0.00943455,  0.02784251,\n",
       "         0.00943455,  0.02784251, -0.00897342,  0.02784251,  0.04625048,\n",
       "         0.00943455, -0.00897342,  0.00943455,  0.04625048, -0.00897342,\n",
       "         0.00943455,  0.00943455,  0.00943455, -0.00897342,  0.00943455,\n",
       "         0.02784251,  0.02784251, -0.00897342, -0.00897342,  0.02784251,\n",
       "         0.00943455,  0.00943455, -0.00897342, -0.02738139, -0.00897342,\n",
       "         0.00943455,  0.00943455,  0.02784251,  0.04625048,  0.02784251,\n",
       "         0.00943455,  0.00943455, -0.00897342,  0.02784251, -0.00897342,\n",
       "        -0.00897342,  0.00943455, -0.00897342,  0.00943455,  0.00943455,\n",
       "        -0.00897342, -0.00897342,  0.04625048, -0.00897342,  0.00943455]),\n",
       " 'shap_detect_class4': array([0.0034837163716517905, 0.02415076174120856, 0.013756093952483117,\n",
       "        -0.01821924541358555, -0.01418477306469923, 0.0056225827671810835,\n",
       "        0.008917848581603605, 0.015814823040976367, 0.04682044617903247,\n",
       "        0.07420786627615239, 0.05117689799294145, 0.02358603650619595,\n",
       "        0.008096430058026738, -0.0020891596367793586, 0.026167637581046566,\n",
       "        -0.0011906283539395712, 0.006129214593369792, 0.001543135022048503,\n",
       "        0.024134130272951748, 0.00964539070265158, -0.001505724165889899,\n",
       "        0.0021039863509160206, -0.0014118052851490592, 0.04448471187335368,\n",
       "        0.014199599778139116, 0.012419322574232505, -0.00894213703553226,\n",
       "        -0.016465660167622187, 0.027075274169402697, 0.0691943221602288,\n",
       "        0.04682044617906955, 0.01457307836830013, 0.012895170879231643,\n",
       "        -0.0025512229505699757, -0.027248035565552553,\n",
       "        -0.0004994504437884073, 0.02551160719034795, 0.001781436659633151,\n",
       "        0.003106695174239338, 0.0017078596563033788, 0.004576064955915338,\n",
       "        0.022560989020824818, 0.01584123328205944, 0.003085086795092673,\n",
       "        0.0009487318440694059, 0.011062070961850523, 0.010607478059743491,\n",
       "        0.0049746786044562175, 0.012737455808568221, -0.007789217464560294,\n",
       "        0.006135857493371755, -0.002239465421491116, 0.01977510158645235,\n",
       "        0.006135857493358099, 0.005655324279723817, 0.005344144614573554,\n",
       "        -0.0007487277228027667, -0.0026797101749520547,\n",
       "        7.4133570608925226e-06, -0.005944148690578133, 0.007235896366243,\n",
       "        0.010490278327237257, 0.04822859221986231, 0.02306971629142729,\n",
       "        0.004755534549369833, 0.004062323763037612, -0.0011906283538573037,\n",
       "        0.01345821690549398, -0.006731855432248968, 0.007794684477706926,\n",
       "        -0.019335163297681257, 0.0028458506412704088,\n",
       "        0.0027831578842228977, 0.014930079961626652, 0.06032420564705976,\n",
       "        0.015841233282061995, 0.00228782763966473, 0.0041570318780337345,\n",
       "        0.029085969230920328, -0.018561132020334603, -0.029378424253019397,\n",
       "        0.001055699854034975, -0.002103199188254412, 0.005772989090578107,\n",
       "        -0.010064460877367232, 0.0027973541676001856, 0.034428761020287135,\n",
       "        0.008174345583289777, 0.013756093952565163, 0.006451292118104801,\n",
       "        0.02240124374263741, 0.010208649119012203, 0.017704955983164017,\n",
       "        0.0024851814409637685, 0.0010556998539619222, 0.013259632207315186,\n",
       "        0.004576064955996051, 0.013428917523713335, 0.00502095747287723,\n",
       "        0.03025796655647639], dtype=object),\n",
       " 'mask_detect_class4': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class34': array([-0.01926979, -0.00609136, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.00609136, -0.00609136, -0.00609136, -0.00609136, -0.00609136,\n",
       "         0.85050663, -0.00609136, -0.00609136, -0.00609136,  0.0202655 ,\n",
       "        -0.01926979, -0.01926979, -0.01926979, -0.00609136, -0.00609136,\n",
       "        -0.00609136,  0.28383411, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.00609136, -0.00609136, -0.01926979, -0.00609136, -0.00609136,\n",
       "        -0.01926979, -0.00609136, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.03244822, -0.00609136, -0.00609136, -0.00609136, -0.01926979,\n",
       "        -0.00609136, -0.01926979, -0.00609136, -0.01926979, -0.00609136,\n",
       "        -0.00609136, -0.01926979, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.01926979, -0.00609136, -0.01926979, -0.01926979, -0.00609136,\n",
       "        -0.00609136, -0.00609136, -0.01926979, -0.00609136, -0.00609136,\n",
       "        -0.00609136, -0.00609136, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.00609136, -0.00609136, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.00609136, -0.00609136, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.00609136, -0.01926979, -0.00609136,  0.81097134, -0.00609136,\n",
       "        -0.00609136, -0.00609136, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.00609136, -0.00609136, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.00609136, -0.00609136, -0.00609136, -0.00609136, -0.00609136,\n",
       "        -0.03244822, -0.00609136, -0.01926979, -0.01926979, -0.00609136]),\n",
       " 'shap_detect_class34': array([-0.021878122739336425, -0.015432137446412697,\n",
       "        -0.021878122738895778, -0.021878122738216654, -0.02187812273910894,\n",
       "        -0.02187812273888945, -0.021878122738459793, -0.020230815386887202,\n",
       "        -0.021878122739132144, -0.021878122739650396, 1.015925509311901,\n",
       "        -0.02187812273931744, -0.021878122738941186, -0.021878122738305805,\n",
       "        -0.02187812273836831, -0.01879972857736667, -0.02187812273877887,\n",
       "        -0.0218781227385193, -0.02187812273860068, -0.02187812273859857,\n",
       "        -0.018158396458693327, 1.0159255093103674, -0.018619712591036786,\n",
       "        -0.021878122738491212, -0.01865513009223585, -0.021878122738554606,\n",
       "        -0.021878122738590466, -0.02187812273849299, -0.021878122738466566,\n",
       "        -0.021878122738420047, -0.021878122738770878, -0.01854648989075003,\n",
       "        -0.021878122738287042, -0.021878122738409056,\n",
       "        -0.021878122738570704, 0.01918604975265692, -0.019597235634943533,\n",
       "        -0.021878122738607897, -0.021878122738568928,\n",
       "        -0.021878122738468897, -0.02187812273852341, -0.021878122738632988,\n",
       "        -0.021878122738476447, -0.021878122738489103,\n",
       "        -0.021878122738541617, -0.02187812273871581, -0.018117964651406138,\n",
       "        -0.018158396458676007, -0.02187812273829237, -0.021878122738533956,\n",
       "        -0.02187812273846279, -0.021878122738449024, -0.018407207581254803,\n",
       "        -0.02187812273861045, -0.021878122738466232, -0.02187812273842271,\n",
       "        -0.021878122738568928, -0.020283954332987353,\n",
       "        -0.021878122738428707, -0.021878122738444694,\n",
       "        -0.019622027886373683, -0.02187812273851253, -0.02187812273852474,\n",
       "        -0.021878122738556827, -0.021878122738603345,\n",
       "        -0.021878122738592465, -0.021878122738479444, -0.02187812273848244,\n",
       "        -0.021878122738690275, -0.021878122738571815,\n",
       "        -0.021878122738502204, -0.019804589008116102,\n",
       "        -0.020248917664833388, -0.021878122738572814,\n",
       "        -0.021878122738428707, -0.021878122738549943,\n",
       "        -0.021878122738582362, -0.021878122738631545, 1.0159255093106418,\n",
       "        -0.021019724366238335, -0.021878122738623773,\n",
       "        -0.021878122738551165, -0.021878122738455685, -0.02187812273855494,\n",
       "        -0.021878122738599126, -0.02187812273868328, -0.02187812273852019,\n",
       "        -0.01896294399682763, -0.02187812273866152, -0.021878122738505756,\n",
       "        -0.021878122738534733, -0.021878122738555272,\n",
       "        -0.021878122738600903, -0.02187812273845613, -0.02187812273862788,\n",
       "        -0.021878122738565486, -0.0218781227385616, -0.021878122738584693,\n",
       "        -0.02187812273886125, -0.021878122738598904], dtype=object),\n",
       " 'mask_detect_class34': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class35': array([0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.02074471, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.05237295, 0.0418302 ,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.0418302 , 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197,\n",
       "        0.01020197, 0.01020197, 0.01020197, 0.01020197, 0.01020197]),\n",
       " 'shap_detect_class35': array([0.07667034166107223, 0.17771116111789298, -0.034522904629586515,\n",
       "        0.150799172524826, 0.05813813394835765, 0.05813813394877376,\n",
       "        0.021073718518212825, -0.0330202931909066, 0.05813813394883627,\n",
       "        -0.06355122998651719, 0.05584210821393909, -0.08085342391575301,\n",
       "        0.07667034166350806, 0.039605926233522215, 0.05584210821367741,\n",
       "        0.07667034166327658, 0.039605926233054256, -0.07273533292496148,\n",
       "        -0.02082518588153559, 0.05813813394828904, 0.0025415108029261946,\n",
       "        -0.07158732005781532, -0.0808534239153812, -0.07158732005773871,\n",
       "        0.03960592623324488, 0.11373475709383918, -0.053055112342679456,\n",
       "        0.07667034166353348, 0.09520254937867778, -0.05305511234260052,\n",
       "        0.0025415108028564726, -0.11865584761744086, -0.12100654063141936,\n",
       "        -0.03452290462740981, 0.0925785199676602, 0.03960592623319015,\n",
       "        0.039605926233253874, 0.03960592623327697, 0.03960592623318271,\n",
       "        0.039605926233235444, -0.03599892117109227, 0.0025415108029659406,\n",
       "        0.02107371851803974, 0.0558421082137448, -0.08085342391534489,\n",
       "        0.03960592623314774, 0.039605926233204136, -0.10334900938664604,\n",
       "        -0.06552538295457977, 0.03146561069485687, -0.12171721526368018,\n",
       "        -0.05436712704801594, 0.0558421082137599, 0.07421031409073497,\n",
       "        -0.1271839432032036, 0.05813813394840672, 0.058138133948409165,\n",
       "        0.03960592623325332, 0.09787385859893427, 0.058138133948386295,\n",
       "        -0.0993856316304692, -0.08085342391527217, 0.058138133948362425,\n",
       "        0.109058405614331, -0.07273533292501122, 0.07421031409074341,\n",
       "        0.09520254937872996, 0.039605926233259314, 0.10820760742443192,\n",
       "        0.0396059262332632, 0.1137347570938867, 0.09257851996773281,\n",
       "        -0.07158732005774404, -0.10865173548804374, 0.2434602111000671,\n",
       "        -0.07273533292509393, -0.13645004706079655, 0.021073718518061835,\n",
       "        -0.045183024109516134, -0.1747809211304605, -0.09011952777289589,\n",
       "        -0.03452290462733387, -0.040274279435561056, 0.09257851996772604,\n",
       "        -0.08085342391530825, -0.10947174467901755, -0.07273533292505996,\n",
       "        0.07421031409077505, 0.07667034166350839, 0.02107371851806017,\n",
       "        0.00992159352137989, 0.05584210821374114, -0.08191943586357997,\n",
       "        -0.11482913805979722, 0.05813813394833245, -0.038873944699652996,\n",
       "        -0.045183024109613945, 0.09787385859893882, 0.07667034166345044,\n",
       "        0.09257851996758859], dtype=object),\n",
       " 'mask_detect_class35': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class49': array([0.01198048, 0.01198048, 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.0020685 , 0.01198048, 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.0020685 , 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.0020685 , 0.01198048, 0.01198048, 0.0020685 ,\n",
       "        0.01198048, 0.01198048, 0.01198048, 0.0020685 , 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.0020685 , 0.01198048, 0.0020685 ,\n",
       "        0.01198048, 0.09127634, 0.01198048, 0.01198048, 0.0020685 ,\n",
       "        0.01198048, 0.01198048, 0.01198048, 0.0020685 , 0.0020685 ,\n",
       "        0.01198048, 0.01198048, 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.02189246, 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.0020685 , 0.01198048, 0.01198048,\n",
       "        0.0020685 , 0.0020685 , 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.0020685 , 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.0020685 , 0.02189246, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.01198048, 0.01198048, 0.01198048,\n",
       "        0.01198048, 0.01198048, 0.01198048, 0.0020685 , 0.01198048]),\n",
       " 'shap_detect_class49': array([0.0248048229115696, 0.004107884381929439, 0.11941939905457677,\n",
       "        -0.03802516905697961, -0.10529021928412208, 0.05910260676137924,\n",
       "        0.34117231188495944, -0.05404065720468154, -0.01743382715031594,\n",
       "        -0.014899508146507867, 0.007064589885998451, 0.007064589885907191,\n",
       "        -0.0018055266272969384, 0.010021295390477691,\n",
       "        -0.014899508146786311, -0.01882985033026352, -0.0402426981850742,\n",
       "        -0.025036784162049353, 0.044910420342569646, 0.04845846694789324,\n",
       "        -0.0047622321319356065, 0.0449104203422267, -0.018829850330449482,\n",
       "        0.16081327611562468, 0.04491042034219905, 0.04136237373690954,\n",
       "        0.03958835043458864, -0.007296551135307361, 0.004107884381267968,\n",
       "        0.004107884381342797, 0.015934706399399756, -0.026368375502698216,\n",
       "        0.0011511788769603681, 0.04845846694753719, -0.03924668933878017,\n",
       "        -0.01996814615423803, 0.001151178876915071, 0.007064589885837136,\n",
       "        -0.018829850330551512, 0.018891411903798838, -0.022502465158349416,\n",
       "        -0.05576540208293679, -0.01882985033050033, 0.012978000894939612,\n",
       "        -0.026368375503117325, -0.022502465158393825, 0.7018903834232499,\n",
       "        0.007064589886149442, 0.001151178876970138, -0.051217588107954515,\n",
       "        -0.04024269818447124, -0.017433827150368675, 0.0070645898857306655,\n",
       "        -0.039246689339130336, 0.006791280973981073, -0.04024269818443005,\n",
       "        -0.04024269818485304, -0.057982931211300937, -0.019968146154182853,\n",
       "        0.01593470639938277, -0.04911281469812301, 0.08623292865050702,\n",
       "        0.04491042034260395, 0.007064589886137562, 0.04491042034229842,\n",
       "        -0.0199681461545983, -0.014899508146661411, -0.0004023443537634064,\n",
       "        -0.04467775644151184, -0.0402426981847922, -0.028881217226844336,\n",
       "        -0.05512645301170849, 0.004107884381313598, -0.027571103165925814,\n",
       "        -0.008310278736758603, 0.05555456015849192, -0.014899508147014795,\n",
       "        -0.014899508147041662, -0.01996814615413922, -0.054040657205062126,\n",
       "        0.012978000894580344, -0.019968146154535016, -0.01771068552895494,\n",
       "        -0.025185861750266048, 0.0011511788772378129, -0.01996814615432918,\n",
       "        0.1548998651067317, -0.026368375502763608, 0.09517951168568917,\n",
       "        0.044910420342551216, 0.012978000894971142, -0.017433827150475478,\n",
       "        0.037814327131907355, -0.05798293121098941, -0.05601179420806157,\n",
       "        -0.05601179420805624, 0.041362373737247826, -0.017433827151486114,\n",
       "        -0.03924668934032638, 0.02480482291096564], dtype=object),\n",
       " 'mask_detect_class49': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class26': array([ 0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.00374626, -0.00751298, -0.00751298,\n",
       "         0.00374626, -0.00751298,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626,  0.00374626, -0.00751298,  0.00374626,  0.00374626,\n",
       "         0.00374626, -0.00751298,  0.00374626,  0.00374626,  0.00374626,\n",
       "        -0.00751298,  0.00374626,  0.00374626,  0.00374626, -0.00751298,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626, -0.00751298,  0.00374626,  0.00374626,  0.30774578,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "        -0.00751298,  0.00374626,  0.00374626, -0.00751298,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.00374626, -0.00751298,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.57796758,  0.00374626, -0.00751298,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626,\n",
       "         0.00374626,  0.00374626,  0.00374626,  0.00374626,  0.00374626]),\n",
       " 'shap_detect_class26': array([-0.04574145788798534, -0.056923180522786554, -0.06880376082391848,\n",
       "        0.012875228736237032, 0.02344545091379191, 0.017679875180054205,\n",
       "        0.2771307831947002, -0.07520995608182413, -0.031135332696303752,\n",
       "        -0.022159733716499264, 0.34818665538582927, -0.17557015223117345,\n",
       "        0.116975901705334, -0.041897740731348, 0.13237427930127388,\n",
       "        -0.1793106290486569, -0.028850260478959888, 0.03874979261804801,\n",
       "        0.01767987518197034, -0.03805402357630183, -0.15452923243330352,\n",
       "        0.003265935847629242, -0.16489668971556093, 0.3924422978664659,\n",
       "        -0.14056490221611073, -0.07579233746923542, 0.0818915052368856,\n",
       "        -0.12453765958023832, -0.028850260478781586, 0.3862711923408405,\n",
       "        0.12338209696473257, 0.3862711923412133, -0.07709067395615554,\n",
       "        -0.08802234660105013, -0.041388332434249, -0.1504827503814954,\n",
       "        0.03300280168103997, 0.10416351118577527, 0.09775731592643944,\n",
       "        0.21138298974093161, -0.08706519554002778, -0.1493140525979132,\n",
       "        0.02248452162671677, -0.1872102165805941, -0.16941682415253512,\n",
       "        -0.049585175043798335, 0.012875228737462163, -0.14268070982449355,\n",
       "        -0.03421030642056677, -0.04408407526114988, 0.3462138077500395,\n",
       "        0.12338209696486413, 0.12602685647525091, -0.11308138572029591,\n",
       "        0.14260068274351823, -0.13366648782512847, 0.12338209696444358,\n",
       "        -0.02736150130689341, 0.02046387592564869, 0.040567463700294404,\n",
       "        0.012875228736967337, 0.28674007608328933, 0.11967943364963629,\n",
       "        0.11056970644570241, 0.1361944874835812, -0.028850260478823664,\n",
       "        0.12338209696478897, -0.08481924897090443, -0.04958517504376947,\n",
       "        -0.045741457887976456, -0.06756953971700252, -0.17363241052390876,\n",
       "        -0.17537955468610134, 0.012875228737028177, 0.03369536333093093,\n",
       "        -0.041897740731863475, -0.04189774073225194, -0.04574145788798789,\n",
       "        -0.14121664652385646, -0.2493211915289727, 0.12715396893975162,\n",
       "        -0.08622621708902656, -0.1264595181581244, -0.16510634701486382,\n",
       "        0.008070582292565853, -0.04958517504349336, -0.041897740731930866,\n",
       "        0.7575954276614719, -0.03265871417417521, -0.08026438536910274,\n",
       "        -0.0380540235761605, -0.0816161513411493, 0.017679875181895177,\n",
       "        -0.15114394025923195, -0.091225444230564, -0.16614330068490013,\n",
       "        0.11056970644559405, 0.43450561768308504, -0.1254897730054535,\n",
       "        0.03209381451482329], dtype=object),\n",
       " 'mask_detect_class26': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class0': array([-0.00653341, -0.01747399,  0.10287243, -0.01747399, -0.01747399,\n",
       "        -0.01747399, -0.01747399,  0.01534776, -0.00653341, -0.01747399,\n",
       "        -0.01747399, -0.00653341, -0.01747399, -0.01747399,  0.02628834,\n",
       "        -0.01747399, -0.01747399, -0.01747399,  0.00440718, -0.01747399,\n",
       "        -0.01747399, -0.01747399, -0.01747399,  0.02628834, -0.00653341,\n",
       "         0.36544645,  0.00440718, -0.01747399,  0.85777272, -0.01747399,\n",
       "         0.00440718, -0.00653341, -0.01747399,  0.00440718, -0.01747399,\n",
       "        -0.01747399, -0.00653341, -0.01747399, -0.01747399, -0.00653341,\n",
       "        -0.01747399, -0.01747399, -0.01747399, -0.01747399, -0.01747399,\n",
       "        -0.00653341,  0.03722893, -0.01747399, -0.01747399, -0.01747399,\n",
       "        -0.00653341, -0.00653341, -0.01747399, -0.01747399, -0.11593925,\n",
       "        -0.01747399, -0.00653341,  0.01534776, -0.01747399, -0.05029574,\n",
       "        -0.00653341, -0.00653341, -0.01747399, -0.01747399, -0.00653341,\n",
       "        -0.01747399, -0.01747399, -0.00653341, -0.01747399, -0.01747399,\n",
       "        -0.00653341, -0.00653341, -0.01747399, -0.01747399, -0.01747399,\n",
       "        -0.00653341, -0.01747399, -0.01747399, -0.01747399,  0.00440718,\n",
       "        -0.06123633, -0.01747399, -0.10499866, -0.01747399,  0.01534776,\n",
       "        -0.01747399, -0.00653341, -0.01747399,  0.93435681, -0.01747399,\n",
       "        -0.01747399, -0.01747399, -0.00653341, -0.00653341, -0.01747399,\n",
       "         0.00440718, -0.00653341, -0.00653341, -0.02841458, -0.00653341]),\n",
       " 'shap_detect_class0': array([0.12474520810664502, -0.06599211244624348, -0.13692322903587795,\n",
       "        0.03897569165388515, -0.09118950965629069, -0.05764656269683155,\n",
       "        -0.03571593268571871, 0.006437032450557378, 0.015135911193741802,\n",
       "        -0.07805621629155757, -0.00610764516225748, -0.009594771591227125,\n",
       "        -0.05407335924826917, -0.01379398455314751, 0.07448121453144829,\n",
       "        -0.04625092689817534, -0.0641504133723565, -0.009014658137075693,\n",
       "        0.15869356312549054, -0.05443114546083849, -0.045352320323811646,\n",
       "        -0.06241425032276626, -0.02133250972582612, -0.13692322903395093,\n",
       "        -0.030363034671859856, -0.13692322903399667, -0.0952257616748503,\n",
       "        -0.0452505748696056, 0.900880403015011, 0.011334432687317597,\n",
       "        -0.019552580171242173, 0.0005635769213598874,\n",
       "        -0.003927385431029662, 0.1931427579173659, -0.025520579265977505,\n",
       "        -0.08874987116372579, -0.042308652892745435, -0.06466319222856132,\n",
       "        -0.03314286582902548, -0.029564232615042263, -0.030481830875072835,\n",
       "        -0.024424190329349837, 0.016276354744643506, -0.046541552904397654,\n",
       "        -0.08426340383239384, 0.07966187678494963, 0.9008804030151201,\n",
       "        -0.060363944702398475, -0.04755680516302263, -0.044955909463460064,\n",
       "        -0.02212194230290354, -0.04546926912150395, 0.0008642588369499604,\n",
       "        0.028776510536899003, -0.0675742899992765, 0.0008642588370320059,\n",
       "        -0.05265712215817586, -0.03589809671053301, 0.005105119169652728,\n",
       "        -0.06809387531490041, -0.029099475054826462, 0.04675882973584777,\n",
       "        -0.1103011102109338, 0.00886347165867174, 0.08868625619415216,\n",
       "        0.011334432687386986, -0.06590905493215271, 0.005994644023719409,\n",
       "        -0.037503385291428826, -0.032270761936498804, -0.09470748806922202,\n",
       "        0.07811716319247841, -0.00939651153641663, -0.05217193088502614,\n",
       "        0.18515376022269425, -0.08562948630041978, -0.06773632023063203,\n",
       "        -0.031413193108949744, 0.03311239429620261, -0.025729982742953905,\n",
       "        -0.008584153925567772, -0.05640398171971028, 0.30370268866924743,\n",
       "        -0.07530363838099241, -0.021465934950072985, 0.04047910123086884,\n",
       "        0.006222099524508251, -0.02451872733671412, 0.9008804030152306,\n",
       "        -0.003871481335274596, -0.026539556868979908, -0.05190541736892307,\n",
       "        0.015168682559550062, -0.04427978989555126, -0.07206050203082304,\n",
       "        -0.013375177599532884, 0.01783696171033955, -0.03750338529162067,\n",
       "        -0.05355867498452882, -0.032452967878327854], dtype=object),\n",
       " 'mask_detect_class0': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class13': array([-0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "         0.02018183, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773,  0.11958484, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "         0.05331617, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "         0.00913705, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "         0.00913705, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773,  0.00913705, -0.00190773,\n",
       "        -0.00190773,  1.09152548, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773,\n",
       "        -0.00190773, -0.00190773, -0.00190773, -0.00190773, -0.00190773]),\n",
       " 'shap_detect_class13': array([-0.03173261229996083, -0.006440620624974747, -0.002377350486115648,\n",
       "        -0.023874477783570436, -0.02017882341620425, -0.007705709604638344,\n",
       "        -0.017039315358925777, -0.021103247662862756, 0.021457444559577432,\n",
       "        0.035606861729589934, 0.004140533337160579, -0.004619672370620886,\n",
       "        -0.012742150798447427, 0.02303673406057294, -0.02731087978608082,\n",
       "        -0.003605201566913463, 0.010541387222415932, 0.06490955251701014,\n",
       "        0.007626439472643631, -0.006517725562233734, -0.0206257672710507,\n",
       "        0.05331692716551817, 0.00023076615916584053, 0.0070950500041756515,\n",
       "        -0.019066316310790254, -0.0024051568357905673,\n",
       "        -0.020466935983712742, -0.018658510459077293, -0.03475579567892528,\n",
       "        -0.017880255017014846, -0.06897675848080176, 0.010265063040693967,\n",
       "        0.007313857432448279, 0.00043780274235660777, -0.03926635046999338,\n",
       "        -0.015493531296119523, -0.030905475943412197,\n",
       "        -0.021856125210284016, -0.011514517001039226, 0.012320379778125834,\n",
       "        0.024830913977318403, -0.088264838933231, -0.04086228661858882,\n",
       "        0.5463225132001697, 0.07829268663025934, -0.011910021433974016,\n",
       "        -0.039711696720005074, 0.06421941787174301, -0.01572508610031953,\n",
       "        -0.017089547487747048, 0.009436332501998712, 0.004754502497792856,\n",
       "        -0.020889247882577178, 0.027190074146246968, -0.005455118914457047,\n",
       "        -0.020178823415714198, -0.01467232404829566, -0.03918377867283063,\n",
       "        0.15565348236538967, -0.01937780715553472, 0.0761131645056441,\n",
       "        -0.022566706266134884, -0.03344599891050437,\n",
       "        -0.0053086989061006395, 0.015049678377166309,\n",
       "        -0.014815497151898449, -0.0452101979520928, -0.02580873233338732,\n",
       "        -0.03993742126182653, -0.0026457584490957586,\n",
       "        -0.020825640563185366, 0.03811491022996083, 0.04090470493966347,\n",
       "        -0.02431582886512873, 0.009220607878343445, 0.22211975464127265,\n",
       "        0.01950979093653038, -0.031174314352645616, 0.007666969177988481,\n",
       "        -0.01689941552461116, 0.009220607878321685, 0.5751503918682624,\n",
       "        0.00863737553481192, -0.03237655971864106, -0.05034753364972622,\n",
       "        0.01248785602559277, 0.023890752848912955, -0.01301998548765515,\n",
       "        -0.016107761665413944, 0.023431124681417392, -0.010751101467627033,\n",
       "        -0.006505752401557707, -0.04494285787049013, -0.004962802200881633,\n",
       "        0.03710875476072473, -0.042065368859157015, -0.01830264151755412,\n",
       "        0.02991291378305705, -0.039052557338676186, 0.005375848782250614],\n",
       "       dtype=object),\n",
       " 'mask_detect_class13': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class5': array([-0.00309774, -0.00309774, -0.00309774, -0.00309774, -0.01598332,\n",
       "        -0.00309774, -0.01598332, -0.00309774, -0.00309774, -0.00309774,\n",
       "        -0.00309774, -0.00309774, -0.00309774, -0.00309774, -0.00309774,\n",
       "        -0.00309774,  0.1901859 ,  0.02267341, -0.00309774, -0.00309774,\n",
       "        -0.00309774,  0.02267341,  0.00978783,  0.00978783, -0.00309774,\n",
       "         0.03555899, -0.00309774, -0.00309774, -0.00309774, -0.00309774,\n",
       "         0.02267341, -0.00309774, -0.00309774, -0.00309774, -0.00309774,\n",
       "         0.02267341, -0.00309774, -0.00309774, -0.00309774,  0.00978783,\n",
       "        -0.00309774, -0.04175447, -0.0288689 , -0.01598332, -0.00309774,\n",
       "        -0.00309774, -0.00309774,  0.03555899, -0.00309774, -0.00309774,\n",
       "        -0.01598332, -0.00309774, -0.00309774, -0.00309774, -0.04175447,\n",
       "         1.00197723, -0.01598332, -0.01598332,  0.00978783, -0.00309774,\n",
       "        -0.00309774, -0.00309774, -0.00309774, -0.00309774, -0.00309774,\n",
       "        -0.00309774, -0.00309774, -0.00309774, -0.00309774, -0.01598332,\n",
       "        -0.01598332, -0.00309774, -0.00309774, -0.00309774, -0.00309774,\n",
       "         0.02267341,  0.02267341, -0.05464005, -0.00309774,  0.03555899,\n",
       "        -0.00309774, -0.01598332, -0.00309774, -0.00309774,  0.00978783,\n",
       "        -0.00309774, -0.00309774, -0.0288689 ,  0.00978783,  0.02267341,\n",
       "        -0.00309774, -0.00309774, -0.00309774, -0.00309774, -0.00309774,\n",
       "        -0.00309774, -0.00309774,  0.00978783, -0.00309774, -0.00309774]),\n",
       " 'shap_detect_class5': array([0.002369679772088462, 0.13217236225692186, 0.010976260758899237,\n",
       "        -0.032187410278734174, -0.01960478670648036, 0.006297939046528533,\n",
       "        -0.011264873052512892, -0.034480673791244754,\n",
       "        -0.0036124498275518224, -0.032441462575596325,\n",
       "        -0.007649403639500951, -0.041799542194964845, 0.020773198988592756,\n",
       "        0.017631497893200065, -0.01785554701921921, -6.038025721988305e-05,\n",
       "        0.13636041031766621, 0.021745105240492335, -0.0013180738281471926,\n",
       "        -0.026726654035567066, -0.047543027599691534, 0.015303530475164862,\n",
       "        0.02632557089858023, -0.01040328800466539, -0.01896811882239402,\n",
       "        0.003054600392266016, -0.03207979766290503, -0.032822541020677276,\n",
       "        -0.03835317388451265, -0.04531344560884343, 0.017157158458564692,\n",
       "        -0.0005809383950866609, -0.03667253107260848,\n",
       "        -0.044381920520954465, -0.03814080446080581, 0.04603963669362665,\n",
       "        -0.00664653277557159, -0.022040592996099395, -0.02945008623693468,\n",
       "        0.11831589227937644, -0.02300688410251661, 0.004033944702587333,\n",
       "        -0.03750781126946867, 0.01295836947381801, -0.03110284510751582,\n",
       "        -0.01948724532116397, -0.009601541461854768, 0.024845279577392132,\n",
       "        -0.012255852819013868, -0.013549608167032434, -0.02410928362716447,\n",
       "        -0.016588078000773887, 0.008391527680231325, -0.0061769383720085,\n",
       "        -0.030097118755955, 0.9522652394616301, -0.03925215222846423,\n",
       "        -0.03357522901370158, -0.011829463600963597, -0.021046592349492577,\n",
       "        -0.0015399185375588598, -0.02414027372046157,\n",
       "        -0.008956281993478421, 0.003836793556620255, 0.003937587033327139,\n",
       "        0.003112863960952339, 0.004325850662706299, 0.0012447908942507802,\n",
       "        -0.02562942174636762, -0.012553917606284215, -0.041780658072648635,\n",
       "        0.007363324010736916, 0.053011922235354114, -0.018079099818477884,\n",
       "        -0.004734002840706131, 0.04598156792214114, -0.016913663766039977,\n",
       "        -0.007000669210955879, -0.032877204642075775, 0.29498960583057676,\n",
       "        -0.03480405378436302, -0.0070837413582621744, 0.1268035429673634,\n",
       "        -0.011378217612246777, -0.051052038663790156, 0.025285886672094526,\n",
       "        0.0057383123999885655, -0.040671421513755135, 0.026890334217967382,\n",
       "        0.09880830521081019, -0.030999633307213226, -0.02119650540895568,\n",
       "        -0.038213864251453566, -0.033847023941214305,\n",
       "        -0.009110993327954175, -0.011793287439446298, -0.01517882431289519,\n",
       "        0.10174341227651851, 0.03533030351436772, -0.0020369509286126686],\n",
       "       dtype=object),\n",
       " 'mask_detect_class5': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class20': array([-0.02618337,  0.00317617, -0.04086314,  0.07657502, -0.04086314,\n",
       "        -0.05554291,  0.01785594,  0.01785594,  0.07657502,  0.00317617,\n",
       "         0.09125479, -0.0115036 ,  0.12061434,  0.03253571, -0.02618337,\n",
       "         0.06189525, -0.05554291, -0.02618337,  0.41420975, -0.0115036 ,\n",
       "         0.00317617, -0.02618337, -0.02618337, -0.0115036 ,  0.00317617,\n",
       "         0.07657502,  0.01785594,  0.04721548, -0.02618337,  0.04721548,\n",
       "        -0.02618337,  0.06189525, -0.02618337, -0.02618337,  0.00317617,\n",
       "        -0.02618337,  0.00317617, -0.02618337, -0.0115036 ,  0.00317617,\n",
       "         0.01785594, -0.0115036 ,  0.01785594, -0.0115036 , -0.0115036 ,\n",
       "        -0.02618337, -0.0115036 , -0.05554291, -0.08490246,  0.01785594,\n",
       "        -0.0115036 ,  0.03253571, -0.02618337, -0.04086314, -0.02618337,\n",
       "        -0.02618337,  0.00317617,  0.00317617, -0.05554291, -0.02618337,\n",
       "         0.01785594, -0.0115036 ,  0.03253571,  0.03253571, -0.04086314,\n",
       "         0.01785594, -0.04086314,  0.03253571,  0.78120402, -0.02618337,\n",
       "         0.00317617, -0.04086314, -0.02618337, -0.0115036 ,  0.06189525,\n",
       "         0.03253571, -0.05554291, -0.0115036 , -0.02618337, -0.02618337,\n",
       "         0.03253571,  0.01785594, -0.02618337, -0.04086314,  0.04721548,\n",
       "        -0.02618337, -0.02618337,  0.01785594,  0.00317617, -0.07022269,\n",
       "        -0.05554291,  0.01785594,  0.07657502, -0.0115036 ,  0.06189525,\n",
       "        -0.02618337, -0.02618337, -0.0115036 , -0.05554291,  0.04721548]),\n",
       " 'shap_detect_class20': array([-0.0017173434385188147, -0.0030184082388496902,\n",
       "        -0.0019624419875424737, 0.003789429357065499, 0.005005351323289164,\n",
       "        0.0020602765709553106, -0.004745921567358313,\n",
       "        -0.0036383626185014784, -0.014915628006309078,\n",
       "        -0.003018408238724124, -0.013695400338062269,\n",
       "        0.0028824125850023252, -0.005850620879783941, 0.00292188191109255,\n",
       "        -0.004321363206916229, 0.004552549795530547, 0.0006804286584020103,\n",
       "        0.0017084015183557177, 1.0155666380315087, -0.0038362203995762068,\n",
       "        8.13636609400259e-05, -0.005345658860554936, 0.0031786051347376665,\n",
       "        0.00029426904677198884, 0.0021281682902483112,\n",
       "        -0.013799566114703565, -0.005829031455493516,\n",
       "        0.0002773409753009659, 0.01006078492028295, 0.009793982280274172,\n",
       "        0.0072460637112320425, -0.019111079463050573,\n",
       "        0.0011022147840688001, -0.0012712640772095662,\n",
       "        0.004350246230429788, -0.0029326109808976986,\n",
       "        -0.0014020865917182546, 0.005822141219386401,\n",
       "        -0.011077815178261341, -0.0010573280573012989,\n",
       "        -0.0024402996423726897, 0.005437769503888745, 0.01404984626389394,\n",
       "        0.006037532180725447, -0.002297936419593416, 0.004297757938217517,\n",
       "        -0.003553131574732915, 0.0005643974721053491, 0.00409206218671887,\n",
       "        0.004193959907384359, 0.001021083984252269, -0.005686301806431482,\n",
       "        -0.005873497478705025, 0.01846118763142135, -0.0006818020650796175,\n",
       "        -0.0011850563059214725, 0.00032395450531463865,\n",
       "        -0.0014403425443766382, 0.006778950960608321,\n",
       "        -0.003976519553237079, -0.002469305788040277,\n",
       "        -0.004434514559319869, -0.004343827947691725, 0.016531532467083054,\n",
       "        -0.0016297514616212538, 0.010050230090688617,\n",
       "        -0.0005099084150370636, -0.0033678370710998884,\n",
       "        -0.022236994017500455, -0.0036657711281853356,\n",
       "        -0.003436203581789421, -0.00400964513049229,\n",
       "        -0.0014985710982120537, -0.003207657470570613,\n",
       "        0.013748766598516649, 0.0012630549266895441, 0.005096462846719496,\n",
       "        -0.00015606567605364052, 0.0012700365218187848,\n",
       "        -0.009751784052981494, 0.003144073070644793, 0.004233301051029259,\n",
       "        0.0013581013940205944, 0.0015565526685347164,\n",
       "        -0.006080710368382647, 0.0018668322752457556,\n",
       "        -0.00022760918466013802, 0.0020924684188207143,\n",
       "        0.004305298362321519, 0.001695584499387448, 0.0031923136564881993,\n",
       "        0.0031061960203473404, -0.01087003200161163,\n",
       "        -0.0036007896259410144, -0.003681118093254665,\n",
       "        0.012670946333208866, -0.00127126407706879,\n",
       "        -0.00028715838612558553, 0.015439045429530451,\n",
       "        0.004602755086963839], dtype=object),\n",
       " 'mask_detect_class20': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class19': array([-0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.01698826, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335,  0.00998155, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.03047316, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335,  0.00998155, -0.00350335, -0.00350335, -0.00350335,\n",
       "         0.76513628, -0.00350335, -0.00350335, -0.00350335,  0.00998155,\n",
       "        -0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "         0.61680231, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "         0.00998155, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335, -0.00350335,  0.00998155, -0.00350335,\n",
       "        -0.00350335, -0.00350335,  0.00998155, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335, -0.00350335, -0.00350335, -0.00350335,\n",
       "        -0.00350335, -0.00350335,  0.00998155, -0.00350335, -0.00350335]),\n",
       " 'shap_detect_class19': array([-0.015386145360495207, 0.008699492576100698, -0.01643123829543025,\n",
       "        -0.015130425634213407, -0.01538087598419835, -0.01662120151964419,\n",
       "        -0.017960726820162365, -0.01658778757676671, 0.027691004638064953,\n",
       "        -0.0025318786341451682, 0.011747675100342803,\n",
       "        -0.016763368670495993, 0.027210781351205804, -0.017129688936786236,\n",
       "        -0.015562946795880217, -0.022301070599923034,\n",
       "        -0.011335723383200214, -0.008690273813197091,\n",
       "        -0.006612634075502832, -0.015412253266122167,\n",
       "        -0.022131805964359375, -0.007357649086625395,\n",
       "        -0.007820244711914781, 0.031231942949327518, -0.018820967181618298,\n",
       "        -0.009194628387366066, -0.020478858737214667, -0.01621162237146756,\n",
       "        -0.01325204802016211, 0.004259278773776964, 0.011931767317564956,\n",
       "        0.021885708985942443, -0.014737276831545798, -0.018913499702822967,\n",
       "        -0.008667690772597547, 1.0085853743051856, -0.008252527803503829,\n",
       "        -0.013097036275150464, -0.014798059643333805,\n",
       "        -0.0041505371629297905, -0.016699885012521287,\n",
       "        -0.01624571234325578, -0.016460808865039867, -0.011407766368729422,\n",
       "        -0.015740288496525423, -0.014404248721879176,\n",
       "        -0.006037076959240273, -0.012379115918651928,\n",
       "        -0.020514098249210466, -0.01686345260043065, 1.0085853743051771,\n",
       "        -0.012745184219147054, -0.009952451852799249,\n",
       "        -0.008611015188080051, -0.02209048554571147, -0.01550158272329305,\n",
       "        -0.02158734868470491, -0.014532357290380604, 0.01585806162800263,\n",
       "        -0.018942974258147394, 0.004222081510973252, -0.01830484653383424,\n",
       "        0.010554965231292845, 2.8935522979334216e-05,\n",
       "        -0.012938985084306798, -0.0050832895567363146,\n",
       "        -0.017108102207187836, -0.008252527803401799,\n",
       "        -0.014122932186907522, -0.015310070667246545,\n",
       "        -0.013612188088982013, -0.010175989265824525,\n",
       "        -0.009562885924874642, -0.01884022142339703, -0.013905259819513072,\n",
       "        0.0022303371667318217, -0.009890740709857404, -0.01811875365779947,\n",
       "        -0.022529942177356044, 0.00018617849758462146,\n",
       "        -0.014873284626828132, -0.01840780324335456, -0.016600584405829788,\n",
       "        -0.0109510871026951, -0.01900556970587375, -0.014604521230896284,\n",
       "        -0.014661606139223737, -0.014897393825240135,\n",
       "        -0.007929978112021563, -0.013318094850400808,\n",
       "        -0.010978072695649432, -0.007982671873543956,\n",
       "        -0.008462185102808273, -0.021078621413985643, -0.01657175499231034,\n",
       "        -0.013157011057394863, -0.0032556246228816477,\n",
       "        -0.027776863810759056, -0.017570629999883236,\n",
       "        -0.008044946319500923], dtype=object),\n",
       " 'mask_detect_class19': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class30': array([ 0.00615526,  0.09652164,  0.02121632, -0.0089058 , -0.0089058 ,\n",
       "         0.08146058, -0.0089058 ,  0.00615526, -0.054089  ,  0.02121632,\n",
       "        -0.08421112, -0.03902793,  0.87969695, -0.02396687,  0.83451376,\n",
       "        -0.02396687, -0.0089058 ,  0.02121632, -0.08421112, -0.03902793,\n",
       "        -0.06915006, -0.054089  , -0.0089058 , -0.06915006, -0.06915006,\n",
       "        -0.054089  ,  0.00615526, -0.0089058 , -0.02396687, -0.054089  ,\n",
       "        -0.02396687, -0.0089058 , -0.02396687,  0.02121632,  0.00615526,\n",
       "         0.02121632, -0.0089058 ,  0.00615526,  0.00615526, -0.0089058 ,\n",
       "        -0.02396687,  0.03627739,  0.00615526,  0.00615526, -0.03902793,\n",
       "        -0.054089  , -0.02396687, -0.02396687, -0.0089058 , -0.03902793,\n",
       "         0.02121632, -0.06915006,  0.02121632,  0.05133845, -0.0089058 ,\n",
       "        -0.02396687, -0.02396687, -0.03902793,  0.09652164, -0.02396687,\n",
       "         0.05133845,  0.02121632,  0.06639951,  0.02121632,  0.02121632,\n",
       "         0.02121632, -0.06915006, -0.08421112,  0.02121632, -0.0089058 ,\n",
       "         0.02121632, -0.02396687, -0.02396687, -0.06915006, -0.03902793,\n",
       "        -0.054089  ,  0.05133845, -0.0089058 ,  0.03627739, -0.02396687,\n",
       "        -0.02396687, -0.054089  , -0.054089  ,  0.03627739, -0.03902793,\n",
       "        -0.02396687, -0.0089058 , -0.02396687,  0.02121632, -0.06915006,\n",
       "        -0.0089058 , -0.02396687, -0.02396687, -0.02396687,  0.02121632,\n",
       "         0.03627739,  0.08146058,  0.08146058,  0.02121632,  0.00615526]),\n",
       " 'shap_detect_class30': array([-0.011471149822044113, 0.042108315553452624, -0.005844053872177013,\n",
       "        0.008217809442193191, -0.004212964735427094, -0.012067214980794105,\n",
       "        -0.009878484932357434, -0.008070788859527722, 0.04131187903625422,\n",
       "        0.0061173467018516, 0.00721980732006311, -0.007717583207306533,\n",
       "        1.0092633435448337, -0.00016284543970168652, 0.12713025630145236,\n",
       "        0.003648475851997901, -0.008290461539004257, -0.009541595012640736,\n",
       "        0.0006114989112877556, -0.01157038899929641,\n",
       "        -0.0059927691188337295, -0.0002365530862173948,\n",
       "        -0.015048841289124204, 0.041065934896454825, 0.001746900900268189,\n",
       "        -0.013473452965008126, -0.012934218850933488, 0.006053165896022006,\n",
       "        -0.0022667788336526717, 0.034210628780918184,\n",
       "        -0.006526272068321903, 0.0021337104712663146,\n",
       "        -0.005693758355889478, -0.015149273898653615,\n",
       "        -0.0011603854787033407, -0.011243561304823624,\n",
       "        -0.005979339982813636, -0.0037039622685823836,\n",
       "        -0.006021541532877817, -0.002930213224049516,\n",
       "        -0.009528354186932875, -0.0008655249842675072,\n",
       "        -0.00987848493231236, 0.0012761272436941917, 0.005146221398579676,\n",
       "        -0.005979339982947085, -0.0064854297370519065,\n",
       "        -0.00774042668183994, -0.011606429707532784, 0.006626250230985065,\n",
       "        -0.000930489218106012, 0.011491607595004782, 0.009460097011197766,\n",
       "        0.0031297753832033592, -0.013969510941001961,\n",
       "        -0.004468524500043314, -0.0007190976642159619,\n",
       "        -0.0035329720706958057, -0.0013192096323300095,\n",
       "        -0.00934041605299063, 0.020297529473049747, -0.012230719432940296,\n",
       "        -0.009952760767560354, -0.0074547543942357075,\n",
       "        -0.011243561304896899, 0.0069401775473101335,\n",
       "        -0.017629821390005573, -0.011775520296071096, 0.003175272405809504,\n",
       "        0.0016838122061536565, -0.0038306782189035937,\n",
       "        0.020058434153125693, -0.00594295135627676, -0.007068489221821239,\n",
       "        -0.0025951977044714747, -0.0021833708663745455,\n",
       "        -0.0031039249750760556, -0.007936834045903507,\n",
       "        -0.010076769477402658, -0.014147634603702275,\n",
       "        -0.009120737878390961, -0.003228004797034667,\n",
       "        0.0025938204557364175, -0.008301431109247637,\n",
       "        -0.017056395856017703, -0.008105336538522856, 0.004544871822093843,\n",
       "        -0.010964581833848408, 0.0007210920971464363, 0.014885537232399937,\n",
       "        0.007033731841397661, -0.007408540341755865,\n",
       "        -0.0032280047972557124, -0.005543690138123392,\n",
       "        -0.008204947066892343, -0.001467150278318785, 0.02177746335119879,\n",
       "        0.013157178853393514, 0.014807774748955893, 0.002971967527940933],\n",
       "       dtype=object),\n",
       " 'mask_detect_class30': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class8': array([ 0.00911452, -0.01318744,  0.00911452, -0.01318744, -0.00203646,\n",
       "        -0.01318744, -0.00203646,  0.00911452,  0.05371844,  0.00911452,\n",
       "        -0.01318744, -0.01318744,  0.0202655 , -0.00203646,  0.03141648,\n",
       "        -0.02433842, -0.01318744, -0.02433842,  0.0202655 , -0.01318744,\n",
       "         0.00911452,  0.00911452, -0.02433842,  0.0202655 ,  0.03141648,\n",
       "        -0.00203646, -0.00203646,  0.00911452,  0.03141648,  0.04256746,\n",
       "         0.06486942,  0.03141648, -0.00203646, -0.01318744,  0.04256746,\n",
       "        -0.00203646,  0.00911452, -0.01318744, -0.02433842, -0.0354894 ,\n",
       "        -0.02433842, -0.00203646,  0.0760204 , -0.00203646, -0.00203646,\n",
       "        -0.00203646,  0.0202655 , -0.02433842, -0.01318744,  0.00911452,\n",
       "         0.00911452, -0.00203646,  0.0202655 , -0.00203646,  0.00911452,\n",
       "         0.0202655 ,  0.0202655 ,  0.0760204 ,  0.0202655 , -0.00203646,\n",
       "         0.0202655 ,  0.00911452,  0.1317753 ,  0.03141648,  0.0202655 ,\n",
       "         0.00911452,  0.03141648, -0.00203646,  0.00911452,  0.00911452,\n",
       "        -0.00203646, -0.00203646,  0.00911452,  0.00911452,  0.0202655 ,\n",
       "         0.00911452,  0.00911452, -0.00203646,  0.04256746, -0.01318744,\n",
       "         0.08717138, -0.00203646, -0.02433842,  0.00911452,  0.03141648,\n",
       "        -0.02433842,  0.0202655 ,  0.03141648,  0.0202655 ,  0.00911452,\n",
       "         0.04256746,  0.03141648,  0.08717138, -0.00203646, -0.00203646,\n",
       "        -0.02433842, -0.00203646, -0.01318744, -0.01318744,  0.00911452]),\n",
       " 'shap_detect_class8': array([-0.0005456641607823887, 0.0027304164837266276,\n",
       "        -0.02600415148141999, -0.011394595106173577, -0.023602102834742178,\n",
       "        -0.011803502208652228, 0.007174683972556162, -0.009226961360854324,\n",
       "        -0.0025460650936139917, -0.006748479546937136,\n",
       "        0.023388967902479463, -0.00790608182320307, -0.002563729836310369,\n",
       "        -0.017725981163024707, 0.05528754914186651, -0.018394104711672354,\n",
       "        -0.017807560086717578, -0.01445842961732735, 0.011543546139234584,\n",
       "        -0.008194190226107456, -0.003436916340648244,\n",
       "        -0.007462579489594501, -0.012976601523504327,\n",
       "        -0.0003307562699386146, 0.01657421632514333, 0.01959260806414398,\n",
       "        -0.004061422921142199, -0.00033075626991740936,\n",
       "        0.01190725835208295, 0.01975337243438835, 0.047985290149275994,\n",
       "        -0.0025232002270217935, -0.008852349644379531,\n",
       "        -0.0012438564993217938, 0.0010870500581561249,\n",
       "        -0.0008232010908266751, 0.04488944556219454, -0.007379578069973136,\n",
       "        -0.01913034578600792, -0.013960567104117083, -0.001643181667936533,\n",
       "        0.015826933771578844, -0.0016873623248943037,\n",
       "        -0.004590049785803352, -0.009084704775578878,\n",
       "        -0.009408395562627292, -0.01121506810793782, -0.013499603782947345,\n",
       "        0.0007087210968547142, 0.0008318564663685191,\n",
       "        -0.0035509827640374247, -0.017607972918456172,\n",
       "        0.010557792329086935, 0.005556402081748568, 0.005101540703443486,\n",
       "        0.004548872652334834, 0.0042817043169095514, 0.015573553846510158,\n",
       "        -0.007485884205490345, 0.00142076475526276, 0.0065071155262610425,\n",
       "        0.009446163229703375, 0.9899916638553243, 0.022243849982267805,\n",
       "        0.010409041665214391, -0.0011779892974308481, 0.007852044798029145,\n",
       "        -0.0035662244887681993, -0.009413233808000077,\n",
       "        -0.007508914521943799, -0.0026796887511437717,\n",
       "        -0.018024808485895383, -0.006633294380784638,\n",
       "        -0.015035388400372773, 0.0025668488961074765,\n",
       "        -0.005138146658874354, 0.008096644980615242, 0.0011940075448887422,\n",
       "        0.02999898828619063, -0.01890150447368588, 0.03931228733626646,\n",
       "        0.0009084511841488396, 0.006532585745825048, -0.007442858380622863,\n",
       "        -0.009170343596186292, -0.015010321789494796, 0.008048281128397727,\n",
       "        0.013185469771640812, -0.008868018512295017, -0.01219451192425991,\n",
       "        0.040511745172230995, 0.006650029989666906, 0.0290623749210972,\n",
       "        0.015591616241312334, -0.005709359497138244, -0.020142357300165337,\n",
       "        -0.01058351272305591, -0.017651755100206223, -0.030071735167742086,\n",
       "        -0.018309189356713773], dtype=object),\n",
       " 'mask_detect_class8': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class21': array([-0.01551362,  0.00129365, -0.01551362, -0.0323209 , -0.01551362,\n",
       "         0.15255912, -0.01551362, -0.01551362, -0.0323209 , -0.01551362,\n",
       "        -0.04912817,  0.00129365,  0.05171547, -0.01551362,  0.00129365,\n",
       "        -0.0323209 , -0.0323209 ,  0.00129365, -0.0323209 , -0.01551362,\n",
       "         0.00129365,  0.00129365,  0.0349082 ,  0.01810092,  0.00129365,\n",
       "         0.00129365,  0.01810092, -0.01551362, -0.01551362, -0.01551362,\n",
       "        -0.01551362, -0.01551362, -0.01551362,  0.00129365, -0.0323209 ,\n",
       "         0.01810092, -0.01551362, -0.01551362,  0.00129365, -0.01551362,\n",
       "         0.00129365, -0.01551362,  0.00129365,  0.00129365,  0.0349082 ,\n",
       "        -0.01551362,  0.00129365, -0.0323209 ,  0.00129365, -0.01551362,\n",
       "        -0.01551362,  0.65677733, -0.0323209 ,  0.0349082 ,  0.00129365,\n",
       "        -0.01551362, -0.01551362, -0.01551362,  0.00129365,  0.00129365,\n",
       "         0.00129365,  0.00129365, -0.01551362, -0.01551362, -0.01551362,\n",
       "        -0.01551362, -0.01551362,  0.00129365,  0.00129365, -0.06593544,\n",
       "        -0.01551362,  0.00129365, -0.01551362,  0.01810092,  0.01810092,\n",
       "         0.00129365,  0.95930826,  0.00129365,  0.00129365,  0.00129365,\n",
       "         0.00129365, -0.06593544, -0.01551362, -0.0323209 , -0.01551362,\n",
       "        -0.01551362, -0.01551362,  0.00129365, -0.01551362,  0.00129365,\n",
       "         0.00129365,  0.00129365, -0.01551362, -0.01551362, -0.01551362,\n",
       "        -0.01551362,  0.01810092,  0.0349082 ,  0.00129365, -0.01551362]),\n",
       " 'shap_detect_class21': array([0.03897701162067113, 0.006232705218936818, 0.03909114428196481,\n",
       "        0.01320826205190273, 0.005413065164547426, -0.011162860423141074,\n",
       "        0.020126553659442825, 0.010160567716850588, 0.018098520179886446,\n",
       "        0.0099389222747992, 0.009906295943497456, 0.0050748834795262265,\n",
       "        -3.681583748305073e-06, 0.009292399571192655, 0.027340128208848125,\n",
       "        0.02950700944716944, 0.011653725432670736, 0.01042871220217556,\n",
       "        0.010064941141486372, 0.00995877905501441, 0.00561725669066071,\n",
       "        -0.0003447225860753189, -0.002461762898300801,\n",
       "        0.003213640107487148, 0.006542180710838119, -0.0008364561241536173,\n",
       "        0.008973627959902197, 0.004944144800949513, 0.0005674161086273166,\n",
       "        0.0036532848754542435, 0.01265558359119412, 0.005870998583265896,\n",
       "        0.0017593730031737476, 0.002164361032382711, 0.032048612443505986,\n",
       "        0.004944956482338725, 0.011398088099692893, 0.013550337726507822,\n",
       "        -0.0033024631208580235, 0.0040076910088837625,\n",
       "        0.0045650476631196035, 0.043610109046247736, 0.005177579659290776,\n",
       "        0.010513345020413123, -0.0020393120094261974, 0.003940310937234903,\n",
       "        0.0025682162280153964, 0.018394837958101595, 0.0048062060211040425,\n",
       "        0.03001982338842568, 0.011458613783238647, -0.011162860422993415,\n",
       "        0.010386927166713633, -0.0011613514975075123,\n",
       "        0.0075823611738752295, 0.004268039062244933, 0.011913178248648348,\n",
       "        0.01235867243863753, -0.0004149702342925998, 0.005882806566320564,\n",
       "        0.007129800541319398, 0.002455377282593929, 0.008588571483874263,\n",
       "        0.00825183337373181, 0.010250921225697152, 0.032868453473620995,\n",
       "        0.04227418296154206, 0.00019618430586954005, 0.0037124902512633007,\n",
       "        0.031128587952603537, 0.004307504278308061, 0.05507992460137223,\n",
       "        0.007576288076669657, 0.0034844303572310054, 0.00704422084098022,\n",
       "        0.005662253729503464, -0.011162860423046261, 0.010387896374845829,\n",
       "        0.011646010611113367, 0.02807300560825121, 0.0038898916936735972,\n",
       "        0.0174504186519715, 0.010722794402500568, 0.04435028430927068,\n",
       "        -0.0032150270111617196, 0.008412908503211858, 0.011698900746678342,\n",
       "        -0.0016013749609984362, 0.009124504140073375, 0.015407993236101092,\n",
       "        -0.0009883150107987682, 0.0034921146857502805,\n",
       "        -0.00033189272615419263, 0.0026520580555990936,\n",
       "        0.007545174689687739, 0.01307989017097011, 0.005742538108044037,\n",
       "        0.037917097766829944, 0.0034818584006686137, 0.007913063530892828],\n",
       "       dtype=object),\n",
       " 'mask_detect_class21': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class44': array([-0.0084342 ,  0.00122999,  0.00122999, -0.01809838, -0.01809838,\n",
       "        -0.0084342 , -0.01809838, -0.01809838, -0.01809838, -0.0084342 ,\n",
       "        -0.01809838,  0.00122999,  0.00122999, -0.01809838,  0.00122999,\n",
       "         0.02055835, -0.01809838, -0.01809838, -0.01809838, -0.01809838,\n",
       "        -0.0084342 , -0.0084342 , -0.04709093, -0.01809838, -0.01809838,\n",
       "        -0.01809838, -0.01809838, -0.0084342 , -0.01809838,  1.11261097,\n",
       "        -0.01809838,  0.01089417, -0.01809838, -0.01809838, -0.0084342 ,\n",
       "        -0.01809838, -0.01809838, -0.01809838, -0.01809838, -0.0084342 ,\n",
       "        -0.02776256, -0.01809838,  0.00122999, -0.0084342 , -0.0084342 ,\n",
       "        -0.01809838, -0.01809838, -0.01809838, -0.01809838, -0.01809838,\n",
       "        -0.01809838, -0.01809838, -0.01809838, -0.01809838, -0.0084342 ,\n",
       "        -0.0084342 , -0.0084342 , -0.01809838,  0.03988672, -0.0084342 ,\n",
       "        -0.01809838, -0.0084342 , -0.0084342 , -0.01809838, -0.0084342 ,\n",
       "        -0.0084342 , -0.0084342 , -0.01809838,  0.00122999, -0.01809838,\n",
       "        -0.0084342 , -0.01809838, -0.01809838, -0.01809838, -0.0084342 ,\n",
       "        -0.01809838, -0.02776256, -0.01809838,  0.00122999, -0.01809838,\n",
       "        -0.0084342 , -0.01809838, -0.01809838, -0.02776256,  0.20417782,\n",
       "        -0.02776256, -0.01809838, -0.01809838, -0.01809838, -0.02776256,\n",
       "        -0.03742674, -0.0084342 ,  0.00122999,  0.01089417, -0.0084342 ,\n",
       "        -0.02776256, -0.01809838,  1.07395424, -0.01809838, -0.01809838]),\n",
       " 'shap_detect_class44': array([-0.008521873478835262, 0.006554231134344168,\n",
       "        -0.0059139953907018095, 0.0037953238244395893,\n",
       "        -0.010690350181428943, -0.010543468481773788, -0.00978741338011635,\n",
       "        -0.006267547232291837, -0.010516023544404951,\n",
       "        -0.009752209728730143, -0.0021668972248330975,\n",
       "        -0.011578456874960952, -0.007786672547375195,\n",
       "        -0.010273361817855542, -0.02192342074065501, -0.022691854852577964,\n",
       "        -0.008566092970901273, -0.008267137191786733,\n",
       "        -0.0017328180272975224, -0.005545214857675007,\n",
       "        -0.01687155838310639, -0.019918619697170237, 0.010313843740933137,\n",
       "        -0.01857528774597461, 2.5924822618983434e-05,\n",
       "        -0.012495226063315323, -0.014871342123247144, -0.01773281188301923,\n",
       "        7.431291093040748e-05, 1.0083960505005427, 0.0013421556974416715,\n",
       "        -0.01666668874425692, -0.017820724035494062, -0.014332248945910786,\n",
       "        -0.0007668968978497004, -0.0033718600712815405,\n",
       "        -0.01516182132817201, -0.0072305351967544285, -0.01368328409325903,\n",
       "        -0.01798492484922476, -0.009692466957837098, -0.013309499423468152,\n",
       "        -0.011021296728729757, -0.003917667778896017,\n",
       "        -0.013317602757013214, -0.011320859595702282,\n",
       "        -0.0032287511905119137, -0.012510568631686536,\n",
       "        -0.00835753410695228, -0.0002053148457055176,\n",
       "        -0.006876190697354123, -0.010754248292699775, -0.01042814106793244,\n",
       "        -0.013925196361748826, -0.01868092902086793, -0.015722258928044797,\n",
       "        -0.005608644859356748, -0.02074317274650317, -0.029407581548473116,\n",
       "        -0.019003535111935532, -0.007968360858343293,\n",
       "        -0.010886778268729413, -0.012643061338494799, 0.003213098399106551,\n",
       "        -0.011358822730166751, -0.02019630670773509, -0.009176258840256413,\n",
       "        -0.00674988041996083, -0.00710279951337589, -0.009956244730884745,\n",
       "        -0.006458606884036988, -0.012137629467167455,\n",
       "        -0.007443483515700011, -0.010089158960467581,\n",
       "        0.00039502391106349677, -0.004084268522499879,\n",
       "        -0.004164670320096153, -0.009705961795641871,\n",
       "        -0.025289313167242256, -0.02279484016932798, -0.027454068829299128,\n",
       "        -0.012609113978826358, 0.014968861415705081,\n",
       "        -0.0017713163071821914, -0.02940758154853762,\n",
       "        -0.008841818949483438, -0.009261981632282867,\n",
       "        -0.007239166324682911, -0.0052470737125052125,\n",
       "        -0.01252901698330433, -0.014008614385389695, -0.00108545513787639,\n",
       "        -0.022027644609568187, -0.02940758154842571, -0.01835807522867905,\n",
       "        -0.002473505128811837, -0.01443206016258658, 1.0083960505006289,\n",
       "        -0.005969789438074469, -0.01070841700718006], dtype=object),\n",
       " 'mask_detect_class44': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class11': array([-0.00552735,  0.00306304,  0.18346111,  0.01165342, -0.02270812,\n",
       "         0.0202438 ,  0.02883419, -0.03988889,  0.00306304,  0.00306304,\n",
       "         0.00306304, -0.01411773,  0.00306304, -0.00552735, -0.05706965,\n",
       "        -0.01411773,  0.00306304,  0.00306304, -0.05706965,  0.00306304,\n",
       "         0.00306304, -0.01411773, -0.01411773, -0.06566004, -0.04847927,\n",
       "        -0.22887734, -0.0312985 ,  0.00306304, -0.16874465,  0.01165342,\n",
       "        -0.03988889, -0.0312985 , -0.00552735, -0.02270812, -0.00552735,\n",
       "         0.00306304, -0.00552735,  0.00306304, -0.00552735, -0.02270812,\n",
       "        -0.01411773,  0.04601496, -0.00552735,  0.00306304,  0.01165342,\n",
       "        -0.02270812, -0.09143119,  0.02883419,  0.00306304,  0.0202438 ,\n",
       "        -0.03988889, -0.01411773, -0.00552735, -0.00552735,  0.63875148,\n",
       "         0.00306304, -0.00552735, -0.03988889,  0.04601496,  0.07178611,\n",
       "        -0.00552735, -0.01411773, -0.00552735,  0.02883419, -0.02270812,\n",
       "         0.00306304,  0.00306304, -0.00552735, -0.00552735,  0.00306304,\n",
       "        -0.04847927, -0.05706965, -0.00552735, -0.00552735, -0.02270812,\n",
       "        -0.01411773,  0.00306304,  0.00306304, -0.00552735, -0.03988889,\n",
       "         0.10614765, -0.02270812,  0.75042648,  0.01165342, -0.01411773,\n",
       "        -0.01411773, -0.02270812,  0.0202438 ,  0.26936495, -0.00552735,\n",
       "        -0.01411773, -0.00552735,  0.02883419, -0.00552735,  0.01165342,\n",
       "        -0.03988889, -0.0312985 ,  0.0202438 ,  0.04601496, -0.00552735]),\n",
       " 'shap_detect_class11': array([0.010581568943412, -0.024401324979235972, 0.07692919652191355,\n",
       "        0.01652792693165972, -0.005887339691357241, 0.011271518925138557,\n",
       "        0.008142312580691757, -0.011397654230832499, 0.007293022077021427,\n",
       "        -0.0026694531640860664, -0.0008203496634551222,\n",
       "        0.0038221330053426206, 0.003136912324409158, 0.0017787797062436272,\n",
       "        0.0007921393061190996, -0.013105073205363804, -0.02004805317388636,\n",
       "        -0.012381563762351444, -0.015534716174515073,\n",
       "        -0.019701265946659885, -0.01480032896802419, -0.006821124160645398,\n",
       "        -0.03152734853027839, 0.14064326301700347, -0.006664316277686155,\n",
       "        0.0018963063322463558, 0.03084826925663975, -0.023852016285465294,\n",
       "        0.17027661316078313, 0.03151183460933005, -0.02121762703522656,\n",
       "        0.0559913835268272, 0.0038889612696830778, 0.05039817322705775,\n",
       "        -0.02188156809120756, -0.02352325074087258, -0.00538942089275396,\n",
       "        0.002280944423684761, -0.01449893180673345, -0.017260686142137605,\n",
       "        0.0002115266604673094, 0.18853305482227178, 0.007680292280255352,\n",
       "        -0.0005591378255564994, -0.007565065582134767,\n",
       "        0.007944588621179416, 0.009892618994212343, -0.002792487965297963,\n",
       "        -0.017507977289372367, 0.0005393555693586904, 0.005169477041440773,\n",
       "        -0.007429235867962181, -0.005060469424516434,\n",
       "        -0.013939262451487133, -0.04222603530631963, 0.011721433127149461,\n",
       "        -0.004667427670209112, -0.006329426006366545, 0.08150119692785651,\n",
       "        -0.0021408818234203153, -0.013099791415918882,\n",
       "        0.021365905066819457, -0.012475465411495579, 0.029986778491875365,\n",
       "        -0.009643394327499721, 0.016550855737763825, 0.0053488566774280155,\n",
       "        -0.02304882925770968, 0.007935629423213242, -0.0149866662946333,\n",
       "        0.0037086554291838603, 0.00543537742186373, -0.017151077325810893,\n",
       "        -0.011382572673756086, -0.0005000138991040348,\n",
       "        -0.02395502727822063, -0.014771698694350022, -0.00435952055165667,\n",
       "        0.0710783770608252, -0.011554154882469803, 0.07170472660114313,\n",
       "        0.012924330212821133, 0.14080273160957557, 0.016456443005745558,\n",
       "        0.0011390521576866153, -0.011968596809430632,\n",
       "        -0.013436392810053266, 0.04305236735236451, 0.043316887312528696,\n",
       "        -0.006236542833664815, 0.0008807730878587217,\n",
       "        -0.019308233016881227, 0.017120957578239837, -0.007024991964773797,\n",
       "        0.017123626311423834, -0.015515935465459263, 0.024705965563286525,\n",
       "        0.049225513755844275, 0.10918896550705814, -0.016035125384831872],\n",
       "       dtype=object),\n",
       " 'mask_detect_class11': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class1': array([ 0.00427116,  0.53951819,  0.03400711,  0.03400711,  0.03400711,\n",
       "        -0.08493668, -0.02546478,  0.03400711, -0.14440857,  0.03400711,\n",
       "         0.093479  ,  0.00427116,  0.00427116,  0.00427116,  0.12321495,\n",
       "         0.06374306,  0.06374306, -0.02546478, -0.02546478, -0.02546478,\n",
       "        -0.02546478,  0.00427116, -0.17414451,  0.00427116, -0.08493668,\n",
       "         0.00427116, -0.05520073,  0.06374306, -0.05520073, -0.05520073,\n",
       "        -0.08493668,  0.03400711,  0.00427116,  0.00427116,  0.06374306,\n",
       "         0.00427116, -0.08493668,  0.00427116, -0.05520073, -0.02546478,\n",
       "         0.06374306, -0.02546478, -0.08493668,  0.00427116, -0.02546478,\n",
       "         0.00427116,  0.00427116,  0.03400711, -0.05520073,  0.03400711,\n",
       "        -0.02546478,  0.12321495,  0.093479  ,  0.15295089, -0.11467262,\n",
       "         0.03400711,  0.00427116,  0.00427116, -0.11467262, -0.02546478,\n",
       "        -0.02546478,  0.03400711,  0.00427116, -0.11467262, -0.02546478,\n",
       "         0.18268684, -0.05520073,  0.00427116,  0.00427116,  0.06374306,\n",
       "         0.03400711,  0.21242279, -0.05520073, -0.02546478, -0.02546478,\n",
       "        -0.02546478, -0.14440857, -0.02546478, -0.20388046,  0.12321495,\n",
       "        -0.2930883 , -0.02546478,  0.06374306, -0.05520073,  0.00427116,\n",
       "        -0.05520073,  0.03400711,  0.00427116,  0.03400711,  0.00427116,\n",
       "        -0.08493668, -0.05520073, -0.08493668,  0.15295089,  0.03400711,\n",
       "         0.33136657,  0.093479  ,  0.18268684, -0.02546478,  0.12321495]),\n",
       " 'shap_detect_class1': array([-0.04584661830553727, 0.6624048453665513, -0.0579639991339046,\n",
       "        -0.010489906467581411, 0.0018029180476747397,\n",
       "        -0.028577231009567328, -0.04859261018806116, -0.023984091468841506,\n",
       "        0.056923300413992295, 0.03614534522472146, 0.07635102962602425,\n",
       "        0.04453102273827303, 0.10112604770511513, -0.030716494404096184,\n",
       "        -0.048091487339251504, -0.021295385459035865, 0.007225784734187335,\n",
       "        0.027732889332425015, 0.006039565803409697, -0.04161128323391561,\n",
       "        -0.060787566712282026, 0.07216682308073163, -0.0016969214025046586,\n",
       "        0.016324911528487474, -0.05534755943682701, -0.0018860832015106244,\n",
       "        -0.07295185024363338, 0.040466611397886765, -0.016459184615646216,\n",
       "        0.09233287801637069, 0.014126278212888477, 0.052757880844106486,\n",
       "        -0.02885758184272913, 0.015332566625190003, -0.020649564376337803,\n",
       "        -0.040854301062756004, -0.036592014859455846,\n",
       "        -0.020498876574683855, -0.018668385923857334,\n",
       "        -0.027605742058541938, -0.0058989029178829755,\n",
       "        0.014462692549108147, -0.03976092547378096, -0.019024606000290656,\n",
       "        0.015329533622289282, -0.043287590566264744, 0.060454058553854995,\n",
       "        -0.02946424266127523, -0.01753886379346148, -0.005347663021245452,\n",
       "        -0.05533665813820343, 0.02146614416144854, -0.015729550190149544,\n",
       "        0.05381629571298219, -0.056344291689639725, -0.01375513776391235,\n",
       "        -0.019976809406769935, -0.04845709289578626, 0.005960785163420357,\n",
       "        -0.0027528411613282344, 0.004715414438874466, 0.033042550809324944,\n",
       "        0.04314399679704428, -0.05048041646325896, -0.02662973114629985,\n",
       "        0.12274695670591773, -0.04319987896787636, -0.025715634547797128,\n",
       "        -0.0620295569088386, 0.04892541202448342, -0.04789090681496133,\n",
       "        0.1496077565942564, 0.04199322859605892, -0.05721663525274978,\n",
       "        0.028811929132188996, 0.007406523785570163, 0.03541417801744795,\n",
       "        -0.05448386281892992, -0.002119021618921191, 0.15338687346162938,\n",
       "        -0.03013987892987713, 0.013537343018562575, 0.03865000088921566,\n",
       "        -0.04870243924170081, 0.01181089207314756, -0.028474369718946346,\n",
       "        0.020968705514091468, -0.0372380526390822, 0.09641749418925105,\n",
       "        0.04859219726573427, -0.01580240407784017, -0.037922830257840046,\n",
       "        -0.032424447225334996, 0.03972266614218045, 0.03300165214406581,\n",
       "        0.048371029742473315, 0.0231178080293174, 0.0107088011599491,\n",
       "        -0.008433205936123067, 0.06219514035666407], dtype=object),\n",
       " 'mask_detect_class1': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class17': array([-0.00410673, -0.00410673, -0.0520283 ,  0.00547758,  0.00547758,\n",
       "        -0.03285967,  0.07256777, -0.00410673,  0.01506189,  0.01506189,\n",
       "        -0.00410673,  0.03423052, -0.00410673, -0.00410673, -0.00410673,\n",
       "        -0.00410673,  0.02464621,  0.01506189, -0.00410673, -0.01369105,\n",
       "         0.00547758, -0.01369105,  0.00547758, -0.00410673, -0.00410673,\n",
       "         0.04381483,  0.02464621, -0.00410673,  0.02464621, -0.00410673,\n",
       "        -0.00410673,  0.13965796, -0.00410673, -0.02327536,  0.04381483,\n",
       "         0.02464621, -0.00410673, -0.00410673,  0.00547758, -0.00410673,\n",
       "        -0.00410673, -0.02327536,  0.08215209,  0.01506189,  0.00547758,\n",
       "        -0.00410673,  0.00547758,  0.03423052, -0.00410673,  0.00547758,\n",
       "        -0.00410673,  0.00547758, -0.00410673,  0.06298346,  0.19716384,\n",
       "        -0.00410673, -0.00410673, -0.01369105,  0.00547758, -0.03285967,\n",
       "         0.00547758, -0.03285967, -0.01369105, -0.00410673, -0.00410673,\n",
       "        -0.00410673, -0.00410673,  0.0917364 , -0.00410673, -0.00410673,\n",
       "         0.25466972,  0.02464621, -0.00410673, -0.00410673, -0.00410673,\n",
       "        -0.00410673, -0.00410673, -0.00410673,  0.07256777, -0.01369105,\n",
       "        -0.01369105, -0.00410673,  0.0917364 ,  0.00547758, -0.01369105,\n",
       "         0.00547758,  0.03423052,  0.04381483, -0.0520283 , -0.00410673,\n",
       "        -0.01369105, -0.00410673, -0.01369105, -0.00410673, -0.00410673,\n",
       "        -0.00410673, -0.02327536,  0.01506189,  0.06298346,  0.02464621]),\n",
       " 'shap_detect_class17': array([0.005514367423380406, 0.016391768116069905, 0.013505976491933858,\n",
       "        0.006661694773683724, 0.006364599846053309, 0.013330930549716458,\n",
       "        0.007587425624922872, 0.005879691090493466, 0.007976404885396082,\n",
       "        0.0071697923195988, 0.016958755607128895, 0.0044784927210888,\n",
       "        0.023983246988564577, 0.005092253088096577, 0.006856253659883738,\n",
       "        0.008267145725830094, 0.0044927560045244785, 0.006609016805823709,\n",
       "        0.01993520456661102, 0.00480137444410067, 0.00795621661739343,\n",
       "        0.011122653242666036, 0.006303260397596988, 0.02809028864883567,\n",
       "        0.016775232318887667, 0.003561945773225217, 0.0061643335789804965,\n",
       "        0.005503185039264835, 0.006858606822645719, 0.017534910151176364,\n",
       "        0.01599282136461566, 0.007315569740600436, 0.0058025365041038945,\n",
       "        0.004617421014843082, 0.04167137516333397, 0.005769714761798328,\n",
       "        0.0236192704603857, 0.011681425904063403, 0.0068590162773030094,\n",
       "        0.01794352610251093, 0.01901430759931433, 0.00444977731767926,\n",
       "        0.005323618923242623, 0.006879877730140871, 0.005559407373375569,\n",
       "        0.006445026922234476, 0.057012712267596966, 0.005770414329168583,\n",
       "        0.005203650764523227, 0.005751593231186458, 0.006225697409539599,\n",
       "        0.006238636752075921, 0.01664413338404258, 0.004708368059199941,\n",
       "        0.005189435894479066, 0.017836909487065622, 0.00611386202737374,\n",
       "        0.012092512729412253, 0.007969261718918652, 0.020225741452149393,\n",
       "        0.006301423934498063, 0.014845327686391796, 0.013646034002605667,\n",
       "        0.005480162481267703, 0.006408868067649953, 0.018886057026858305,\n",
       "        0.005392730457996375, 0.007059247230703836, 0.0049378618483910675,\n",
       "        0.006521473795080723, 0.009773061296469487, 0.008616465735867163,\n",
       "        0.006640992742981799, 0.01577993357425389, 0.00458503133247401,\n",
       "        0.004992817050744058, 0.014842852361053982, 0.005352844081466301,\n",
       "        0.009256191886302556, 0.0033599650017228644, 0.0058999844673013335,\n",
       "        0.004961957591093302, 0.014908611236899016, 0.00494205329518449,\n",
       "        0.0053199964771937225, 0.005749860979832322, 0.006050590099467179,\n",
       "        0.008856862263371124, 0.020855330458303678, 0.019021266932688574,\n",
       "        0.014396412104427991, 0.0052036507644928065, 0.013936059933487899,\n",
       "        0.01670579729573407, 0.006010585772002752, 0.005503185039285263,\n",
       "        0.014698428919425188, 0.00543954053265816, 0.01254348326314636,\n",
       "        0.007909206216496045], dtype=object),\n",
       " 'mask_detect_class17': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class40': array([-0.02300265,  0.00149809,  0.00149809,  0.00149809, -0.00666882,\n",
       "        -0.02300265, -0.02300265, -0.00666882,  0.00149809,  0.00149809,\n",
       "         0.00966501,  0.01783192,  0.00149809, -0.00666882, -0.00666882,\n",
       "        -0.01483574, -0.03116957,  0.00966501,  0.00149809, -0.02300265,\n",
       "        -0.03116957,  0.00966501, -0.01483574, -0.01483574,  0.00149809,\n",
       "        -0.00666882, -0.01483574, -0.00666882, -0.02300265,  0.06683341,\n",
       "        -0.01483574,  0.00966501, -0.00666882,  0.00149809,  0.00149809,\n",
       "         0.00149809,  0.00149809,  0.00149809, -0.01483574,  0.00149809,\n",
       "         0.00149809, -0.03116957,  0.00149809,  0.00149809,  0.00966501,\n",
       "        -0.02300265,  0.00149809,  0.49151298, -0.01483574,  0.00149809,\n",
       "        -0.06383723, -0.00666882,  0.00149809,  0.00149809, -0.05567031,\n",
       "        -0.01483574,  0.00149809, -0.07200414,  0.02599884, -0.01483574,\n",
       "         0.00149809,  0.00149809,  0.00966501,  0.01783192,  0.00149809,\n",
       "         0.00149809,  0.00149809, -0.02300265, -0.01483574,  0.00149809,\n",
       "         0.00149809,  0.00149809,  0.00149809,  0.00149809,  0.00149809,\n",
       "         0.00149809, -0.03116957, -0.07200414,  0.00149809, -0.00666882,\n",
       "         0.04233267, -0.00666882,  0.09950107,  0.00149809, -0.00666882,\n",
       "         0.00149809,  0.00149809, -0.00666882,  0.01783192,  0.00149809,\n",
       "        -0.00666882,  0.00149809,  0.93252638, -0.01483574,  0.00149809,\n",
       "        -0.00666882,  0.00149809,  0.00149809,  0.00149809,  0.00149809]),\n",
       " 'shap_detect_class40': array([-0.03316292493903983, 0.018912789188434864, -0.01679337970899475,\n",
       "        -0.023124093179571314, -0.015583697086066772,\n",
       "        -0.050757424657733585, -0.024474939884888358,\n",
       "        -0.027745593094583798, 0.021818442885083278, 0.03810232518192025,\n",
       "        0.0051412208631558265, 0.10814857452318383, 0.04428508073265436,\n",
       "        -0.02197335991142435, -0.0461163956120304, -0.022747959055926747,\n",
       "        -0.018903927990516545, 0.005553863432317119,\n",
       "        -0.0015688006080905037, -0.025876527056423182,\n",
       "        -0.025534380098019005, 0.14568233667511132, -0.030188573494643656,\n",
       "        0.083658470780962, -0.018538701671850122, -0.014298431550566981,\n",
       "        -0.019992266971043615, -0.030391046834208346, -0.03531785821272759,\n",
       "        0.30515383821117603, -0.03604460016781619, -0.0040265479412929794,\n",
       "        -0.013994542431710166, 0.005971048854975902, -0.01611571224405084,\n",
       "        0.0011969909978957194, -0.020218583696000048,\n",
       "        -0.005633814766446088, -0.018258674369468597, -0.01870400253634108,\n",
       "        -0.003462631712820241, -0.02748225298368223, 0.03327090718972814,\n",
       "        -0.010716075251674395, 0.023543343196973376, -0.021693352325892423,\n",
       "        -0.02343460569974598, 0.014269783721065021, -0.026274981386191443,\n",
       "        -0.006807046811899586, -0.024914638631707398,\n",
       "        -0.022529574520671836, -0.020033525074543035,\n",
       "        -0.004198848102515251, -0.03247027710612549, -0.03293232746808372,\n",
       "        0.02492332767403016, 0.00429012635944892, 0.15309307438632913,\n",
       "        -0.03295542784389349, -0.008821231679250419, -0.029550444563801292,\n",
       "        0.01253423387979713, 0.06926197448117954, 0.0098719813336281,\n",
       "        0.011124535687912496, -0.036167378495226776, -0.03533485085673371,\n",
       "        -0.013177824786468562, -0.01327637764232581, -0.01729796982088494,\n",
       "        -0.011179876297467195, -0.014370012203864801, -0.00827204171046092,\n",
       "        -0.01726778732288614, 0.10279210231631453, 0.005359828460125837,\n",
       "        -0.01691638614762503, -0.04281700232543739, 0.09140184059474332,\n",
       "        0.34630907850912607, -0.013493574367954397, 0.14762421744904686,\n",
       "        -0.008563831669650468, 0.029033351789467865, 0.011987301794443184,\n",
       "        -0.010094077270243584, 0.00037847570004578834, 0.06512619261240105,\n",
       "        -0.004040372051953178, -0.0224273215591978, -0.0007393871158717369,\n",
       "        0.36581817779380454, -0.03759500912466718, 0.00973877265254075,\n",
       "        -0.021283313964287176, -0.014770298691344719, -0.03135204798809843,\n",
       "        0.01867884843075851, -0.016700449770510772], dtype=object),\n",
       " 'mask_detect_class40': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class12': array([-0.01621923, -0.02829946, -0.02829946, -0.01621923, -0.02829946,\n",
       "         0.08042259, -0.004139  , -0.02829946, -0.06454014, -0.01621923,\n",
       "         0.00794122,  0.00794122, -0.01621923, -0.01621923, -0.01621923,\n",
       "        -0.01621923, -0.02829946, -0.004139  , -0.02829946, -0.02829946,\n",
       "        -0.02829946,  0.03210168, -0.02829946, -0.004139  ,  0.11666328,\n",
       "         0.02002145, -0.01621923, -0.02829946, -0.02829946, -0.02829946,\n",
       "        -0.02829946, -0.02829946, -0.004139  ,  0.00794122, -0.004139  ,\n",
       "        -0.01621923, -0.01621923, -0.02829946, -0.004139  , -0.02829946,\n",
       "         0.84147696,  0.03210168, -0.01621923, -0.02829946, -0.04037969,\n",
       "        -0.05245992, -0.004139  , -0.02829946, -0.02829946,  0.06834237,\n",
       "        -0.02829946,  0.03210168, -0.02829946, -0.02829946, -0.02829946,\n",
       "        -0.01621923, -0.01621923, -0.02829946, -0.01621923, -0.01621923,\n",
       "        -0.004139  , -0.004139  ,  0.12874351, -0.02829946, -0.02829946,\n",
       "        -0.01621923, -0.02829946, -0.004139  , -0.01621923, -0.02829946,\n",
       "        -0.01621923,  0.33410738, -0.02829946,  0.00794122, -0.01621923,\n",
       "        -0.01621923, -0.02829946, -0.01621923,  0.00794122, -0.02829946,\n",
       "         0.00794122, -0.01621923,  0.11666328, -0.02829946, -0.01621923,\n",
       "        -0.02829946, -0.02829946, -0.01621923,  0.00794122,  0.03210168,\n",
       "        -0.01621923, -0.02829946, -0.01621923, -0.01621923, -0.01621923,\n",
       "        -0.02829946, -0.02829946, -0.01621923,  0.91395833, -0.01621923]),\n",
       " 'shap_detect_class12': array([-0.017740903521238804, -0.009553670870284692,\n",
       "        -0.023539051252375875, -0.001936883650713983,\n",
       "        -0.015132181403082479, -0.034536205756086846,\n",
       "        -0.016399674806511833, -0.02019700760437093, 0.05197274531021523,\n",
       "        0.012369382038975196, -0.008145978593517178, 0.0017164822046938921,\n",
       "        0.026682198214614372, -0.0150738872388273, -0.06738578498312853,\n",
       "        -0.03397095323436472, -0.03168407346142188, 0.01498204827838423,\n",
       "        -0.013034281823966931, -0.017120207568730672, -0.05340573729229248,\n",
       "        -0.005290111450330648, -0.020181463115147347,\n",
       "        -0.012275523812660283, 0.1536928843701203, 0.026255852367291443,\n",
       "        -0.03126411016615127, -0.02422284230876881, 0.004992905230684408,\n",
       "        -0.014719903627495978, 0.001177750288235302, -0.021309296720364967,\n",
       "        -0.01647343483795438, -0.013391191158211302, 0.001281040121371979,\n",
       "        -0.024248313507947095, -0.01955701389949982, -0.022065634609433005,\n",
       "        -0.017351958249781974, -0.027979640289535812, 1.2728928797172387,\n",
       "        -0.014200218665721409, -0.004502455039458786,\n",
       "        -0.027312174585743088, -0.046667394517105554, -0.04338561607367142,\n",
       "        0.003156425418193276, -0.029585950783658888, -0.02302225389517576,\n",
       "        0.0007464920442696865, -0.03808580122381067, -0.015063714205191703,\n",
       "        -0.01510102321445439, -0.018149931806287545, -0.03783167798718967,\n",
       "        -0.003948839517471714, 0.0003479499428120647, -0.02508705896848662,\n",
       "        -0.02244844137647195, -0.03007529395397701, -0.02957813362684847,\n",
       "        -0.011260904701340557, -0.050507875880244635, -0.0418419883644503,\n",
       "        -0.006629491059859438, 0.008817596236148528, -0.027797557010754703,\n",
       "        -0.013854302698741994, -0.001509994416088345,\n",
       "        -0.022567845140954446, -0.026580294094618817, 0.09357057057055951,\n",
       "        -0.03114040298918408, -0.012555196066876495, 0.003408314519700806,\n",
       "        -0.017098743841347797, -0.016296471907495946,\n",
       "        -0.020665778463575868, -0.004970283610560067,\n",
       "        -0.036703058211217665, 0.004909724149588124, -0.013729727110489143,\n",
       "        -0.011739724278574282, -0.028652213484636646,\n",
       "        -0.011850588890585323, -0.03754413831583858, -0.01963765337282175,\n",
       "        -0.02564335149171182, -0.012102814852379296, 0.07051844517481776,\n",
       "        -0.023955633884018, -0.015536799527400502, -0.0027696177103923025,\n",
       "        -0.027273567280330147, -0.03373586349930424, -0.007010426650086998,\n",
       "        -0.034430441251235955, -0.032846847272866575, 0.9269583357007873,\n",
       "        0.0001808113874517403], dtype=object),\n",
       " 'mask_detect_class12': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class15': array([-2.16351535e-02,  3.41197454e-02,  6.66806063e-04,  6.66806064e-04,\n",
       "         1.18177858e-02,  6.66806064e-04, -3.27861333e-02,  2.29687656e-02,\n",
       "        -2.16351535e-02,  1.18177858e-02,  1.18177858e-02,  6.66806063e-04,\n",
       "        -1.04841737e-02,  1.18177858e-02,  6.66806063e-04,  6.66806063e-04,\n",
       "         6.66806063e-04,  1.18177858e-02,  1.18177858e-02,  1.18177858e-02,\n",
       "        -1.04841737e-02,  1.18177858e-02,  4.52707252e-02,  1.18177858e-02,\n",
       "        -2.16351535e-02,  2.29687656e-02, -1.04841737e-02,  6.66806063e-04,\n",
       "        -2.16351535e-02, -1.04841737e-02, -1.04841737e-02,  2.29687656e-02,\n",
       "         1.18177858e-02,  1.18177858e-02, -3.27861333e-02,  6.66806063e-04,\n",
       "         7.58933431e-01,  6.66806063e-04,  1.18177858e-02,  6.66806063e-04,\n",
       "         2.29687656e-02, -1.04841737e-02, -2.16351535e-02, -1.04841737e-02,\n",
       "         6.66806063e-04, -3.27861333e-02,  6.66806063e-04, -1.04841737e-02,\n",
       "         1.18177858e-02,  2.29687656e-02, -3.27861333e-02,  1.18177858e-02,\n",
       "         2.29687656e-02,  2.90592280e-01, -4.39371130e-02, -1.04841737e-02,\n",
       "         1.18177858e-02,  6.66806063e-04, -3.27861333e-02, -2.16351535e-02,\n",
       "         6.66806063e-04, -1.04841737e-02, -1.04841737e-02, -3.27861333e-02,\n",
       "         1.18177858e-02, -1.04841737e-02,  6.66806063e-04,  1.18177858e-02,\n",
       "        -1.04841737e-02,  6.66806063e-04,  2.29687656e-02,  1.18177858e-02,\n",
       "         1.18177858e-02,  1.18177858e-02,  1.18177858e-02,  2.29687656e-02,\n",
       "        -4.39371130e-02,  6.66806063e-04, -1.04841737e-02,  1.18177858e-02,\n",
       "        -1.04841737e-02,  1.18177858e-02,  6.66806063e-04,  1.18177858e-02,\n",
       "        -1.04841737e-02,  1.18177858e-02,  1.18177858e-02, -2.16351535e-02,\n",
       "         1.18177858e-02,  1.18177858e-02, -1.04841737e-02, -2.16351535e-02,\n",
       "        -2.16351535e-02,  1.18177858e-02,  6.66806063e-04,  6.66806063e-04,\n",
       "         1.18177858e-02, -1.04841737e-02,  6.66806063e-04,  6.66806063e-04]),\n",
       " 'shap_detect_class15': array([-0.0006718432591816814, 0.0316572491500513, 0.002155733465807108,\n",
       "        0.00031964928102823364, 0.0026417754279868255, 0.02205281481300858,\n",
       "        0.011525436860780003, 0.005520884029369011, 0.02563634079442134,\n",
       "        0.016171097389189537, 0.036768964715326646, 0.018532952776125544,\n",
       "        0.0038720266156144767, 0.002816620425832417, 0.02058721008607245,\n",
       "        0.0016636307924684512, 0.002254017327153024, 0.0027906103094976764,\n",
       "        0.018249323786498683, 0.006025414057694967, 0.006866367533049589,\n",
       "        0.0033237710761011563, 0.01480565831137648, 0.005909419943874283,\n",
       "        0.0073816299581728195, 0.01061384942339716, 0.009699102647649616,\n",
       "        0.007879839658887944, 0.016161254986755358, 0.0223267205487363,\n",
       "        0.008562017786574616, 0.016728927878704614, 0.0019162702531059228,\n",
       "        0.006105420151158558, 0.020685204603394514, 0.008475086104346774,\n",
       "        -0.007587426011115284, 0.010359891447633496, 0.003216472725570352,\n",
       "        0.005775083762485478, 0.014838102652657392, 0.0004253558206204211,\n",
       "        0.00686644113264534, 0.007524152716430033, 0.0025883459888860205,\n",
       "        0.005063492839246786, 0.00677777641898869, 0.004967727323899718,\n",
       "        0.0011367106069211097, 0.0006067874015522889, 0.007942679519667095,\n",
       "        0.002240577176523262, 0.013458335345002181, 0.021105472622994448,\n",
       "        0.014887804622179424, 0.000778103035841804, -5.82841163672132e-05,\n",
       "        0.0014965202588144155, 0.021723385625461056, 0.01460766929243773,\n",
       "        0.0314120939484126, 0.018459410244293206, 0.026388288133360138,\n",
       "        0.024969975940109634, 0.009585532122114104, 0.02537034635463309,\n",
       "        0.005408326089677784, 0.005923035929793485, 0.008742403395805676,\n",
       "        0.004992011953162123, 0.009338453272819347, 0.009613013740717102,\n",
       "        0.004129071174272525, 0.003054391531503997, 0.01745049378314656,\n",
       "        0.013297167203483395, 0.0036979063356699093, 0.003203134388387374,\n",
       "        0.031841323611820016, 0.004626590207644998, 0.017254395651532306,\n",
       "        0.002872176013290595, 0.0023862712320108503, 0.010508944215949612,\n",
       "        0.00486154920775661, 0.00850762464354582, 0.006081791492897226,\n",
       "        0.009700480829017755, 0.012832968905241993, 0.009059048287429983,\n",
       "        0.009299113959953642, 0.006648563454561662, 0.01778448426500412,\n",
       "        0.015999020171867828, 0.018228584736326825, 0.02830637259137836,\n",
       "        0.005304544573380365, 0.0051994418176692925, 0.0016740191715993724,\n",
       "        0.01745221353833415], dtype=object),\n",
       " 'mask_detect_class15': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class23': array([-0.00283743, -0.00283743,  0.01326954, -0.00283743, -0.0189444 ,\n",
       "         0.99579476, -0.0189444 , -0.00283743,  0.43205078, -0.00283743,\n",
       "        -0.03505137, -0.0189444 , -0.00283743, -0.00283743,  0.07769742,\n",
       "        -0.00283743, -0.00283743, -0.05115834, -0.00283743,  0.01326954,\n",
       "         0.01326954, -0.06726531, -0.0189444 , -0.03505137,  0.04548348,\n",
       "        -0.03505137, -0.00283743, -0.00283743, -0.00283743, -0.00283743,\n",
       "         0.01326954,  0.01326954, -0.00283743, -0.03505137, -0.00283743,\n",
       "        -0.00283743, -0.00283743, -0.00283743, -0.0189444 , -0.00283743,\n",
       "        -0.05115834, -0.00283743, -0.00283743, -0.00283743,  0.04548348,\n",
       "         0.57701352, -0.00283743, -0.0189444 , -0.00283743, -0.03505137,\n",
       "        -0.00283743, -0.05115834, -0.00283743, -0.00283743, -0.00283743,\n",
       "        -0.00283743, -0.00283743, -0.00283743, -0.03505137, -0.00283743,\n",
       "        -0.06726531, -0.0189444 , -0.06726531,  0.01326954, -0.00283743,\n",
       "        -0.00283743, -0.00283743, -0.05115834, -0.0189444 , -0.00283743,\n",
       "        -0.00283743,  0.06159045, -0.00283743, -0.00283743, -0.00283743,\n",
       "        -0.03505137, -0.03505137, -0.00283743,  0.01326954,  0.01326954,\n",
       "        -0.05115834, -0.00283743, -0.05115834, -0.00283743, -0.00283743,\n",
       "        -0.0189444 , -0.00283743, -0.00283743, -0.05115834, -0.05115834,\n",
       "        -0.00283743, -0.00283743, -0.00283743, -0.00283743, -0.00283743,\n",
       "         0.01326954, -0.00283743, -0.00283743, -0.06726531, -0.0189444 ]),\n",
       " 'shap_detect_class23': array([0.0014975312662746099, -0.004695841529612665, 0.00641794453257738,\n",
       "        -0.0004271872345940064, 0.012418154630756684,\n",
       "        -0.022778577084932472, -0.00670935955637042, 0.004166757185689152,\n",
       "        -0.022778577084824225, 0.0005441249500023337, 0.034516831767891554,\n",
       "        -0.002859442857078287, 0.028442916610393332,\n",
       "        -0.0034184700557491343, 0.0032260013138631916,\n",
       "        0.0033876366491411014, -0.0011954459348745283,\n",
       "        0.015716731940379702, 0.009112086992393742, 0.008806750847033418,\n",
       "        0.0020928300215542484, 0.01360024071121102, 0.011998885052940556,\n",
       "        -0.0010947067880032746, 0.0971868789558279, 0.01713694722462278,\n",
       "        -0.0028146226366306815, 0.002939210042208651,\n",
       "        0.0015347175926901935, 0.004259294353610499, 0.02998821411329211,\n",
       "        0.019436163174901266, -0.005490581195067068,\n",
       "        -0.0008467791962859517, 0.00832653558505747, -0.002124647513802702,\n",
       "        -0.005314641994914049, 0.01420147541889294, -0.0019178128763268631,\n",
       "        0.0006012293943414848, 0.036983384226926264, 0.0029362318453814984,\n",
       "        0.00014158530754315723, -0.0009174035977184136,\n",
       "        0.004374220044981114, -0.005691873943571957, 0.003345024997225332,\n",
       "        0.014604948107245441, -0.002702018726765343, 0.018360772262523528,\n",
       "        0.0020043845090069734, 0.005518316725968586, 0.007190444087153525,\n",
       "        0.008134722593076571, -0.0030728880471125875,\n",
       "        -0.00032242055133724357, 0.0016267242650541691,\n",
       "        -0.004522943604177709, 0.0026937643290984026,\n",
       "        -0.00022953617036558516, 0.051616696475568435,\n",
       "        0.0001897036477713776, 0.030012427768995154, 0.0027705765402386007,\n",
       "        0.0006440743328908205, -0.002754165631628225,\n",
       "        -0.0022583809255397602, 0.19914638541988494,\n",
       "        -0.0034199762689256508, -0.0036611417576454253,\n",
       "        0.0011182170741181885, 0.1577090110976107, -0.0002007036195083023,\n",
       "        0.010064794786995068, 0.004786917808058511, 0.018386978697644052,\n",
       "        0.014881124814749569, -0.0012051448274054133, 0.012581371080721215,\n",
       "        0.008475580960463525, 0.01081597817748492, 0.0009270648034741535,\n",
       "        0.0006843593225249744, 0.001895607237414887, 0.002329575303398612,\n",
       "        0.011329410097890347, 0.0013893682464286572,\n",
       "        -0.0002696433866116177, 0.013917900510730385, 0.025074929673286395,\n",
       "        -0.0007591886857600816, 0.0003614572309090791,\n",
       "        -0.0038557607762265134, -0.0024602803068053403,\n",
       "        -0.006079452049895018, 0.014662399895541411, 0.001020188628690022,\n",
       "        0.007528237742012611, 0.06668249800727433, 0.013401222369481047],\n",
       "       dtype=object),\n",
       " 'mask_detect_class23': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class28': array([ 0.0962838 ,  0.16161912,  0.17795295, -0.00171918,  0.01461465,\n",
       "         0.19428678, -0.08338832, -0.01805301, -0.09972215, -0.08338832,\n",
       "        -0.09972215, -0.13238981,  0.03094848, -0.01805301,  0.01461465,\n",
       "         0.03094848,  0.21062061, -0.05072067, -0.01805301,  0.01461465,\n",
       "         0.01461465, -0.03438684,  0.06361614, -0.03438684, -0.01805301,\n",
       "        -0.13238981, -0.08338832, -0.01805301, -0.05072067, -0.03438684,\n",
       "        -0.00171918, -0.01805301, -0.01805301, -0.08338832, -0.01805301,\n",
       "         0.22695444,  0.01461465,  0.04728231, -0.03438684, -0.01805301,\n",
       "        -0.05072067,  0.24328827, -0.06705449,  0.06361614, -0.00171918,\n",
       "        -0.01805301, -0.01805301,  0.21062061,  0.04728231, -0.05072067,\n",
       "        -0.00171918, -0.03438684, -0.00171918, -0.00171918,  0.29228975,\n",
       "        -0.03438684, -0.03438684,  0.0962838 , -0.11605598,  0.06361614,\n",
       "        -0.00171918, -0.03438684, -0.03438684,  0.01461465, -0.00171918,\n",
       "        -0.03438684,  0.07994997, -0.01805301, -0.03438684,  0.0962838 ,\n",
       "        -0.01805301, -0.00171918, -0.01805301, -0.01805301, -0.03438684,\n",
       "        -0.08338832, -0.00171918, -0.00171918, -0.00171918,  0.04728231,\n",
       "        -0.08338832, -0.11605598,  0.12895146,  0.01461465, -0.09972215,\n",
       "        -0.00171918, -0.00171918, -0.06705449, -0.05072067, -0.06705449,\n",
       "        -0.01805301, -0.01805301, -0.11605598, -0.00171918, -0.00171918,\n",
       "         0.14528529, -0.01805301,  0.42296039,  0.07994997, -0.01805301]),\n",
       " 'shap_detect_class28': array([0.027657146555667866, 0.03976576790591657, -0.012120069262068878,\n",
       "        0.014907370396924469, -0.013334099073669003, 0.0755946939082277,\n",
       "        -0.009050218053978432, 0.0020609512053553214, 0.02809208581203515,\n",
       "        0.004031818738525095, 0.0029035197408462388, -0.011626093129096904,\n",
       "        0.02254884545237923, 0.0162735092888473, 0.02161175444791541,\n",
       "        -0.011133326003027855, 0.049280563472074435, 0.006272456036719998,\n",
       "        0.01254576861184642, 0.002255729839328424, 0.00474935847545821,\n",
       "        -0.017481248319634712, 0.038889251001440694, 0.006947990005232274,\n",
       "        0.006182560885182764, -0.0002327039361906813, -0.05396020483225694,\n",
       "        -0.02492697285822132, -0.0077600783156815956, 0.039733021191980855,\n",
       "        -0.003952064546326461, 0.015097940857525582, 0.00512497559613756,\n",
       "        -0.00463111052684928, -0.0012612221506322907, 0.0315086163762357,\n",
       "        0.01915679608985177, 0.013676308519507185, 0.010566444301471134,\n",
       "        0.016711548641764273, -0.000249679088593302, -0.018919765458396687,\n",
       "        0.007565335883324531, 0.019390890899876778, 0.0047769005830647915,\n",
       "        0.005671682118331356, -0.0021943528008472324, 0.049201510333169884,\n",
       "        0.028138263402375796, 0.01245399869062902, -0.009245631056006731,\n",
       "        -0.0008616517535882107, 0.004661359746263916, 0.019996330996851053,\n",
       "        0.020525622532014287, 0.0012942540199094577,\n",
       "        -0.0024830685543559827, 0.025257405709654845, 0.020891074335251503,\n",
       "        0.0234323766027148, 0.01133622565090342, 0.0050093548180646374,\n",
       "        0.004710796000739537, 0.006465654357515227, 0.01638091687515819,\n",
       "        0.01960874393971712, 0.021413579011162254, 0.07041480656357924,\n",
       "        0.008817612879565617, 0.008384318003906599, -0.00808650242941078,\n",
       "        0.004911484077542716, 0.01623265150824149, 0.007765991655441784,\n",
       "        0.01959501612038428, -0.015288224008128237, 0.022147447321707925,\n",
       "        0.02568565855379401, 0.007461515401204877, 0.004592036623599638,\n",
       "        -0.006904779300774155, -0.0016256973770992778,\n",
       "        0.045193590832462216, -0.0031404249812354568,\n",
       "        -0.012885885008349862, 0.006818032592281087, 0.002387061397445933,\n",
       "        -0.016500817809131596, -0.005362438074289155,\n",
       "        -0.002026376137178265, 0.006759849782540295,\n",
       "        -0.0022044098066521522, -0.027893969986490186,\n",
       "        -0.003988669009527435, 0.010908478472553274, 0.012919180305406397,\n",
       "        0.014016059376637746, 0.03258279804586417, 0.036437683192300896,\n",
       "        0.0016331781783236465], dtype=object),\n",
       " 'mask_detect_class28': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class39': array([ 0.0028114 , -0.03197966, -0.02038264,  0.0028114 , -0.02038264,\n",
       "        -0.0551737 , -0.00878562, -0.00878562,  0.09558755,  0.0028114 ,\n",
       "         0.15357265,  0.0028114 ,  0.26954283,  0.0028114 , -0.04357668,\n",
       "        -0.00878562, -0.00878562, -0.02038264,  0.03760246,  0.01440842,\n",
       "         0.02600544,  0.0028114 ,  0.01440842,  0.02600544,  0.0028114 ,\n",
       "         0.04919947, -0.02038264, -0.02038264,  0.01440842,  0.02600544,\n",
       "         0.0028114 , -0.02038264,  0.0028114 ,  0.0028114 , -0.02038264,\n",
       "        -0.03197966,  0.0028114 , -0.02038264, -0.02038264, -0.00878562,\n",
       "        -0.00878562, -0.03197966, -0.00878562, -0.00878562, -0.00878562,\n",
       "         0.01440842,  0.0028114 ,  0.01440842,  0.0028114 ,  0.0028114 ,\n",
       "        -0.00878562,  0.01440842, -0.02038264, -0.03197966,  0.0028114 ,\n",
       "         0.0028114 , -0.00878562, -0.00878562, -0.02038264, -0.00878562,\n",
       "        -0.02038264, -0.00878562, -0.02038264, -0.03197966, -0.02038264,\n",
       "        -0.00878562,  0.0028114 ,  0.02600544, -0.02038264,  0.0028114 ,\n",
       "        -0.02038264, -0.02038264,  0.0028114 ,  0.01440842, -0.00878562,\n",
       "         0.01440842,  0.0028114 , -0.00878562, -0.04357668,  0.01440842,\n",
       "        -0.00878562,  0.0028114 , -0.00878562,  0.0028114 ,  0.0028114 ,\n",
       "         0.0028114 ,  0.0028114 ,  0.0028114 ,  0.0028114 ,  1.04654311,\n",
       "        -0.00878562,  0.0028114 ,  0.0028114 ,  0.0028114 , -0.02038264,\n",
       "        -0.03197966, -0.03197966, -0.03197966,  0.0028114 , -0.00878562]),\n",
       " 'shap_detect_class39': array([-0.01712624626434489, 0.05683761736626447, 0.00010602108521706732,\n",
       "        -0.007814271122947525, 0.00024134448739165926,\n",
       "        0.009383321246404619, -0.0002915530100439101, -0.00235117875309665,\n",
       "        0.11075721861303622, 0.002169713042578958, -0.014017993601766254,\n",
       "        0.0005752076475115109, 0.05355718188464298, -0.009163316323631765,\n",
       "        0.004498192299754011, -0.005490266145589229,\n",
       "        -0.0017289051355446894, -0.012932798068829299,\n",
       "        -0.015235700138751196, -0.0017376217892991486,\n",
       "        -0.006835838983323628, -0.011065834737245095,\n",
       "        -0.011470025476706502, 0.00026206795193983723,\n",
       "        -0.0004315189907800887, -0.0011349341922639589,\n",
       "        0.014487117683587014, 0.0018490862322477764,\n",
       "        -0.0027572144012834032, 0.012732840768482134, -0.02329983431492455,\n",
       "        0.0015807448458327045, -0.009708371336214827,\n",
       "        -0.005996344565615375, 0.005546136827800252,\n",
       "        -4.820051767728817e-05, -0.003764786760008354,\n",
       "        -0.00022321763733335054, -0.006171910567568051,\n",
       "        -0.00764935830688751, 0.02086777648389604, 0.0006177830691136421,\n",
       "        0.004047899482943373, 0.004438088789253669, -0.0021973532047534494,\n",
       "        0.00013438948965560638, -0.02211014473475481, -0.01033981582828003,\n",
       "        -0.013214179291394235, 0.009364227793084323,\n",
       "        -0.0015327734189350961, 0.009181667376840785,\n",
       "        -0.0044810865177996595, -0.00788058975173811,\n",
       "        -0.006722292381052597, -0.005083268098107108, 0.000996006554472073,\n",
       "        -0.006383852681363766, -0.0006268168888853287, 0.00823466211375734,\n",
       "        0.005351430002421109, 0.0023162213519163366, 0.0017614673078496512,\n",
       "        0.0025710104144566204, -0.002481666402620375, 0.00553841660707155,\n",
       "        -0.007247907168399514, -0.010225884056608514, 0.012130592746032787,\n",
       "        -0.004117510018764592, 0.0017301964232140365, 0.019395171538711287,\n",
       "        -0.0158282744372501, -0.013940540655381417, 0.010340192706707163,\n",
       "        0.004297618317242069, -0.020420582784619112,\n",
       "        -0.0011610209009463857, 0.0010677452065398496,\n",
       "        -0.028245342672797324, -0.01560798723041279, -0.012935519900348136,\n",
       "        0.005994943978449463, 7.326573454591312e-06, -0.005685608565637046,\n",
       "        -0.006673953082333539, -0.0013595678149028734,\n",
       "        0.0020636228684498548, -0.0022038528288070847, 0.995248950472987,\n",
       "        -0.0003226313020845417, 0.00048739535005537515,\n",
       "        0.004337419763762562, 0.003300556093428386, -0.003189716222555705,\n",
       "        0.003294363687700752, 0.0071932699549198675, 0.006827647437018358,\n",
       "        -0.016018367190288263, -0.005787574291019837], dtype=object),\n",
       " 'mask_detect_class39': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class22': array([-0.00846969, -0.02252669, -0.00846969, -0.0014412 , -0.00846969,\n",
       "         0.01964429, -0.02955518,  0.01964429, -0.02252669, -0.00846969,\n",
       "        -0.0014412 ,  0.35701212, -0.01549819, -0.00846969, -0.0014412 ,\n",
       "         0.0126158 , -0.04361217, -0.00846969, -0.00846969,  0.0126158 ,\n",
       "         0.03370128, -0.00846969, -0.00846969, -0.01549819, -0.0014412 ,\n",
       "         0.0055873 , -0.00846969, -0.0014412 ,  0.0055873 , -0.00846969,\n",
       "        -0.00846969, -0.01549819, -0.00846969, -0.0014412 , -0.0014412 ,\n",
       "        -0.02252669, -0.00846969, -0.00846969, -0.00846969, -0.01549819,\n",
       "        -0.00846969, -0.03658368, -0.02955518, -0.0014412 ,  0.0055873 ,\n",
       "        -0.04361217,  0.0055873 , -0.01549819, -0.01549819,  0.0126158 ,\n",
       "        -0.01549819,  0.07587226, -0.01549819, -0.01549819,  0.03370128,\n",
       "         0.0055873 , -0.0014412 ,  0.98254829, -0.01549819, -0.0014412 ,\n",
       "        -0.00846969,  0.0126158 , -0.0014412 , -0.00846969, -0.0014412 ,\n",
       "        -0.00846969, -0.0014412 ,  0.0055873 , -0.01549819,  0.0126158 ,\n",
       "        -0.0014412 , -0.0014412 , -0.00846969,  0.0055873 , -0.0014412 ,\n",
       "        -0.00846969, -0.05064067, -0.05064067,  0.03370128,  0.0055873 ,\n",
       "        -0.01549819, -0.0014412 , -0.0014412 , -0.0014412 ,  0.01964429,\n",
       "        -0.01549819, -0.0014412 , -0.00846969,  0.0055873 ,  0.0055873 ,\n",
       "        -0.00846969, -0.00846969,  0.0055873 ,  0.0126158 , -0.00846969,\n",
       "         0.04775828, -0.00846969,  0.06884377,  0.0126158 , -0.00846969]),\n",
       " 'shap_detect_class22': array([-0.005744579206820477, 0.0024795493115072897,\n",
       "        -0.00013752365559849267, -0.007685822016225474,\n",
       "        -0.006697827363209119, 0.022412249542209772, -0.011927365350104635,\n",
       "        0.014795264990389079, -0.0119968561034558, 0.0021207666136525694,\n",
       "        -0.004371823079724835, 0.3183863433481109, 0.03486895173861504,\n",
       "        -0.01152976091202218, 0.0018184334287449921, 0.009786566610760161,\n",
       "        -0.002720329951546474, 0.0009274417045036509,\n",
       "        0.0023326825150031816, 0.015847551429734374, 0.033718973270088215,\n",
       "        0.01015252676690026, 0.005404351821099218, 0.006693458264824592,\n",
       "        0.005953902169852032, 0.0022004197905876044,\n",
       "        -0.0038446984623569103, 0.007462834972514543, 0.007996713395139299,\n",
       "        0.22832120280919133, -0.005656237437236866, -0.015187362332376164,\n",
       "        -0.0025486165112372783, 0.022235402097267376,\n",
       "        -0.007212618038494822, -0.017423962182110064, 0.035537069060315285,\n",
       "        -0.005464592763855358, -0.006969724016726131,\n",
       "        0.0005825011337448061, 0.015923911561035786, -0.015418213972645534,\n",
       "        -0.012782447765380622, -0.0023957493238678795, 0.00546423454344791,\n",
       "        -0.013825793422199029, -0.008854671677987591, 0.003951148384473524,\n",
       "        -0.010777308381346384, 0.005957965462367598, 0.0044225922659909545,\n",
       "        -0.007209468166312627, -0.0178650113519796, -0.005817766870330088,\n",
       "        0.025571477319534575, 0.00038503302329395694,\n",
       "        -0.004128405953659375, 0.18527245739974074, -0.005088479166307391,\n",
       "        -0.008169732562186338, 0.02213724699130548, -0.0037173183821028744,\n",
       "        0.00222889677007021, -0.015318503306723463, -0.0017296860573458028,\n",
       "        -0.022550809456537757, 0.011621751526093349,\n",
       "        -0.0016480570098740266, -0.008462740871990504,\n",
       "        -0.002831322849281781, 0.0010525608057957436, 0.014516453023565967,\n",
       "        -0.0046313281364793735, 0.004741753896704726, 0.002026954874993603,\n",
       "        0.02680329378805646, -0.00918571136080204, -0.001990629415808076,\n",
       "        0.00488895892733443, 0.06285243661013118, 0.003631635305538339,\n",
       "        0.0015469167560978603, 0.028062681352409746, -0.012343561813918491,\n",
       "        0.02065545630292609, -0.012462452778015387, -0.00871824216535566,\n",
       "        0.011145081668060941, -0.008245626032492459, 0.0331280670670695,\n",
       "        -0.001770343136404784, -0.0038205079935885733,\n",
       "        0.003741862003737273, 0.011533078927148388, -0.0057887639377902644,\n",
       "        0.03414316980768539, -0.009110189437669391, 0.018448795056449696,\n",
       "        0.012098408202497302, -0.014240699133921453], dtype=object),\n",
       " 'mask_detect_class22': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class9': array([ 0.05946455, -0.06080083, -0.00925853, -0.00066814, -0.00925853,\n",
       "        -0.00925853,  0.00792224, -0.00925853,  0.02510301, -0.00925853,\n",
       "        -0.05221045,  0.15395878, -0.02643929, -0.00925853,  0.01651263,\n",
       "        -0.00066814, -0.02643929, -0.03502968, -0.00925853, -0.00925853,\n",
       "         0.05946455,  0.05946455, -0.00925853, -0.00925853,  0.01651263,\n",
       "         0.01651263,  0.01651263,  0.0336934 ,  0.05087417, -0.04362006,\n",
       "         0.0336934 , -0.03502968,  0.05087417,  0.00792224, -0.00066814,\n",
       "        -0.00925853, -0.01784891, -0.02643929,  0.00792224, -0.01784891,\n",
       "        -0.00925853,  0.00792224,  0.02510301, -0.04362006,  0.02510301,\n",
       "         0.06805493, -0.00066814, -0.06080083,  0.05946455, -0.00925853,\n",
       "         0.11100686, -0.06080083, -0.00066814, -0.00925853,  0.06805493,\n",
       "        -0.00066814, -0.03502968,  0.0336934 , -0.00066814,  0.01651263,\n",
       "        -0.01784891, -0.02643929, -0.00925853, -0.01784891, -0.03502968,\n",
       "        -0.03502968, -0.01784891,  0.04228378,  0.0852357 , -0.02643929,\n",
       "        -0.01784891, -0.02643929, -0.00925853, -0.00925853, -0.00925853,\n",
       "        -0.03502968,  0.23986262,  0.0852357 , -0.00925853,  0.31717608,\n",
       "         0.05087417, -0.00925853, -0.03502968, -0.00066814,  0.07664532,\n",
       "         0.00792224, -0.01784891, -0.01784891, -0.05221045, -0.00925853,\n",
       "         0.00792224, -0.00925853,  0.18832032,  0.01651263, -0.05221045,\n",
       "        -0.03502968, -0.00066814, -0.10375275, -0.02643929, -0.01784891]),\n",
       " 'shap_detect_class9': array([-0.012146647166674795, 0.018581634584192708, 0.016610638997732297,\n",
       "        0.0045731463624778534, 0.005386344241592345, 0.013057403860677441,\n",
       "        0.006761663070647406, 0.004433772604807817, 0.00403978920600867,\n",
       "        0.002922385280810791, 0.0071102892105392446, 0.03570181960140517,\n",
       "        0.015845324261409832, 0.004734763055285307, -0.0022908760123923066,\n",
       "        0.01056979437157779, 0.007435343013644347, 0.008685280258672434,\n",
       "        0.017910449771733505, 0.002848334161329902, 0.012511150118226011,\n",
       "        -0.004059842436230698, 0.008549013967567243, 0.1368825899860393,\n",
       "        0.005711313046116828, 0.011222228819653401, -5.25389511097929e-05,\n",
       "        0.0040338666869006445, 0.0075877138141069445, 0.024285636000847877,\n",
       "        0.005786232784723455, 0.0011048054161595378, 0.005703150874221019,\n",
       "        0.013547270507917153, 0.001229589448261903, 0.009133402100503396,\n",
       "        0.02206984172894655, -0.0012370957111030867, 0.007106829082164423,\n",
       "        0.0020927453211500024, 0.01119494704874413, -0.0055406390909716885,\n",
       "        -0.009484298991351503, 0.016377575874017003, 0.006672990166041282,\n",
       "        0.006716702196134627, 0.005953985949744944, 0.010270946091570643,\n",
       "        -0.012941062084325439, 0.0071643414837224695,\n",
       "        -0.012644291008729325, 0.009888939997240387, 0.002549741584978449,\n",
       "        0.011007954794914121, -0.015373849138897389, -0.003565181807841822,\n",
       "        0.004640373919720497, 0.021398417199991027, 0.0011815578764917678,\n",
       "        0.008485444973409528, 0.004041313480036446, 0.010774876974485426,\n",
       "        0.025852055919875383, 0.015003149355527823, 0.00916384170963136,\n",
       "        0.00871409834197956, 0.019872748774413806, 0.05418202622273627,\n",
       "        -0.003937478346474954, 0.06358150321939582, 0.0021329295166906403,\n",
       "        0.023465427350890744, 0.002397843558856083, 0.00208097079517644,\n",
       "        0.007147890453761407, 0.0035772404329177387, 0.025230623323700074,\n",
       "        0.006164049309927533, 0.010139220500176904, -0.0013442026911477667,\n",
       "        -0.006048078813141844, 0.007175975524384537, 0.05782532276298458,\n",
       "        0.0003557077037986689, 0.026379521048706, 0.0025850314593208745,\n",
       "        0.006167682183468526, 0.00602278716020388, 0.0006306203378614317,\n",
       "        0.0018547340701089432, 0.007311332023376971, 0.0004259052661289564,\n",
       "        0.0005406970678908385, 0.005290670703770206, 0.009330546167834797,\n",
       "        0.018673604257643195, 0.004708642390786166, 0.03782912946920447,\n",
       "        0.012041342476944439, 0.00026733931764511], dtype=object),\n",
       " 'mask_detect_class9': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class38': array([-0.03471681, -0.06738447, -0.03471681, -0.03471681, -0.03471681,\n",
       "        -0.11638596, -0.05105064, -0.01838298, -0.00204915, -0.03471681,\n",
       "         0.03061851,  0.01428468, -0.01838298,  0.01428468, -0.03471681,\n",
       "         0.03061851,  0.17762297,  0.12862148, -0.00204915, -0.01838298,\n",
       "        -0.00204915,  0.07961999,  0.11228765,  0.11228765,  0.01428468,\n",
       "         0.04695234, -0.00204915, -0.01838298, -0.05105064, -0.01838298,\n",
       "         0.04695234, -0.00204915, -0.03471681, -0.03471681, -0.05105064,\n",
       "         0.07961999, -0.05105064, -0.03471681,  0.03061851,  0.06328616,\n",
       "        -0.01838298, -0.0837183 , -0.01838298, -0.05105064,  0.07961999,\n",
       "        -0.03471681,  0.12862148,  0.21029063, -0.01838298, -0.05105064,\n",
       "        -0.11638596,  0.42263041, -0.01838298, -0.0837183 , -0.03471681,\n",
       "        -0.10005213, -0.00204915, -0.03471681,  0.11228765, -0.06738447,\n",
       "        -0.05105064, -0.03471681, -0.00204915, -0.01838298, -0.01838298,\n",
       "        -0.01838298, -0.01838298, -0.01838298, -0.03471681,  0.52063339,\n",
       "        -0.03471681,  0.07961999, -0.01838298, -0.00204915, -0.00204915,\n",
       "         0.03061851, -0.01838298,  0.03061851, -0.06738447, -0.03471681,\n",
       "        -0.03471681,  0.14495531,  0.03061851, -0.03471681, -0.01838298,\n",
       "        -0.03471681,  0.07961999,  0.01428468,  0.04695234,  0.16128914,\n",
       "        -0.03471681, -0.00204915, -0.06738447, -0.03471681, -0.01838298,\n",
       "        -0.05105064, -0.01838298,  0.12862148, -0.01838298,  0.04695234]),\n",
       " 'shap_detect_class38': array([-0.014292717655273735, 0.041724938869016515, 0.03554263139285585,\n",
       "        0.004683570582254659, 0.0036320386154717887, -0.02463254075048904,\n",
       "        0.008561710563838143, 0.015633081369836765, -0.026483457961256507,\n",
       "        -0.01175493546956441, -0.04359927219255044, -0.008375964979878914,\n",
       "        0.03172296399491781, 0.025322213687416162, -0.011178400774708774,\n",
       "        -0.0008661814608834639, 0.06747505084017458, -0.04830291449777868,\n",
       "        -0.047296501370592825, 0.026228772349020324, -0.004339710478090342,\n",
       "        -0.040292544933590024, 0.09318686909694796, -0.004257696598494731,\n",
       "        0.032863133467155525, -0.026372233658981337, -0.03912247221122178,\n",
       "        0.011885915455567497, -0.01249423336087252, 0.021861056122362332,\n",
       "        -0.03183218923746245, 0.022232786501916735, -0.006447155737799193,\n",
       "        0.01736871810885754, 0.009469864671931005, 0.06819924023274648,\n",
       "        0.027019609668762157, 0.01791759468465204, 0.029736736947659437,\n",
       "        0.05167699335439502, 0.035949607859575794, 0.013537290233688992,\n",
       "        0.01398315508650283, 0.015285801872964688, 0.062003397653395464,\n",
       "        0.03367372270147195, 0.06575286588102769, -0.03675457800602988,\n",
       "        0.04878560015071398, 0.004118590522483201, 0.0386589949523618,\n",
       "        -0.061913453934509755, 0.006158821124992664, 0.00884588461417024,\n",
       "        0.030522497098157797, 0.07113829376405467, -0.021633404288832647,\n",
       "        0.012757783005574952, -0.06191345393454284, 0.03351676510445767,\n",
       "        0.016181116848632437, 0.02634968075277777, -0.03308557526656275,\n",
       "        0.03172296399464347, 0.03372473880719962, 0.04770736261088637,\n",
       "        -0.010933626395325469, 0.022232786501919066, -0.024748864408516646,\n",
       "        -0.061913453934520746, 0.0021932972292871833, -0.03636751837637664,\n",
       "        -0.0014933794660115796, 0.038794464307040366,\n",
       "        -0.019981994053778096, -0.038851151000141915, 0.19259553202037072,\n",
       "        0.010281581338396295, -0.01105811925863509, 0.004430157246637645,\n",
       "        -0.017208066707849357, -0.06191345393451575, 0.062046424337979134,\n",
       "        -0.012673678606200722, 0.024570182069537427, 0.009137075307808051,\n",
       "        -0.04126064533660556, 0.006118200361809767, 0.06969207911512343,\n",
       "        -0.06191345393453118, 0.03200542679386709, 0.020040418701075202,\n",
       "        0.063011743436308, 0.020351468118179894, 0.015921818469080362,\n",
       "        0.015361574512856802, 0.033883804408399, 0.088735460395157,\n",
       "        -0.0012625923215481283, -0.051012155278755245], dtype=object),\n",
       " 'mask_detect_class38': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class14': array([-7.58797865e-04, -7.58797864e-04, -7.58797864e-04, -7.58797863e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797863e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797863e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04,  1.65501857e-02, -7.58797864e-04,  1.12432513e+00,\n",
       "        -7.58797864e-04,  1.65501857e-02, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,  3.38591692e-02,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04,  1.65501857e-02, -7.58797864e-04, -7.58797864e-04,\n",
       "        -7.58797864e-04, -7.58797864e-04, -7.58797864e-04, -7.58797864e-04]),\n",
       " 'shap_detect_class14': array([0.307316353607724, -0.7304872784424625, 0.30731635360168524,\n",
       "        0.30731635360099163, 0.30731635360063636, 0.30731635360068743,\n",
       "        0.3073163536000763, 0.3073163535997158, 0.3073163535994103,\n",
       "        0.30731635359863674, 0.30731635360128784, 0.30731635360008397,\n",
       "        -0.7304872784465193, 0.3073163536038745, 0.3073163535999419,\n",
       "        -0.7304872784476955, -0.7304872784484131, 0.3073163536003659,\n",
       "        0.3073163536002119, 0.3073163536000367, 0.3073163536005964,\n",
       "        0.30731635360017895, -0.6427855630643834, 0.30731635360030807,\n",
       "        0.307316353600461, 0.3073163536001727, 0.30731635360022574,\n",
       "        0.307316353600333, 0.30731635360029896, 0.3073163536003041,\n",
       "        -0.6402434843575804, 0.30731635360035353, 0.3073163536004885,\n",
       "        0.3073163536003561, 0.30731635360006027, -0.730487278448742,\n",
       "        -0.6720194681922884, 0.3073163536002126, 0.30731635360005044,\n",
       "        -0.7304872784487269, 0.3073163536001461, 0.30731635360024906,\n",
       "        0.30731635360027904, 0.30731635360030723, -0.7304872784489145,\n",
       "        0.3073163536001814, 0.3073163536005519, 0.3073163536001586,\n",
       "        -0.6101622196602525, 0.3073163536003514, -0.7304872784490113,\n",
       "        0.30731635360037884, -0.7304872784489104, -0.7004060137515855,\n",
       "        -0.6952532045212207, 0.3073163536002231, 0.30731635360016785,\n",
       "        -0.6694400059752645, -0.7048624974107267, 0.3073163536002118,\n",
       "        -0.7304872784488974, 0.30731635360020193, 0.30731635360021675,\n",
       "        0.3073163536003566, 0.30731635360013104, 0.3073163536003014,\n",
       "        -0.7304872784489717, 0.30731635360038106, -0.7304872784489416,\n",
       "        0.3073163536003096, 0.30731635360022613, -0.7304872784486574,\n",
       "        0.3073163536001079, 0.3073163536003116, 0.3073163536000841,\n",
       "        0.3073163536003552, 0.3073163536001351, 0.3073163536002927,\n",
       "        0.3073163536000948, -0.7269483061313655, 0.30731635360036225,\n",
       "        0.30731635360031573, -0.6694400059754853, 0.30731635360014725,\n",
       "        -0.7156615122770306, 0.30731635359994514, -0.7304872784491863,\n",
       "        0.30731635360015847, -0.730487278448892, -0.700406013751925,\n",
       "        0.3073163536000924, 0.3073163536001624, -0.7304872784489123,\n",
       "        0.30731635360006393, 0.3073163536002242, 0.30731635360015036,\n",
       "        0.3073163536002308, 0.30731635360049353, -0.6389163697389493,\n",
       "        -0.7304872784482725], dtype=object),\n",
       " 'mask_detect_class14': array([[1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class32': array([-0.00794097,  0.09887368,  0.00731827, -0.00794097, -0.00794097,\n",
       "        -0.00794097,  0.0225775 ,  0.03783674, -0.00794097,  0.00731827,\n",
       "        -0.0232002 , -0.00794097, -0.00794097, -0.00794097,  0.00731827,\n",
       "         0.05309597,  0.00731827, -0.00794097,  0.0225775 ,  0.00731827,\n",
       "         0.06835521, -0.00794097,  0.0225775 ,  0.00731827,  0.00731827,\n",
       "         0.00731827,  0.00731827,  0.0225775 , -0.03845944,  0.14465139,\n",
       "        -0.00794097,  0.12939215, -0.00794097, -0.03845944,  0.06835521,\n",
       "         0.00731827,  0.09887368,  0.0225775 , -0.0232002 ,  0.00731827,\n",
       "         0.0225775 , -0.00794097,  0.0225775 ,  0.00731827,  0.0225775 ,\n",
       "         0.03783674, -0.00794097,  0.09887368, -0.0232002 ,  0.00731827,\n",
       "        -0.00794097,  0.05309597,  0.0225775 , -0.03845944,  0.03783674,\n",
       "         0.00731827,  0.0225775 ,  0.03783674,  0.00731827,  0.00731827,\n",
       "         0.0225775 ,  0.00731827,  0.06835521,  0.00731827, -0.00794097,\n",
       "         0.00731827,  0.0225775 , -0.03845944, -0.03845944, -0.0232002 ,\n",
       "         0.03783674,  0.00731827, -0.00794097, -0.0232002 ,  0.03783674,\n",
       "         0.0225775 , -0.00794097,  0.00731827,  0.05309597, -0.0232002 ,\n",
       "        -0.0232002 ,  0.00731827,  0.00731827, -0.00794097, -0.0232002 ,\n",
       "        -0.00794097,  0.00731827,  0.06835521, -0.0232002 , -0.00794097,\n",
       "        -0.03845944, -0.00794097, -0.03845944, -0.00794097,  0.00731827,\n",
       "         0.00731827, -0.0232002 ,  0.0225775 , -0.0232002 ,  0.00731827]),\n",
       " 'shap_detect_class32': array([0.005471274559879946, 0.043511223068699145, 0.0033161654146336428,\n",
       "        0.004905096911822726, 0.009098851753744253, -0.007034005061817616,\n",
       "        -0.0065669204456824115, 0.001999077787247394, 0.04629897397346516,\n",
       "        -0.004087289378305048, 0.07069179438486062, 0.0018804211653660197,\n",
       "        0.0296120672828748, -0.0019081809896150936, -0.0031066940925015274,\n",
       "        -0.008683597564332901, 0.0016502362299386508, 0.008917768667645376,\n",
       "        0.09730214392435022, 0.010818507920297815, 0.0006812319052318383,\n",
       "        0.009832939418777942, 0.0015876450417182664,\n",
       "        -0.0023138723719773324, 0.011968337838684118, 0.008484266732582846,\n",
       "        0.00701702941457083, -0.005728291247980577, -0.008220883585464245,\n",
       "        0.0009469266394517284, 0.007861802415925156, 0.016140577828387626,\n",
       "        0.009832939418949138, 0.0049368534997131786, 0.027449976382616814,\n",
       "        0.005173888320989084, 0.01473179461735663, 0.004691124802674418,\n",
       "        0.009102998129896012, 0.009832939418880304, -0.0023138723719771104,\n",
       "        0.004048521934562954, 0.016980904655828022, 0.0012772970656518279,\n",
       "        -0.005413805298857266, -0.001954459858792168, 0.008460183291819412,\n",
       "        -0.01579184161931102, 0.00973701777867153, 0.012870168932082704,\n",
       "        0.0033849646250383447, 0.006553212659282437, 0.000813016493401042,\n",
       "        0.003951320942328973, 0.005732974452788753, 0.006826955489443343,\n",
       "        0.03812003537017605, -0.010692069471669452, 0.013410425083338229,\n",
       "        0.013036037048667293, 0.011518780276616791, 0.02613961826144373,\n",
       "        -0.015791841619401836, 0.024642066122782413, 0.0010146949320553045,\n",
       "        0.004425112251734475, 0.01048166805275419, 0.01676670369983979,\n",
       "        0.04939251874070427, 0.015812054994543523, 0.012256905192794099,\n",
       "        0.020035671569943014, 0.009134308582338102, 0.01200646995338217,\n",
       "        0.00792938425607792, 0.021272573810918738, 0.022797375711619106,\n",
       "        0.017050045470764053, 0.0005699273544683692, 0.001948391407119665,\n",
       "        0.003913290634687483, 0.02678471764424417, 0.007965108993823078,\n",
       "        0.008936167483784008, 0.023161531622119425, 0.002415239644645073,\n",
       "        0.0032155509090010526, 0.009481915021104736,\n",
       "        -0.0032377654251549703, 0.01953988772382309, 0.011117500611867337,\n",
       "        0.008771557955785436, 0.026326812278748335, -0.002593535723059315,\n",
       "        0.022645329938010272, -0.0031080783293433445, 0.007025827436331511,\n",
       "        0.01116409687535036, 0.00145508011415596, 0.02049499866187432],\n",
       "       dtype=object),\n",
       " 'mask_detect_class32': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class33': array([-0.02984508,  0.05068978,  0.00236886, -0.02984508,  0.01847583,\n",
       "         0.00236886,  0.00236886, -0.04595205,  0.01847583,  0.01847583,\n",
       "         0.09901069,  0.03458281,  0.01847583, -0.04595205,  0.01847583,\n",
       "        -0.06205902,  0.05068978, -0.06205902,  0.00236886, -0.01373811,\n",
       "        -0.06205902, -0.01373811,  0.01847583,  0.03458281, -0.02984508,\n",
       "         0.05068978, -0.01373811,  0.00236886,  0.05068978,  0.08290372,\n",
       "         0.01847583, -0.01373811, -0.01373811,  0.01847583,  0.03458281,\n",
       "        -0.02984508,  0.06679675,  0.00236886, -0.04595205, -0.06205902,\n",
       "        -0.01373811, -0.01373811, -0.01373811, -0.04595205, -0.02984508,\n",
       "         0.00236886, -0.02984508, -0.06205902,  0.00236886,  0.01847583,\n",
       "         0.09901069, -0.04595205,  0.00236886,  0.00236886, -0.06205902,\n",
       "         0.01847583,  0.00236886, -0.04595205, -0.07816599,  0.13122463,\n",
       "        -0.02984508,  0.03458281,  0.00236886,  0.00236886, -0.01373811,\n",
       "         0.01847583, -0.02984508,  0.03458281,  0.00236886,  0.87214529,\n",
       "        -0.01373811, -0.06205902, -0.04595205,  0.05068978,  0.00236886,\n",
       "         0.01847583,  0.05068978, -0.04595205, -0.01373811, -0.01373811,\n",
       "         0.01847583, -0.09427296, -0.14259387,  0.01847583,  0.06679675,\n",
       "         0.06679675, -0.01373811,  0.03458281,  0.00236886, -0.02984508,\n",
       "         0.03458281, -0.01373811,  0.1473316 ,  0.08290372,  0.03458281,\n",
       "         0.01847583,  0.05068978, -0.11037993, -0.02984508, -0.02984508]),\n",
       " 'shap_detect_class33': array([-0.016247951248494874, -0.027528425509461996,\n",
       "        -0.025072085552481194, 0.00805341330429743, -0.014755457730307842,\n",
       "        -0.022059104654733153, -0.01937600106246451, -0.023071941850006827,\n",
       "        -0.01156221578533756, -0.024907709266255185, -0.015173620365802276,\n",
       "        -0.01888006190912639, 0.033518846964242566, -0.00803915542358713,\n",
       "        -0.0046356983316743205, -0.0190317875868532, -0.02752842550934642,\n",
       "        -0.004967476986266095, 0.04660040535124266, -0.005400416297191235,\n",
       "        -0.014744730153545937, -0.02752842550918, 0.00490293799230801,\n",
       "        -0.008702055766894978, -0.01621207513707912, -0.012885693487417749,\n",
       "        -0.022966651302559593, -0.018093847036062316,\n",
       "        -0.015173620365872775, -0.021948836089586976, -0.01180412805397868,\n",
       "        -0.016755377425619833, -0.025493516426735807, -0.02203740100100826,\n",
       "        -0.021893292665620012, -0.0031573030345053432,\n",
       "        -0.027528425509281695, -0.023035769093283975,\n",
       "        0.00014633801196450857, 0.010689105067793747,\n",
       "        -0.008659268562758338, -0.02089002274545726, -0.02133258292986706,\n",
       "        -0.009145430416628075, -0.0021128263568986894,\n",
       "        -0.019545320647289866, 0.01613650225793095, -0.015062315814902139,\n",
       "        -0.02072315579084183, -0.01524672572156005, -0.021762849775614712,\n",
       "        0.013047355593504228, -0.014620420135449508, -0.010056983892224203,\n",
       "        0.009535989921078736, -0.016050412988871332, -0.008659268562812295,\n",
       "        0.002580692210815805, 0.031284531206724475, -0.002818815222352833,\n",
       "        0.016168569524458443, -0.00951100134158267, -0.019049637665722652,\n",
       "        -0.01823466164021248, -0.022365223359606112, 0.01894039383632473,\n",
       "        -0.006396677345293256, -0.016546376492809656,\n",
       "        -0.013233609640734167, 1.0102752065399552, -0.02064415597654501,\n",
       "        0.006540885643926964, -0.002755619288069555, -0.020609734628791898,\n",
       "        -0.0030684072453889266, -0.019420584633869864, 1.010275206539879,\n",
       "        -0.009250083653109198, -0.011804128053818586,\n",
       "        -0.017045560539050597, -0.019545320647252118,\n",
       "        -0.008309839730420654, -0.0033934573219963626, -0.0229666513024519,\n",
       "        -0.023204243709003314, -0.02752842550918788, -0.008451152861291167,\n",
       "        -0.022538984970598253, -0.005065143430241226, 0.008569092127251876,\n",
       "        -0.014349966689599536, -0.01704556053910511, -0.014948987545100767,\n",
       "        -0.015801830796732363, -0.011055351984794348,\n",
       "        -0.013071459490723636, -0.016186309311978397, 0.002596018036803205,\n",
       "        0.018940393836202607, -0.00024344738973525182], dtype=object),\n",
       " 'mask_detect_class33': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class7': array([-0.02049662,  0.05786162, -0.00482497, -0.00482497,  0.01084668,\n",
       "         0.10487656, -0.00482497,  0.02651833, -0.00482497, -0.00482497,\n",
       "        -0.03616826, -0.02049662, -0.06751156, -0.00482497,  0.19890645,\n",
       "        -0.00482497, -0.00482497, -0.06751156, -0.00482497, -0.02049662,\n",
       "         0.01084668, -0.02049662,  0.01084668, -0.02049662, -0.00482497,\n",
       "        -0.00482497,  0.01084668, -0.00482497,  0.02651833, -0.00482497,\n",
       "        -0.00482497, -0.00482497,  0.02651833, -0.00482497,  0.02651833,\n",
       "        -0.00482497, -0.00482497,  0.08920492,  0.01084668,  0.07353327,\n",
       "        -0.00482497, -0.00482497, -0.00482497, -0.02049662,  0.1518915 ,\n",
       "        -0.00482497, -0.03616826, -0.03616826, -0.00482497, -0.00482497,\n",
       "         0.04218997, -0.05183991,  0.05786162,  0.04218997,  0.02651833,\n",
       "        -0.00482497, -0.02049662, -0.02049662, -0.02049662,  0.01084668,\n",
       "         0.10487656, -0.00482497, -0.02049662, -0.00482497, -0.02049662,\n",
       "        -0.00482497,  0.01084668, -0.00482497, -0.00482497, -0.00482497,\n",
       "        -0.00482497, -0.00482497,  0.02651833, -0.00482497, -0.00482497,\n",
       "         0.01084668,  0.19890645,  0.01084668,  0.04218997, -0.00482497,\n",
       "        -0.00482497,  0.07353327, -0.06751156,  0.01084668,  0.02651833,\n",
       "        -0.02049662, -0.00482497, -0.02049662, -0.00482497, -0.00482497,\n",
       "        -0.00482497, -0.00482497,  0.07353327,  0.12054821,  0.05786162,\n",
       "         0.04218997, -0.02049662, -0.02049662, -0.00482497, -0.00482497]),\n",
       " 'shap_detect_class7': array([-0.01384319356067687, -0.01669560849015972, -0.014746681481716317,\n",
       "        -0.012728216458786079, -0.011304420791040881,\n",
       "        -0.016695608489427638, -0.01435689607950108, -0.011387150013630665,\n",
       "        -0.013730455255498208, -0.01669560848960172, -0.013459214626966753,\n",
       "        -0.016695608490205016, 0.01789784591175958, -0.01438937819606978,\n",
       "        -0.016695608489900815, -0.012742070844911524,\n",
       "        -0.011682064373877754, 0.004869142306067387, -0.0125773401089051,\n",
       "        -0.01669560848998386, -0.01669560848976981, -0.014560210069993085,\n",
       "        -0.00917529231563119, -0.008797559539754696, -0.016695608489849967,\n",
       "        -0.010453180627991498, -0.011753686432635524,\n",
       "        -0.009718777350109953, -0.0096516924353367, -0.008100961433539,\n",
       "        -0.012935450402710158, -0.005525510688872304, -0.01357439455886178,\n",
       "        -0.004510047252475058, -0.0071635429832290765,\n",
       "        -0.005164457022694302, -0.009387132207856252,\n",
       "        -0.016695608489711633, -0.016695608489970315,\n",
       "        -0.016695608489883274, -0.01293545040264421, -0.01189096204510709,\n",
       "        -0.016695608489907476, -0.00631757216941109, -0.01669560848976981,\n",
       "        -0.013447396808949685, -0.014223175775135433,\n",
       "        -0.015048301137354558, -0.011823290968456135,\n",
       "        -0.009488638822785056, -0.013041370348884973,\n",
       "        -0.0053946614983915175, -0.0007293987659864332,\n",
       "        -0.004116170525645391, -0.01669560848989282, -0.011241685498592169,\n",
       "        -0.01293545040268751, -0.0036638277220728543,\n",
       "        -0.005759848405022305, -0.013960948062836875, 1.0211080235592096,\n",
       "        -0.009776917609432445, -0.005322418001712403,\n",
       "        -0.008370980425356445, -0.009215942673188149,\n",
       "        -0.013187539874420118, -0.016695608489865066, 0.10539893645704135,\n",
       "        -0.008343064167532388, -0.013871653028395547,\n",
       "        -0.013156636172605651, -0.012935450402727255,\n",
       "        -0.016695608489827096, -0.016695608489767144,\n",
       "        -0.011608335783692025, -0.003614050102755284, 1.0211080235592438,\n",
       "        -0.01669560848981244, -0.01669560848976448, -0.0036638277221472393,\n",
       "        -0.015303517769415631, -0.016695608489734504,\n",
       "        -0.007592067857814522, -0.01669560848993057, -0.00860882694145082,\n",
       "        -0.012534685140573654, -0.012593617849400163,\n",
       "        -0.007086315600595361, -0.016695608489899927, -0.01105537135918988,\n",
       "        -0.0116182913076881, -0.014660699407431865, -0.016695608489926572,\n",
       "        -0.016695608489788905, -0.01669560849006224, -0.016695608489925684,\n",
       "        -0.004628124396279576, -0.014481233741427513,\n",
       "        -0.004790978432705817, -0.013730455255597462], dtype=object),\n",
       " 'mask_detect_class7': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class24': array([ 0.00367044,  0.00367044,  0.00367044,  0.00367044,  0.00367044,\n",
       "        -0.07364302,  0.00367044,  0.00367044,  0.04232717,  0.00367044,\n",
       "         0.00367044,  0.00367044, -0.03498629,  0.00367044,  0.00367044,\n",
       "         0.00367044,  0.00367044,  0.04232717,  0.00367044,  0.00367044,\n",
       "         0.00367044,  0.00367044, -0.03498629,  0.00367044,  0.66083484,\n",
       "         0.00367044,  0.00367044,  0.00367044,  0.00367044,  0.00367044,\n",
       "        -0.03498629, -0.07364302,  0.00367044,  0.00367044, -0.03498629,\n",
       "         0.00367044,  0.00367044,  0.00367044,  0.00367044,  0.00367044,\n",
       "         0.0809839 ,  0.00367044,  0.00367044,  0.00367044, -0.07364302,\n",
       "         0.11964063,  0.00367044,  0.00367044,  0.00367044, -0.03498629,\n",
       "         0.00367044,  0.00367044, -0.03498629,  0.00367044,  0.00367044,\n",
       "         0.00367044,  0.00367044,  0.00367044,  0.00367044,  0.00367044,\n",
       "         0.00367044,  0.00367044,  0.04232717,  0.00367044,  0.00367044,\n",
       "         0.00367044,  0.00367044,  0.00367044,  0.00367044,  0.00367044,\n",
       "         0.00367044, -0.03498629,  0.00367044, -0.03498629,  0.00367044,\n",
       "         0.00367044,  0.00367044,  0.00367044,  0.00367044,  0.00367044,\n",
       "         0.00367044,  0.00367044,  0.00367044,  0.00367044,  0.00367044,\n",
       "         0.00367044,  0.00367044,  0.00367044,  0.00367044, -0.07364302,\n",
       "         0.00367044,  0.00367044,  0.00367044,  0.00367044,  0.00367044,\n",
       "        -0.03498629,  0.00367044,  0.00367044, -0.03498629,  0.00367044]),\n",
       " 'shap_detect_class24': array([-0.008050206215858391, 0.011168379563576414, -0.02342507483799794,\n",
       "        -0.01765949910359066, -0.017659499104285215, 0.04375641631965377,\n",
       "        -0.008050206214764266, -0.008050206214349931, -0.04648737777159728,\n",
       "        -0.008050206214241684, -0.008050206214701094, 0.011168379563668118,\n",
       "        0.052351063375714935, -0.008050206214091804, 0.07560716717477867,\n",
       "        -0.017659499104161314, -0.008050206214828881, -0.04648737777191281,\n",
       "        -0.008050206214793798, -0.023425074837741477,\n",
       "        -0.008050206214673228, -0.00036277190320987973,\n",
       "        0.008133866019942149, -0.0080502062147072, 0.9913162542769374,\n",
       "        0.011168379563913033, 0.011168379563892605, 0.011168379563979314,\n",
       "        -0.017659499104139442, -0.008050206214745725,\n",
       "        -0.020542286970875567, 0.05235106337551787, -0.008050206214647582,\n",
       "        0.011168379563942898, -0.019176755876106566, 0.01116837956396044,\n",
       "        0.011168379563972097, -0.01765949910396858, 0.011168379563911812,\n",
       "        0.011168379563969766, 0.039996258232029014, -0.008050206214584299,\n",
       "        0.011168379563948116, 0.011168379563917585, -0.00695200131306728,\n",
       "        -0.00036277190326561293, -0.008050206214674005,\n",
       "        -0.023425074837623905, -0.0176594991039829, 0.005402803830458436,\n",
       "        0.06882413690000488, 0.030386965342719896, 0.02634094728401004,\n",
       "        -0.017659499104067722, -0.023425074837648996,\n",
       "        -0.008050206214683775, -0.023425074837625792,\n",
       "        -0.008050206214638922, -0.008050206214692102,\n",
       "        -0.008050206214696431, -0.008050206214686106, 0.011168379564073683,\n",
       "        0.03490898552584876, -0.008050206214719413, -0.008050206214656797,\n",
       "        0.01116837956406358, -0.023425074837686632, 0.011168379563986752,\n",
       "        -0.017659499104062837, -0.02726879199331389, 0.011168379563966657,\n",
       "        0.05235106337548068, -0.008050206214741396, -0.0049752324900316225,\n",
       "        -0.04648737777204659, 0.011168379563897712, -0.0234250748376289,\n",
       "        -0.008050206214683775, 0.01116837956401906, 0.01116837956397887,\n",
       "        0.011168379564026831, -0.008050206214583078, 0.011168379563953557,\n",
       "        -0.0080502062146931, -0.008050206214673672, -0.023425074837639337,\n",
       "        -0.017659499104097587, 0.011168379563929243, 0.019058114778394142,\n",
       "        0.0029318428016688047, -0.008050206214670008,\n",
       "        -0.017659499104067944, 0.011168379563954223, 0.011168379564078568,\n",
       "        -0.008050206214775368, 0.022699531031171838, 0.011168379564035047,\n",
       "        0.011168379563964326, 0.0006855145936222051, -0.01765949910416964],\n",
       "       dtype=object),\n",
       " 'mask_detect_class24': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class41': array([ 0.02295975, -0.02342832,  0.02295975, -0.00023428, -0.00023428,\n",
       "        -0.0698164 ,  0.02295975, -0.02342832,  0.04615379, -0.04662236,\n",
       "         0.20851206,  0.04615379, -0.00023428, -0.02342832, -0.04662236,\n",
       "        -0.02342832, -0.02342832,  0.02295975,  0.04615379,  0.02295975,\n",
       "         0.02295975,  0.04615379, -0.02342832, -0.04662236,  0.11573591,\n",
       "        -0.02342832, -0.02342832, -0.04662236, -0.02342832, -0.13939851,\n",
       "        -0.00023428,  0.04615379,  0.02295975,  0.02295975,  0.02295975,\n",
       "         0.02295975,  0.11573591, -0.02342832,  0.02295975,  0.06934783,\n",
       "         0.04615379,  0.02295975,  0.04615379, -0.02342832, -0.04662236,\n",
       "        -0.0698164 ,  0.02295975, -0.02342832, -0.02342832,  0.06934783,\n",
       "        -0.00023428,  0.09254187, -0.02342832,  0.04615379, -0.02342832,\n",
       "        -0.00023428,  0.04615379, -0.02342832, -0.04662236,  0.09254187,\n",
       "        -0.02342832,  0.06934783,  0.02295975,  0.02295975, -0.02342832,\n",
       "        -0.02342832,  0.04615379,  0.02295975, -0.0698164 , -0.0698164 ,\n",
       "        -0.00023428, -0.02342832, -0.04662236, -0.0698164 , -0.04662236,\n",
       "         0.02295975, -0.02342832,  0.04615379, -0.0698164 ,  0.04615379,\n",
       "        -0.04662236, -0.02342832,  0.13892994,  0.02295975,  0.02295975,\n",
       "        -0.0698164 , -0.00023428, -0.02342832, -0.00023428, -0.00023428,\n",
       "         0.16212398, -0.00023428,  0.04615379,  0.04615379,  0.02295975,\n",
       "        -0.00023428,  0.09254187,  0.02295975,  0.04615379,  0.04615379]),\n",
       " 'shap_detect_class41': array([-0.8282931514862782, 0.20951048056675936, 0.20951048056675134,\n",
       "        0.2095104805646233, 0.20951048056174001, -0.8282931514893165,\n",
       "        0.20951048056641025, -0.8282931514809193, 0.20951048056831884,\n",
       "        0.2095104805677022, 0.20951048056716776, 0.20951048056719868,\n",
       "        0.20951048056723814, 0.20951048056736302, 0.20951048056677155,\n",
       "        0.20951048057039448, 0.2095104805662043, -0.8282931514827733,\n",
       "        0.20951048056750793, 0.20951048056740545, 0.20951048056616567,\n",
       "        0.20951048056639046, 0.2095104805674423, 0.20951048056742533,\n",
       "        0.2095104805663405, 0.2095104805662485, 0.20951048056738208,\n",
       "        0.2095104805674069, 0.20951048056629545, -0.8282931514827325,\n",
       "        0.20951048056749225, 0.20951048056742805, 0.20951048056640623,\n",
       "        -0.8282931514827705, 0.20951048056738159, 0.2095104805674207,\n",
       "        0.20951048056639332, 0.20951048056641333, 0.20951048056737562,\n",
       "        0.2095104805674256, 0.20951048056636232, 0.20951048056658286,\n",
       "        0.20951048056743227, 0.20951048056742527, -0.828293151482679,\n",
       "        -0.8282931514826553, 0.20951048056756075, 0.20951048056736474,\n",
       "        -0.8282931514826307, 0.20951048056634378, 0.20951048056720395,\n",
       "        0.20951048056743918, 0.2095104805663313, -0.8282931514826503,\n",
       "        0.20951048056740607, 0.20951048056734328, 0.20951048056635113,\n",
       "        0.2095104805663265, 0.20951048056727817, 0.20951048056733446,\n",
       "        0.20951048056636157, 0.20951048056630603, 0.20951048056738206,\n",
       "        0.20951048056746363, 0.20951048056636515, 0.20951048056632574,\n",
       "        0.20951048056728017, 0.2095104805674771, -0.8282931514826907,\n",
       "        0.2095104805663296, 0.20951048056739824, -0.8282931514815655,\n",
       "        -0.8282931514826929, -0.82829315148271, 0.20951048056728516,\n",
       "        0.20951048056746227, -0.8282931514826751, 0.2095104805663149,\n",
       "        -0.8137580866071091, -0.8282931514815672, -0.8282931514825889,\n",
       "        0.20951048056636065, 0.20951048056728164, 0.20951048056750296,\n",
       "        -0.8282931514817241, 0.20951048056736185, 0.20951048056731394,\n",
       "        0.20951048056750946, 0.20951048056740892, 0.2095104805673387,\n",
       "        0.20951048056774177, 0.2095104805674018, 0.20951048056740668,\n",
       "        0.2095104805673405, 0.2095104805676158, 0.20951048056739732,\n",
       "        0.20951048056744964, 0.20951048056427846, -0.8282931514862496,\n",
       "        0.20951048056296528], dtype=object),\n",
       " 'mask_detect_class41': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 0., 1.]]),\n",
       " 'shap_class_class46': array([-0.01407829,  0.09134915, -0.01407829, -0.01407829, -0.01407829,\n",
       "         0.09134915, -0.01407829, -0.01407829,  0.03863543, -0.01407829,\n",
       "         0.09134915, -0.01407829,  0.09134915, -0.01407829,  0.03863543,\n",
       "        -0.01407829,  0.03863543, -0.06679201, -0.01407829, -0.01407829,\n",
       "        -0.11950574,  0.09134915, -0.06679201, -0.01407829, -0.01407829,\n",
       "         0.03863543,  0.03863543, -0.01407829,  0.03863543, -0.01407829,\n",
       "        -0.01407829, -0.01407829, -0.01407829, -0.01407829, -0.01407829,\n",
       "        -0.06679201, -0.01407829, -0.01407829,  0.03863543,  0.03863543,\n",
       "         0.03863543, -0.01407829, -0.01407829, -0.11950574, -0.06679201,\n",
       "        -0.01407829, -0.06679201, -0.01407829, -0.01407829,  0.03863543,\n",
       "         0.09134915,  0.09134915,  0.03863543, -0.01407829, -0.01407829,\n",
       "         0.03863543, -0.01407829, -0.01407829, -0.11950574, -0.01407829,\n",
       "         0.03863543, -0.01407829, -0.06679201, -0.01407829, -0.01407829,\n",
       "        -0.01407829, -0.01407829, -0.01407829, -0.01407829,  0.03863543,\n",
       "        -0.01407829,  0.09134915, -0.01407829,  0.03863543, -0.01407829,\n",
       "        -0.06679201, -0.01407829, -0.01407829, -0.01407829, -0.01407829,\n",
       "        -0.06679201,  0.03863543,  0.03863543, -0.01407829, -0.01407829,\n",
       "        -0.01407829, -0.01407829,  0.09134915, -0.01407829,  0.09134915,\n",
       "        -0.01407829, -0.01407829, -0.01407829, -0.01407829, -0.01407829,\n",
       "         0.03863543,  0.03863543,  0.03863543,  0.09134915, -0.01407829]),\n",
       " 'shap_detect_class46': array([-0.10152161232147017, 0.936282019731484, -0.10152161231060053,\n",
       "        -0.10152161230861623, -0.10152161230771051, 0.9362820197436476,\n",
       "        -0.10152161231135237, -0.10152161231128953, -0.10152161231030854,\n",
       "        -0.10152161231040147, -0.10152161231163437, -0.10152161231097379,\n",
       "        0.936282019739322, -0.10152161230963042, -0.07491126277185556,\n",
       "        -0.10152161231163981, -0.10152161231074586, -0.10152161231054246,\n",
       "        -0.10152161231158108, -0.10152161231156998, -0.03835095644680664,\n",
       "        0.9362820197382271, -0.1015216123114081, -0.10152161231129242,\n",
       "        0.20981947730402528, -0.10152161231083545, -0.10152161231149992,\n",
       "        -0.10152161231128587, -0.10152161231085177, -0.10152161231080559,\n",
       "        -0.05434871994553647, -0.10152161231120671, -0.10152161231062762,\n",
       "        -0.10152161231076595, -0.10152161231148304, 0.054148932496044244,\n",
       "        -0.10152161231069667, -0.1015216123107372, -0.10152161231146628,\n",
       "        -0.10152161231127532, -0.10152161231074408, 0.0049197858482742385,\n",
       "        -0.10152161231131118, -0.10152161231130985, -0.10152161231077739,\n",
       "        -0.10152161231082868, -0.10152161231125723, -0.10152161231127577,\n",
       "        -0.10152161231063606, -0.10152161231060297, 0.936282019737597,\n",
       "        0.9362820197377505, -0.10152161231071155, -0.10152161231066748,\n",
       "        -0.10152161231143197, -0.10152161231133872, -0.10152161231067469,\n",
       "        -0.10152161231064105, -0.10152161231142276, -0.10152161231137002,\n",
       "        -0.10152161231068058, -0.10152161231061729, -0.10152161231145662,\n",
       "        -0.10152161231134982, -0.10152161231064472, -0.10152161231065415,\n",
       "        -0.10152161231144707, -0.10152161231129164, -0.10152161231069678,\n",
       "        -0.10152161231064016, -0.10152161231142498, 0.9362820197377394,\n",
       "        -0.101521612310698, -0.10152161231062817, -0.10152161231136969,\n",
       "        -0.10152161231135881, -0.10152161231061285, -0.10152161231068646,\n",
       "        -0.10152161231137635, -0.10152161231133572, -0.10152161231059431,\n",
       "        -0.10152161231060675, -0.101521612311393, -0.1015216123111603,\n",
       "        -0.10152161231114332, -0.10152161231112844, -0.10152161231125256,\n",
       "        0.9362820197379298, -0.10152161231116252, 0.9362820197378393,\n",
       "        -0.10152161231112788, -0.10152161231114298, -0.10152161231115486,\n",
       "        -0.1015216123111421, -0.10152161231117307, -0.10152161231113432,\n",
       "        -0.10152161231117096, -0.10152161230947909, 0.9362820197401256,\n",
       "        -0.10152161230895729], dtype=object),\n",
       " 'mask_detect_class46': array([[0., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 0., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class47': array([-6.52646090e-04,  4.07652788e-02,  4.07652788e-02,  8.21832037e-02,\n",
       "         4.07652788e-02, -6.52646088e-04, -8.34884958e-02, -4.20705710e-02,\n",
       "        -4.20705710e-02, -6.52646089e-04,  8.21832037e-02, -6.52646089e-04,\n",
       "        -1.66324346e-01, -6.52646088e-04,  8.27705851e-01, -8.34884958e-02,\n",
       "         4.07652788e-02, -4.20705710e-02,  4.07652788e-02, -8.34884958e-02,\n",
       "        -4.20705710e-02,  4.07652788e-02,  2.06436978e-01, -6.52646089e-04,\n",
       "        -8.34884958e-02,  1.23601129e-01,  8.21832037e-02,  8.21832037e-02,\n",
       "         1.23601129e-01, -6.52646089e-04, -6.52646089e-04,  4.07652788e-02,\n",
       "         8.21832037e-02,  2.47854903e-01, -6.52646089e-04, -4.20705710e-02,\n",
       "        -6.52646089e-04, -4.20705710e-02, -6.52646089e-04, -8.34884958e-02,\n",
       "        -4.20705710e-02, -4.20705710e-02, -6.52646089e-04, -6.52646089e-04,\n",
       "        -4.20705710e-02,  4.07652788e-02, -4.20705710e-02,  1.23601129e-01,\n",
       "        -6.52646089e-04, -8.34884958e-02, -6.52646089e-04, -4.20705710e-02,\n",
       "        -4.20705710e-02,  4.07652788e-02, -4.20705710e-02, -4.20705710e-02,\n",
       "        -4.20705710e-02, -4.20705710e-02,  8.21832037e-02,  8.21832037e-02,\n",
       "        -4.20705710e-02,  8.21832037e-02, -8.34884958e-02, -8.34884958e-02,\n",
       "        -4.20705710e-02, -6.52646089e-04, -6.52646089e-04,  4.07652788e-02,\n",
       "        -4.20705710e-02, -6.52646089e-04, -4.20705710e-02, -4.20705710e-02,\n",
       "        -4.20705710e-02, -6.52646089e-04, -6.52646089e-04, -4.20705710e-02,\n",
       "        -4.20705710e-02, -8.34884958e-02, -6.52646089e-04, -6.52646089e-04,\n",
       "        -4.20705710e-02, -4.20705710e-02, -6.52646089e-04, -6.52646089e-04,\n",
       "        -4.20705710e-02,  8.21832037e-02, -6.52646089e-04, -6.52646089e-04,\n",
       "        -6.52646089e-04,  2.06436978e-01,  4.07652788e-02, -4.20705710e-02,\n",
       "        -4.20705710e-02,  1.23601129e-01, -8.34884958e-02, -4.20705710e-02,\n",
       "         8.21832037e-02, -8.34884958e-02, -4.20705710e-02, -4.20705710e-02]),\n",
       " 'shap_detect_class47': array([0.2670662553412925, -0.770737376709273, 0.26706625533430955,\n",
       "        0.26706625533390066, 0.2670662553326177, 0.26706625533324657,\n",
       "        0.26706625533179007, -0.7256154796674479, 0.26706625533850264,\n",
       "        -0.7707373767102157, 0.26706625533127515, 0.2670662553324301,\n",
       "        -0.6220178531176563, 0.2670662553374437, 0.2670662553322474,\n",
       "        -0.730821852401615, 0.26706625533316164, 0.26706625533325246,\n",
       "        0.2670662553330142, 0.26706625533294864, -0.7274955587140659,\n",
       "        -0.7707373767156647, 0.26706625533368744, 0.26706625533340095,\n",
       "        0.2670662553328017, 0.2670662553326062, 0.267066255333034,\n",
       "        -0.7707373767156561, 0.26706625533263617, 0.2670662553326339,\n",
       "        0.2670662553337681, 0.2670662553334244, 0.267066255332901,\n",
       "        0.2670662553325963, 0.2670662553328634, 0.26706625533340594,\n",
       "        0.26706625533289113, -0.7707373767156322, 0.2670662553328674,\n",
       "        0.267066255333406, 0.26706625533301265, -0.7707373767156238,\n",
       "        0.26706625533330514, 0.2670662553333962, 0.26706625533300515,\n",
       "        0.26706625533338135, 0.26706625533384437, 0.267066255333238,\n",
       "        0.26706625533291733, 0.2670662553334558, 0.2670662553329725,\n",
       "        0.2670662553334185, -0.770737376715827, 0.26706625533344286,\n",
       "        -0.7707373767157191, 0.26706625533322575, 0.26706625533321526,\n",
       "        0.26706625533341727, 0.2670662553330749, 0.26706625533322265,\n",
       "        -0.7235644843499325, 0.26706625533317097, -0.7707373767157355,\n",
       "        0.26706625533346673, 0.26706625533326384, 0.26706625533340844,\n",
       "        -0.7707373767159726, 0.2670662553335015, -0.7707373767157948,\n",
       "        0.26706625533342687, -0.7707373767157186, -0.7406561120184734,\n",
       "        0.26706625533324446, 0.2670662553334256, 0.2670662553330815,\n",
       "        0.2670662553334789, 0.2670662553332736, 0.2670662553334121,\n",
       "        0.2670662553330954, -0.6718989355680243, 0.26706625533352535,\n",
       "        -0.6804935826243628, 0.2670662553330791, 0.26706625533327905,\n",
       "        0.2670662553334261, 0.26706625533343376, 0.2670662553328672,\n",
       "        0.26706625533327827, -0.7707373767157835, 0.2670662553331218,\n",
       "        0.267066255333621, 0.2670662553330142, 0.26706625533324585,\n",
       "        -0.7707373767159114, -0.770737376715799, -0.7707373767160339,\n",
       "        0.26706625533347805, -0.7707373767167582, 0.26706625533130857,\n",
       "        -0.7707373767174239], dtype=object),\n",
       " 'mask_detect_class47': array([[1., 0., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.]]),\n",
       " 'shap_class_class29': array([-0.04894053,  0.1341703 ,  0.07313335,  0.01209641, -0.04894053,\n",
       "         0.01209641,  0.01209641,  0.01209641, -0.04894053,  0.01209641,\n",
       "         0.01209641,  0.01209641,  0.1341703 , -0.10997747,  0.07313335,\n",
       "         0.01209641, -0.04894053,  0.01209641,  0.1341703 ,  0.01209641,\n",
       "         0.01209641,  0.01209641,  0.1341703 , -0.10997747, -0.04894053,\n",
       "        -0.04894053, -0.04894053, -0.10997747,  0.01209641,  0.07313335,\n",
       "        -0.04894053,  0.01209641, -0.04894053,  0.07313335,  0.01209641,\n",
       "        -0.04894053,  0.01209641, -0.04894053, -0.04894053,  0.01209641,\n",
       "         0.01209641,  0.07313335, -0.04894053, -0.04894053, -0.10997747,\n",
       "         0.01209641,  0.01209641,  0.07313335,  0.01209641,  0.07313335,\n",
       "        -0.04894053, -0.04894053,  0.07313335,  0.01209641, -0.04894053,\n",
       "         0.01209641, -0.04894053, -0.04894053,  0.07313335, -0.04894053,\n",
       "        -0.10997747, -0.04894053, -0.04894053,  0.07313335, -0.04894053,\n",
       "         0.07313335, -0.04894053,  0.01209641,  0.1341703 ,  0.01209641,\n",
       "        -0.04894053,  0.07313335, -0.04894053, -0.04894053, -0.04894053,\n",
       "        -0.04894053, -0.04894053,  0.01209641,  0.07313335, -0.10997747,\n",
       "        -0.04894053,  0.01209641,  0.01209641, -0.04894053,  0.07313335,\n",
       "        -0.04894053,  0.01209641, -0.04894053,  0.01209641,  0.07313335,\n",
       "         0.07313335, -0.04894053,  0.01209641,  0.01209641,  0.01209641,\n",
       "         0.1341703 , -0.04894053,  0.1341703 ,  0.01209641,  0.01209641]),\n",
       " 'shap_detect_class29': array([0.13477969247272995, 0.13477969247347912, 0.13477969247386545,\n",
       "        0.13477969247306565, 0.13477969247356109, 0.13477969247392327,\n",
       "        0.1347796924731442, -0.9030239395721115, 0.13477969248057742,\n",
       "        -0.9030239395682484, 0.1347796924705591, 0.13477969247446006,\n",
       "        0.13477969247382243, -0.754766277854096, 0.13477969247332275,\n",
       "        -0.9030239395747801, -0.9030239395756896, 0.13477969247394286,\n",
       "        0.13477969247344404, 0.13477969247353783, -0.9030239395756252,\n",
       "        0.1347796924741627, 0.13477969247428387, 0.13477969247385987,\n",
       "        0.134779692473186, 0.1347796924733748, 0.13477969247344887,\n",
       "        0.13477969247383043, 0.13477969247324906, 0.1347796924732554,\n",
       "        0.13477969247429325, 0.13477969247384344, 0.13477969247320873,\n",
       "        0.13477969247321134, 0.1347796924733787, 0.13477969247386554,\n",
       "        0.13477969247320223, -0.9030239395748654, 0.13477969247337665,\n",
       "        0.1347796924738651, -0.9030239395751976, 0.13477969247409738,\n",
       "        0.13477969247374308, 0.13477969247386262, 0.1347796924738461,\n",
       "        0.13477969247416385, 0.13477969247396396, 0.134779692473785,\n",
       "        0.13477969247320867, 0.13477969247409377, 0.13477969247377383,\n",
       "        -0.9030239395751968, 0.1347796924740436, 0.13477969247405303,\n",
       "        0.13477969247388807, 0.1347796924737281, 0.1347796924740349,\n",
       "        0.13477969247421678, 0.13477969247379876, 0.13477969247372676,\n",
       "        0.13477969247416038, 0.1347796924741097, -0.903023939575154,\n",
       "        0.13477969247384264, 0.13477969247417781, 0.13477969247421262,\n",
       "        -0.9030239395752482, 0.13477969247384966, 0.1347796924741741,\n",
       "        0.1347796924742195, 0.1347796924738912, 0.13477969247384824,\n",
       "        0.1347796924741683, 0.13477969247422003, 0.13477969247380114,\n",
       "        0.13477969247384528, 0.13477969247417926, 0.1347796924742077,\n",
       "        0.13477969247380725, -0.9030239395751938, 0.1347796924742078,\n",
       "        0.13477969247424182, 0.134779692473801, 0.13477969247381005,\n",
       "        0.13477969247432786, 0.13477969247431798, 0.13477969247375512,\n",
       "        0.13477969247381247, 0.13477969247392627, 0.1347796924739189,\n",
       "        0.13477969247416033, 0.13477969247348884, 0.13477969247392754,\n",
       "        -0.9030239395751221, 0.13477969247350347, 0.13477969247347957,\n",
       "        0.13477969247396188, 0.13477969247278973, 0.13477969247222332,\n",
       "        0.13477969247181143], dtype=object),\n",
       " 'mask_detect_class29': array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_expl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459239c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:40:00,103 [INFO] utils.log: classes with highest and lowest separabilities...: [29 27 24 14  6 46 45 18 10 48 34 35 49 26  0 13  5 20 19 30  8 21 44 11\n",
      "  1 17 40 12 15 23 28 39 22  9 38 36 32 33 31  4  7 41 43  2 37 47]\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/tmp/ipykernel_3331045/3557504847.py:437: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(3*top_k/2,5))\n",
      "/tmp/ipykernel_3331045/3557504847.py:437: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(3*top_k/2,5))\n",
      "/tmp/ipykernel_3331045/3557504847.py:437: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(3*top_k/2,5))\n",
      "/tmp/ipykernel_3331045/3557504847.py:437: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(3*top_k/2,5))\n",
      "/tmp/ipykernel_3331045/3557504847.py:437: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(3*top_k/2,5))\n",
      "/tmp/ipykernel_3331045/3557504847.py:437: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(3*top_k/2,5))\n",
      "/tmp/ipykernel_3331045/3780220629.py:47: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axes = plt.subplots(nrows=1, ncols=2)\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/dingw/.conda/envs/adv_train/lib/python3.11/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/CPU:0'):\n",
    "\n",
    "if args.explain and args.shap:\n",
    "    logger.info(f'classes with highest and lowest separabilities...: {classes}')\n",
    "    k = 10\n",
    "    for i in range(N_CLASSES):\n",
    "\n",
    "        idx_in = np.where(in_test_yhat == i)[0]\n",
    "        idx_out = np.where(out_test_yhat == i)[0]\n",
    "        in_concepts_ith = in_test_concepts[idx_in,:] # concept scores of ID data classified as class i\n",
    "        out_concepts_ith = out_test_concepts[idx_out,:] # concept scores of OOD data classified as class i\n",
    "        \n",
    "        # if len(idx_in) < N_CONCEPTS or len(idx_out) < N_CONCEPTS:\n",
    "        #     continue\n",
    "\n",
    "        # indices for OOD detection results\n",
    "        idx_IN_IN = in_test_scores[idx_in] >= thres95   # ID detected as ID\n",
    "        idx_IN_OUT = ~idx_IN_IN                 # ID detected as OOD\n",
    "        idx_OUT_OUT = out_test_scores[idx_out] < thres95 # OOD detected as OOD\n",
    "        idx_OUT_IN = ~idx_OUT_OUT               # OOD detected as ID\n",
    "        \n",
    "        # relative comparison\n",
    "        scores = {}\n",
    "        labels = ['ID', 'OOD', 'ID->OOD', 'OOD->ID']\n",
    "        scores[labels[0]] = in_concepts_ith\n",
    "        scores[labels[1]] = out_concepts_ith\n",
    "        scores[labels[2]] = in_concepts_ith[idx_IN_OUT]\n",
    "        scores[labels[3]] = out_concepts_ith[idx_OUT_IN]\n",
    "\n",
    "        scores1 = {}\n",
    "        if (len(np.where(idx_IN_OUT)[0]) > 0) and (len(np.where(idx_OUT_IN)[0]) > 0):\n",
    "            labels1 = ['ID', 'ID->OOD', 'OOD->ID', 'OOD']\n",
    "            i_in_out = np.random.choice(len(np.where(idx_IN_OUT)[0]))\n",
    "            i_out_in = np.random.choice(len(np.where(idx_OUT_IN)[0]))\n",
    "            idx_in_out_sp = idx_in[idx_IN_OUT][i_in_out]\n",
    "            idx_out_in_sp = idx_out[idx_OUT_IN][i_out_in]\n",
    "            x_in_out_sp = in_loader[idx_in_out_sp//256][0][idx_in_out_sp%256]\n",
    "            y_in_out_sp = in_loader[idx_in_out_sp//256][1][idx_in_out_sp%256]\n",
    "            y_in_out_sp = int(np.where(y_in_out_sp)[0])\n",
    "            x_out_in_sp = out_loader[idx_out_in_sp//256][idx_out_in_sp%256]\n",
    "\n",
    "            scores1[labels1[0]] = in_concepts_ith\n",
    "            scores1[labels1[3]] = out_concepts_ith\n",
    "            scores1[labels1[1]] = np.expand_dims(in_concepts_ith[idx_IN_OUT][i_in_out], axis=0)  \n",
    "            scores1[labels1[2]] = np.expand_dims(out_concepts_ith[idx_OUT_IN][i_out_in], axis=0)   \n",
    "            \n",
    "            fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "            axes[0].imshow(x_in_out_sp)\n",
    "            axes[0].set_title(f\"IN->OUT, y_true={y_in_out_sp}\")\n",
    "            axes[0].axis(\"off\")\n",
    "            axes[1].imshow(x_out_in_sp)\n",
    "            axes[1].set_title(f\"OUT->IN\")\n",
    "            axes[1].axis(\"off\")\n",
    "            plt.savefig(os.path.join(explain_dir,'class{}_AwA2_{}_false_samples.jpg'.format(i,args.out_data)))\n",
    "            \n",
    "        scores2 = {}\n",
    "        if (len(np.where(idx_IN_IN)[0]) > 0) and (len(np.where(idx_OUT_OUT)[0]) > 0):\n",
    "            labels2 = ['ID', 'ID->ID', 'OOD->OOD', 'OOD']\n",
    "            i_in_in = np.random.choice(len(np.where(idx_IN_IN)[0]))\n",
    "            i_out_out = np.random.choice(len(np.where(idx_OUT_OUT)[0]))\n",
    "            idx_in_in_sp = idx_in[idx_IN_IN][i_in_in]\n",
    "            idx_out_out_sp = idx_out[idx_OUT_OUT][i_out_out]\n",
    "            x_in_in_sp = in_loader[idx_in_in_sp//256][0][idx_in_in_sp%256]\n",
    "            y_in_in_sp = in_loader[idx_in_in_sp//256][1][idx_in_in_sp%256]\n",
    "            y_in_in_sp = int(np.where(y_in_in_sp)[0])\n",
    "            x_out_out_sp = out_loader[idx_out_out_sp//256][idx_out_out_sp%256]\n",
    "    \n",
    "            scores2[labels2[0]] = in_concepts_ith\n",
    "            scores2[labels2[3]] = out_concepts_ith\n",
    "            scores2[labels2[1]] = np.expand_dims(in_concepts_ith[idx_IN_IN][i_in_in], axis=0) \n",
    "            scores2[labels2[2]] = np.expand_dims(out_concepts_ith[idx_OUT_OUT][i_out_out], axis=0)  \n",
    "\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "            axes[0].imshow(x_in_in_sp)\n",
    "            axes[0].set_title(f\"IN->IN, y_true={y_in_in_sp}\")\n",
    "            axes[0].axis(\"off\")\n",
    "            axes[1].imshow(x_out_out_sp)\n",
    "            axes[1].set_title(f\"OUT->OUT\")\n",
    "            axes[1].axis(\"off\")\n",
    "            plt.savefig(os.path.join(explain_dir,'class{}_AwA2_{}_true_samples.jpg'.format(i,args.out_data)))\n",
    "        \n",
    "        \n",
    "        if f\"shap_class_class{i}\" in shap_expl:\n",
    "            shap_expl_class_i = shap_expl[f\"shap_class_class{i}\"]\n",
    "            shap_expl_class_i_copy = shap_expl_class_i.copy()\n",
    "            c_is = []\n",
    "            for c_i, c_js in dict_dupl_topic.items():\n",
    "                c_js = [i_ for i_ in c_js if (i_ not in c_is)]\n",
    "                if len(c_js) > 0:\n",
    "                    shap_expl_class_i_copy[np.array(c_js)] = np.nan\n",
    "                c_is.append(c_i)\n",
    "            shap_expl_class_i_copy = shap_expl_class_i_copy[~np.isnan(shap_expl_class_i_copy)]\n",
    "\n",
    "            explain_relative(scores, labels, separa['class'+str(i)], shap_expl_class_i_copy, \n",
    "                figname=os.path.join(explain_dir,'class{}_AwA2_{}_shap_class_top{}_separability_{}.jpg'.format(i,args.out_data,k,args.score)),\n",
    "                figname_dist=os.path.join(explain_dir,'class{}_AwA2_{}_distribution.jpg'.format(i,args.out_data)),\n",
    "                top_k=k)\n",
    "            if len(scores1)>0:\n",
    "                explain_relative(scores1, labels1, separa['class'+str(i)], shap_expl_class_i_copy, \n",
    "                        figname=os.path.join(explain_dir,'class{}_AwA2_{}_shap_class_top{}_separability_{}_false_eg.jpg'.format(i,args.out_data,k,args.score)),\n",
    "                        figname_dist=os.path.join(explain_dir,'class{}_AwA2_{}_distribution.jpg'.format(i,args.out_data)),\n",
    "                        top_k=k)\n",
    "            if len(scores2)>0:\n",
    "                explain_relative(scores2, labels2, separa['class'+str(i)], shap_expl_class_i_copy, \n",
    "                    figname=os.path.join(explain_dir,'class{}_AwA2_{}_shap_class_top{}_separability_{}_true_eg.jpg'.format(i,args.out_data,k,args.score)),\n",
    "                    figname_dist=os.path.join(explain_dir,'class{}_AwA2_{}_distribution.jpg'.format(i,args.out_data)),\n",
    "                    top_k=k)\n",
    "\n",
    "        if f\"shap_detect_class{i}\" in shap_expl:\n",
    "            shap_expl_class_i = shap_expl[f\"shap_detect_class{i}\"]\n",
    "            shap_expl_class_i_copy = shap_expl_class_i.copy()\n",
    "            shap_expl_class_i_copy = shap_expl_class_i_copy.astype(float)\n",
    "            c_is = []\n",
    "            for c_i, c_js in dict_dupl_topic.items():\n",
    "                c_js = [i_ for i_ in c_js if (i_ not in c_is)]\n",
    "                if len(c_js) > 0:\n",
    "                    shap_expl_class_i_copy[np.array(c_js)] = np.nan\n",
    "                c_is.append(c_i)\n",
    "            shap_expl_class_i_copy = shap_expl_class_i_copy[~np.isnan(shap_expl_class_i_copy)]\n",
    "\n",
    "            explain_relative(scores, labels, separa['class'+str(i)], shap_expl_class_i_copy, \n",
    "                figname=os.path.join(explain_dir,'class{}_AwA2_{}_shap_detect_top{}_separability_{}.jpg'.format(i,args.out_data,k,args.score)),\n",
    "                figname_dist=os.path.join(explain_dir,'class{}_AwA2_{}_distribution.jpg'.format(i,args.out_data)),\n",
    "                top_k=k)\n",
    "            if len(scores1)>0:\n",
    "                explain_relative(scores1, labels1, separa['class'+str(i)], shap_expl_class_i_copy, \n",
    "                        figname=os.path.join(explain_dir,'class{}_AwA2_{}_shap_detect_top{}_separability_{}_false_eg.jpg'.format(i,args.out_data,k,args.score)),\n",
    "                        figname_dist=os.path.join(explain_dir,'class{}_AwA2_{}_distribution.jpg'.format(i,args.out_data)),\n",
    "                        top_k=k)\n",
    "            if len(scores2)>0:\n",
    "                explain_relative(scores2, labels2, separa['class'+str(i)], shap_expl_class_i_copy, \n",
    "                    figname=os.path.join(explain_dir,'class{}_AwA2_{}_shap_detect_top{}_separability_{}_true_eg.jpg'.format(i,args.out_data,k,args.score)),\n",
    "                    figname_dist=os.path.join(explain_dir,'class{}_AwA2_{}_distribution.jpg'.format(i,args.out_data)),\n",
    "                    top_k=k)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b4cfa-2939-4957-85ca-1eab380e8e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
