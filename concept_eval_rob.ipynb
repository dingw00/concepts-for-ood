{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17493425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "import copy\n",
    "import pandas as pd\n",
    "from scipy.special import comb\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sns.set_style(\"whitegrid\") #darkgrid\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "SMALL_SIZE=12\n",
    "MEDIUM_SIZE=15\n",
    "BIGGER_SIZE=20\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "#plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "#plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.metrics as metrics\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "import concept_model\n",
    "import helper\n",
    "# from test_baselines import run_eval\n",
    "\n",
    "\n",
    "from utils.test_utils import arg_parser, prepare_data, get_measures\n",
    "from utils.test_utils import ConceptProfiles\n",
    "from utils.test_utils import get_recovered_features\n",
    "from utils.ood_utils import run_ood_over_batch\n",
    "from utils.stat_utils import hellinger, compute_pval, bayes_posterior, FLD, multivar_separa\n",
    "from utils.plot_utils import plot_stats, plot_per_class_stats, plot_score_distr\n",
    "from utils import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03108c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.in_data = \"data/AwA2/test\"\n",
    "        self.out_data = \"SUN\" # MSCOCO\n",
    "        self.workers = 4\n",
    "        \n",
    "        self.batch_size = 256\n",
    "        self.name = \"test\"\n",
    "        self.model = \"InceptionV3\"\n",
    "        self.model_path = \"results/AwA2/inceptionv3_AwA2_normal_epoch_40.weights.h5\" # \"results/AwA2/inceptionv3_AwA2_normal_epoch_40.weights.h5\" \"results/AwA2/inceptionv3_AwA2_e40.weights.h5\"\n",
    "        self.concept_sim_thr = 0.95\n",
    "        \n",
    "        self.gpu = \"0\"\n",
    "        self.result_dir = f\"results/AwA2_2_baseline_normal/epoch_40_{self.concept_sim_thr}\" # AwA2_2_baseline_normal\n",
    "        self.logdir = self.result_dir+\"/logs\"\n",
    "        \n",
    "        self.shap = True\n",
    "        self.separate = True\n",
    "        self.explain = True\n",
    "        self.plot = True\n",
    "        self.out_data_dim = 224\n",
    "        self.score = \"energy\"\n",
    "        self.temperature_energy = 1\n",
    "        self.temperature_odin = 1000\n",
    "        \n",
    "\n",
    "        self.opt = \"adam\"\n",
    "\n",
    "args = ARGS()\n",
    "softmax = layers.Activation('softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee29317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_concepts(topic_vec, return_mapping=False, thr=0.95):\n",
    "    # Remove one concept vector if there are two vectors where the dot product is over 0.95\n",
    "    # topic_vec: dim=(dim_features, n_concepts) (2048, 70)\n",
    "    # print(np.shape(topic_vec))\n",
    "    n_concept = topic_vec.shape[1]\n",
    "    topic_vec_n = topic_vec/(np.linalg.norm(topic_vec,axis=0,keepdims=True)+1e-9)\n",
    "\n",
    "    topic_vec_n_dot = np.transpose(topic_vec_n) @ topic_vec_n - np.eye(n_concept)\n",
    "    dict_similar_topic = {}\n",
    "    idx_delete = set()\n",
    "    for i in range(n_concept):\n",
    "        ith_redundant_concepts = [j for j in range(n_concept) if topic_vec_n_dot[i][j] >= thr]\n",
    "        dict_similar_topic[i] = ith_redundant_concepts\n",
    "        \n",
    "        ith_redundant_concepts = [x for x in ith_redundant_concepts if x > i]\n",
    "        idx_delete.update(ith_redundant_concepts)\n",
    "    idx_delete = list(idx_delete)\n",
    "\n",
    "    topic_vec_r = np.delete(topic_vec, idx_delete, axis=1)\n",
    "\n",
    "\n",
    "    dict_topic_mapping = {}\n",
    "    count = 0\n",
    "    for i in range(n_concept):\n",
    "        if i in idx_delete:\n",
    "            dict_topic_mapping[i] = None\n",
    "        else:\n",
    "            dict_topic_mapping[i] = count\n",
    "            count += 1\n",
    "    print('concept mapping between before/after duplicate removal......')\n",
    "    print(dict_topic_mapping)\n",
    "    if return_mapping:\n",
    "        return topic_vec_r, dict_similar_topic, dict_topic_mapping\n",
    "    else:\n",
    "        return topic_vec_r, dict_similar_topic\n",
    "\n",
    "def visualize_nn(test_loader, topic_vec, f_test, save_dir, logger, out_data=None, dir=\"concepts\"):\n",
    "    num_concept = topic_vec.shape[1]\n",
    "\n",
    "    f_test_n = f_test/(np.linalg.norm(f_test,axis=3,keepdims=True)+1e-9)\n",
    "    topic_vec_n = topic_vec/(np.linalg.norm(topic_vec,axis=0,keepdims=True)+1e-9)\n",
    "    topic_prob = np.matmul(f_test_n,topic_vec_n)\n",
    "    n_size = np.shape(f_test)[1]\n",
    "    for i in range(num_concept):\n",
    "      savepath = os.path.join(save_dir, dir, 'concept'+str(i))\n",
    "      os.makedirs(savepath, exist_ok=True)\n",
    "        \n",
    "      neighbors_num = 15\n",
    "      ind = np.argpartition(topic_prob[:,:,:,i].flatten(), -neighbors_num)[-neighbors_num:]\n",
    "      sim_list = topic_prob[:,:,:,i].flatten()[ind]\n",
    "      logger.info(f'[ID TEST: CONCEPT {i}] top-{neighbors_num} scores: {sim_list}')\n",
    "      for jc,j in enumerate(ind):\n",
    "        j_int = int(np.floor(j/(n_size*n_size)))\n",
    "        a = int((j-j_int*(n_size*n_size))/n_size)\n",
    "        b = int((j-j_int*(n_size*n_size))%n_size)\n",
    "        \n",
    "        if not out_data:\n",
    "            f1 = savepath+'/concept_full_{}_{}_sim_{}.png'.format(i,jc, round(sim_list[jc], 3))\n",
    "            f2 = savepath+'/concept_{}_{}_sim_{}.png'.format(i,jc, round(sim_list[jc], 3)) \n",
    "        else:\n",
    "            f1 = savepath+'/{}_concept_full_{}_{}_sim_{}.png'.format(out_data, i,jc, round(sim_list[jc], 3))\n",
    "            f2 = savepath+'/{}_concept_{}_{}_sim_{}.png'.format(out_data, i,jc, round(sim_list[jc], 3))\n",
    "            \n",
    "        # if sim_list[jc]>0.70:\n",
    "        x_test_filename = test_loader.filepaths[j_int]\n",
    "        helper.copy_save_image(x_test_filename,f1,f2,a,b)\n",
    "        \n",
    "\n",
    "def compute_concept_scores(topic_vec, feature, predict_model=None):\n",
    "    # topic_vec: concept vectors (dim= (feature_dim, n_concepts))\n",
    "    # feature: features extracted from an intermediate layer of trained model\n",
    "\n",
    "    feature_n = tf.math.l2_normalize(feature, axis=3)\n",
    "    topic_vec_n = tf.math.l2_normalize(topic_vec, axis=0)\n",
    "\n",
    "    topic_prob = tf.matmul(feature_n, topic_vec_n) # K.dot\n",
    "\n",
    "    prob_max = tf.math.reduce_max(topic_prob, axis=(1,2))\n",
    "    prob_max_abs = tf.math.reduce_max(tf.abs(topic_prob), axis=(1,2))\n",
    "    concept_scores = tf.where(prob_max == prob_max_abs, prob_max, -prob_max_abs)\n",
    "\n",
    "    \"\"\"\n",
    "    ##for debugging\n",
    "    n_concept = np.shape(concept_scores)[1]\n",
    "    print(tf.reduce_mean(input_tensor=tf.nn.top_k(K.transpose(K.reshape(topic_prob,(-1,n_concept))),k=10,sorted=True).values))\n",
    "    print(tf.reduce_mean(input_tensor=K.dot(K.transpose(K.variable(value=topic_vec_n)), K.variable(value=topic_vec_n)) - np.eye(n_concept)))\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if predict_model: # in eager execution\n",
    "        pred = softmax(predict_model(feature))\n",
    "        #pred = tf.math.argmax(pred, axis=1)\n",
    "        return concept_scores.numpy(), pred.numpy()\n",
    "    else:\n",
    "        return concept_scores\n",
    "\n",
    "def prepare_profiles(feature_model, topic_vec, num_classes, args, logger):\n",
    "    # profiling using validation data\n",
    "    #profile_path = \"{}/AwA2_train_concept_dict.pkl\".format(args.result_dir)\n",
    "    profile_path = \"{}/AwA2_val_concept_dict.pkl\".format(args.result_dir)\n",
    "    if not os.path.exists(profile_path):\n",
    "        logger.info(\"Profiling the distribution of concept scores from train set...\")\n",
    "\n",
    "        tf.random.set_seed(0)\n",
    "        datagen = ImageDataGenerator(rescale=1./255.)\n",
    "                                                #rotation_range=40,\n",
    "                                                #width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                                #shear_range=0.2, zoom_range=0.2,\n",
    "                                                #horizontal_flip=True)\n",
    "        data_loader = datagen.flow_from_directory(\"data/AwA2/val\", \\\n",
    "                                                batch_size=350, target_size=(224,224), \\\n",
    "                                                class_mode='categorical', \\\n",
    "                                                shuffle=False)\n",
    "\n",
    "        ConceptP = ConceptProfiles()\n",
    "        ConceptP.setUp(num_classes, data_loader)\n",
    "        ConceptP.prepare_concept_dict(feature_model, topic_vec)\n",
    "        concept_dict = ConceptP.concept_dict\n",
    "\n",
    "        #LOAD_DIR = 'data/Animals_with_Attributes2'\n",
    "        #y_train = np.load(LOAD_DIR+'/y_train.npy')\n",
    "        #y_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "        logger.info(\"Saving concept profiles of AwA2 train set in {}\".format(profile_path))\n",
    "        with open(profile_path,'wb') as f:\n",
    "            pickle.dump(concept_dict, f)\n",
    "\n",
    "    else:\n",
    "        logger.info(\"Loading concept profiles of AwA2 train set from {}\".format(profile_path))\n",
    "        with open(profile_path,'rb') as f:\n",
    "            concept_dict = pickle.load(f)\n",
    "\n",
    "    return concept_dict\n",
    "\n",
    "\n",
    "def compute_coherency(feature, topic_vec):\n",
    "    \"\"\"\n",
    "    compute coherency across top-k nearest neighbors for each concept\n",
    "    :param topic_vec: concept vectors, dim=(feature_dim, num_concept)\n",
    "    :param feature: features extracted from an intermediate layer of trained model\n",
    "    \"\"\"\n",
    "\n",
    "    # normalize\n",
    "    feature_n = tf.math.l2_normalize(feature, axis=3)\n",
    "    topic_vec_n = tf.math.l2_normalize(topic_vec, axis=0)\n",
    "    \n",
    "    topic_prob = tf.matmul(feature_n, topic_vec_n) # normalized concept scores, dim=(num_data, num_concept)\n",
    "    num_concept = topic_prob.shape[1]\n",
    "    coher = tf.reduce_mean(tf.nn.top_k(K.transpose(K.reshape(topic_prob,(-1,num_concept))),k=10,sorted=True).values)\n",
    "    return coher.numpy()\n",
    "\n",
    "def compute_redundancy(topic_vec):\n",
    "    \"\"\"\n",
    "    compute similarity between concept vectors\n",
    "    :param topic_vec: normalized concept vectors, dim=(dim_feat, num_concept)\n",
    "    \"\"\"\n",
    "    num_concept = topic_vec.shape[-1]\n",
    "\n",
    "    topic_vec_n = tf.math.l2_normalize(topic_vec, axis=0)\n",
    "    redun = tf.reduce_mean(K.dot(K.transpose(topic_vec_n), topic_vec_n) - np.eye(num_concept))\n",
    "    return redun.numpy()\n",
    "\n",
    "def compute_completeness(y, yhat, yhat_recov, num_class, logger=None, label=None):\n",
    "    \"\"\"\n",
    "    compute completeness score by Yeh et al.\n",
    "    :param y: groundtruth class labels, dim=(N,)\n",
    "    :param yhat: predicted class labels, dim=(N,)\n",
    "    :param yhat_recov: predicted class labels using recovered features, dim=(N,).\n",
    "                       If label is not None, per-class predicted labels, dim=(N',) where N' <= N\n",
    "    \"\"\"\n",
    "\n",
    "    acc = np.sum(y == yhat)/len(y)\n",
    "    if logger:\n",
    "        logger.info(f'[ID TEST] accuracy with original features: {acc}')\n",
    "    \n",
    "    if label is not None:\n",
    "        acc_recov = np.sum(y[y==label] == yhat_recov)/len(yhat_recov)\n",
    "        if logger:\n",
    "            logger.info(f'[ID TEST] per-class accuracy with recovered features: {acc_recov}')\n",
    "        acc_random = 1/num_class #0.5 #NOTE: check a_r = 0.5?\n",
    "    else:\n",
    "        acc_recov = np.sum(y == yhat_recov)/len(y)\n",
    "        if logger:\n",
    "            logger.info(f'[ID TEST] accuracy with recovered features: {acc_recov}')\n",
    "        acc_random = 1/num_class\n",
    "    \n",
    "    # compute completeness\n",
    "    completeness = (acc_recov - acc_random) / (acc - 1/num_class)\n",
    "    if logger:\n",
    "        logger.info(f'[ID TEST] completeness score: {completeness}')\n",
    "    return completeness\n",
    "\n",
    "def compute_detection_completeness(auroc, auroc_recov, logger=None):\n",
    "    \"\"\"\n",
    "    compute detection completeness score\n",
    "    \"\"\"\n",
    "    # compute completeness\n",
    "    auroc_random = 1/2\n",
    "    completeness = (auroc_recov - auroc_random) / (auroc - auroc_random)\n",
    "    if logger:\n",
    "        logger.info(f'[DETECTION] auroc with original features: {auroc}')\n",
    "        logger.info(f'[DETECTION] auroc with recovered features: {auroc_recov}')\n",
    "        logger.info(f'[DETECTION] completeness score: {completeness}')\n",
    "    return completeness\n",
    "\n",
    "\n",
    "def compute_conceptSHAP(concept_mask, topic_vec, \n",
    "                        feat_in, feat_out, y, yhat_in, yhat_out, auroc,\n",
    "                        in_loader, out_loader,\n",
    "                        topic_model, feature_model, args, logger, \n",
    "                        finetune=False, labels=None):\n",
    "\n",
    "    assert labels is not None\n",
    "\n",
    "    num_class = 50\n",
    "    num_concept = topic_vec.shape[1]\n",
    "\n",
    "    ## modify topic model\n",
    "    logger.info(f'[ConceptSHAP] using concept mask: {concept_mask}.....')\n",
    "    #topic_vec_temp = np.random.rand(topic_vec.shape[0], topic_vec.shape[1]) \n",
    "    topic_vec_temp = copy.copy(topic_vec)\n",
    "    topic_vec_temp[:,np.array(concept_mask)==0] = 0\n",
    "    #print(topic_model.layers[0].get_weights())\n",
    "    topic_model.layers[0].set_weights([topic_vec_temp])\n",
    "    #print(topic_model.layers[0].get_weights())\n",
    "\n",
    "    _, logits_in, _ = topic_model(feat_in)\n",
    "    _, logits_out, _ = topic_model(feat_out)\n",
    "\n",
    "\n",
    "    compl_class, compl_detect = np.array([]), np.array([])\n",
    "    compl_class_2, compl_detect_2 = np.array([]), np.array([])\n",
    "    for label in labels:\n",
    "        # compute classification completeness\n",
    "        _, logits, _ = topic_model(feat_in[np.where(y == label)[0]])\n",
    "        #print(logits)\n",
    "        yhat_in_recov = tf.math.argmax(logits, axis=1)\n",
    "        _compl_class = compute_completeness(y, yhat_in, yhat_in_recov, num_class, logger, label)\n",
    "        compl_class = np.append(compl_class, _compl_class) \n",
    "        \n",
    "        # compute detection completeness\n",
    "        idx_in = np.where(tf.math.argmax(logits_in, axis=1).numpy() == label)[0]\n",
    "        idx_out = np.where(tf.math.argmax(logits_out, axis=1).numpy() == label)[0]\n",
    "        logger.info(f'[ConceptSHAP CLASS {label}] number of ID: {len(idx_in)} | number of OOD: {len(idx_out)}')\n",
    "        if len(idx_in) == 0 or len(idx_out) == 0:\n",
    "            compl_detect = np.append(compl_detect, None)\n",
    "            continue\n",
    "\n",
    "        s_in = run_ood_over_batch(None, feature_model, topic_model, args, num_class, feat_in[idx_in])\n",
    "        s_out = run_ood_over_batch(None, feature_model, topic_model, args, num_class, feat_out[idx_out])\n",
    "        #s_in, s_out = np.random.rand(len(idx_in)), np.random.rand(len(idx_out))\n",
    "        auroc_recov, aupr_in, aupr_out, fpr95, thres95 = get_measures(s_in[:,None],s_out[:,None])\n",
    "        _compl_detect = compute_detection_completeness(auroc, auroc_recov, logger)\n",
    "        compl_detect = np.append(compl_detect, _compl_detect) \n",
    "        logger.info(f'[ConceptSHAP CLASS {label}] auroc: {auroc_recov} | aupr_in: {aupr_in} | aupr_out: {aupr_out} | fpr95: {fpr95} | thres95: {thres95}')\n",
    "        logger.info(f'[ConceptSHAP CLASS {label}] (before finetuning) classification completeness: {_compl_class} | detection completeness: {_compl_detect}')\n",
    "\n",
    "        if finetune:\n",
    "            target_size = (224, 224)\n",
    "            batch_size = args.batch_size\n",
    "            train_datagen = ImageDataGenerator(rescale=1. / 255.,\n",
    "                                           rotation_range=40,\n",
    "                                           width_shift_range=0.2,\n",
    "                                           height_shift_range=0.2,\n",
    "                                           shear_range=0.2,\n",
    "                                           zoom_range=0.2,\n",
    "                                           horizontal_flip=True)\n",
    "            train_loader = train_datagen.flow_from_directory('data/AwA2/train',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    target_size=target_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "            # datagen = ImageDataGenerator(rescale=1.0 / 255.)\n",
    "            # ood_loader = datagen.flow_from_directory(\"./data/MSCOCO\",\n",
    "            #                                     batch_size=batch_size,\n",
    "            #                                     target_size=target_size,\n",
    "            #                                     class_mode=None, shuffle=True)\n",
    "    \n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            optimizer_state = [optimizer.iterations, optimizer.learning_rate, optimizer.beta_1, optimizer.beta_2, optimizer.weight_decay]\n",
    "            optimizer_reset = tf.compat.v1.variables_initializer(optimizer_state)\n",
    "            softmax = layers.Activation('softmax')\n",
    "            #train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "            #test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "        \n",
    "            COEFF_CONCEPT = 10.0\n",
    "        \n",
    "            train_step_signature = [\n",
    "            tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, None), dtype=tf.float32),\n",
    "            #tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32), \n",
    "            ]\n",
    "            @tf.function(input_signature=train_step_signature)\n",
    "            def train_step(x_in, y_in): #, x_out=None):\n",
    "                f_in = feature_model(x_in)\n",
    "                f_in_n = K.l2_normalize(f_in,axis=(3))\n",
    "            \n",
    "                #f_out = feature_model(x_out)\n",
    "                #f_out_n = K.l2_normalize(f_out,axis=(3))\n",
    "\n",
    "                obj_terms = {} # terms in the objective function\n",
    "                with tf.GradientTape() as tape:\n",
    "                    f_in_recov, logits_in, topic_vec_n = topic_model(f_in, training=True)\n",
    "                    pred_in = softmax(logits_in) # class prediction using concept scores\n",
    "                    topic_prob_in_n = K.dot(f_in_n, topic_vec_n) # normalized concept scores\n",
    "\n",
    "                    #_, logits_out, _ = topic_model(f_out, training=True)\n",
    "                    #topic_prob_out_n = K.dot(f_out_n, topic_vec_n)\n",
    "\n",
    "                    # baseline\n",
    "                    CE_IN = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_in, pred_in))\n",
    "                    loss_coherency = tf.reduce_mean(tf.nn.top_k(K.transpose(K.reshape(topic_prob_in_n,(-1,num_concept))),k=10,sorted=True).values)\n",
    "                    loss_similarity = tf.reduce_mean(K.dot(K.transpose(topic_vec_n), topic_vec_n) - tf.eye(num_concept))\n",
    "                    loss = CE_IN - COEFF_CONCEPT*loss_coherency + COEFF_CONCEPT*loss_similarity\n",
    "                    obj_terms['[ID] CE'] = CE_IN\n",
    "                    obj_terms['[ID] concept coherency'] = loss_coherency\n",
    "                    obj_terms['[ID] concept similarity'] = loss_similarity\n",
    "\n",
    "                grads = tape.gradient(loss, topic_model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, topic_model.trainable_variables))\n",
    "                return obj_terms\n",
    "\n",
    "            for layer in topic_model.layers:\n",
    "                layer.trainable = True\n",
    "                \n",
    "            for step, (x_in, y_in) in enumerate(train_loader):\n",
    "                step += 1\n",
    "                if step == len(train_loader): # >100\n",
    "                    break\n",
    "                #x_out = ood_loader.__next__()\n",
    "                obj_terms = train_step(x_in, y_in) #, x_out)\n",
    "                if step % 20 == 0:\n",
    "                    for term in obj_terms:\n",
    "                        print(f'[STEP{step}] {term}: {obj_terms[term]}')\n",
    "\n",
    "            for layer in topic_model.layers:\n",
    "                layer.trainable = False\n",
    "            #train_acc = train_acc_metric.result()\n",
    "            #logger.info(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "            # compute classification completeness\n",
    "            _, logits, _ = topic_model(feat_in[np.where(y == label)[0]])\n",
    "            #print(logits)\n",
    "            yhat_in_recov = tf.math.argmax(logits, axis=1)\n",
    "            _compl_class = compute_completeness(y, yhat_in, yhat_in_recov, num_class, logger, label)\n",
    "            compl_class_2 = np.append(compl_class_2, _compl_class)\n",
    "\n",
    "            # compute detection completeness\n",
    "            idx_in = np.where(tf.math.argmax(logits_in, axis=1).numpy() == label)[0]\n",
    "            idx_out = np.where(tf.math.argmax(logits_out, axis=1).numpy() == label)[0]\n",
    "            s_in = run_ood_over_batch(None, feature_model, topic_model, args, num_class, feat_in[idx_in])\n",
    "            s_out = run_ood_over_batch(None, feature_model, topic_model, args, num_class, feat_out[idx_out])\n",
    "            auroc_recov, aupr_in, aupr_out, fpr95, thres95 = get_measures(s_in[:,None],s_out[:,None])\n",
    "            _compl_detect = compute_detection_completeness(auroc, auroc_recov, logger)\n",
    "            compl_detect_2 = np.append(compl_detect_2, _compl_detect)\n",
    "            logger.info(f'[ConceptSHAP CLASS {label}] auroc: {auroc_recov} | aupr_in: {aupr_in} | aupr_out: {aupr_out} | fpr95: {fpr95} | thres95: {thres95}')\n",
    "            logger.info(f'[ConceptSHAP CLASS {label}] (after finetuning) classification completeness: {_compl_class} | detection completeness: {_compl_detect}')\n",
    "\n",
    "        logger.info('--------------------------------------------------------')\n",
    "\n",
    "    topic_model.layers[0].set_weights([topic_vec])\n",
    "    if finetune:\n",
    "        return compl_class_2, compl_detect_2\n",
    "    else:\n",
    "        assert len(compl_class) == len(labels)\n",
    "        assert len(compl_detect) == len(labels)\n",
    "        return compl_class, compl_detect\n",
    "\n",
    "\n",
    "def compute_separability(in_concept, out_concept, in_yhat, out_yhat, num_classes, logger=None):\n",
    "    # compute Multivariate Separability (global)\n",
    "    separa = {'global': multivar_separa(in_concept, out_concept).numpy()}\n",
    "\n",
    "    # compute per-class separability\n",
    "    # num_classes = 50\n",
    "    num_concepts = in_concept.shape[1]\n",
    "    for i in range(num_classes):\n",
    "        idx_in = np.where(in_yhat == i)[0]\n",
    "        idx_out = np.where(out_yhat == i)[0]\n",
    "        if logger:\n",
    "            logger.info(f'class {i}: num IN - {len(idx_in)}, num OUT - {len(idx_out)}')\n",
    "\n",
    "        ## explanation using groundtruth ID/OOD labels\n",
    "        #sep_concept_ith = FLD(in_concept[idx_in,:], out_concept[idx_out,:], optimal=False)\n",
    "        sep_concept_ith = multivar_separa(in_concept[idx_in,:], out_concept[idx_out,:]).numpy()\n",
    "        if logger:\n",
    "            logger.info(f'[CLASS {i}: SEPARABILITY, CONCEPTS] separability using groundtruth ID/OOD: {sep_concept_ith}')\n",
    "\n",
    "        separa['class'+str(i)] = sep_concept_ith\n",
    "\n",
    "    return separa\n",
    "\n",
    "\n",
    "def explain_topK(scores, top_k, separa, figname=None):\n",
    "    \"\"\"\n",
    "    Plot bar graph of top-k largest average concept scores\n",
    "    :param scores: concept scores, dim=(N,num_concepts)\n",
    "    :param top_k: interested in printing top-k highest concept scores\n",
    "    :param separa: separability score averaged across concepts or per-class multivariate separability\n",
    "    \"\"\"\n",
    "    s_mean = np.mean(scores, axis=0)\n",
    "    concept_idx = np.argsort(np.abs(s_mean))[::-1][:top_k] \n",
    "    \n",
    "    num_types = 1 \n",
    "    num_concepts = top_k\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(num_concepts) * bar_width * (num_types + 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3*top_k/5,3))\n",
    "    bar = ax.bar(index + 0 * bar_width, s_mean[concept_idx],\n",
    "            bar_width, yerr=np.std(scores[:,concept_idx],axis=0))\n",
    "    ax.set_title('Top-{0} concept scores, separability: {1:.5f}'.format(top_k, separa))\n",
    "    ax.set_ylabel('Concept score')\n",
    "    ax.set_xticks(index + num_types * bar_width / 2)\n",
    "    ax.set_xticklabels(['concept {}'.format(c) for c in concept_idx], rotation=45)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(figname)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def explain_relative(scores, labels, separa, shap_class_i, figname, figname_dist, top_k=6):\n",
    "    \"\"\"\n",
    "    scores: dictionary of concept scores of groundtruth ID, groundtruth OOD, ID -> ID, ID -> OOD, OOD -> ID, OOD -> OOD\n",
    "    labels: labels for different types of scores\n",
    "    separa: separability scores, dim=(num_concepts,)\n",
    "    \"\"\"\n",
    "    # concepts with top-k separability scores\n",
    "    concept_idx = np.argsort(shap_class_i)[::-1][:top_k] # top K: from largest to smallest value\n",
    "    # concept_idx = np.arange(top_k)\n",
    "    num_types = len(labels)\n",
    "    num_concepts = top_k\n",
    "    bar_width = 0.35\n",
    "    # create location for each bar. scale by an appropriate factor to ensure \n",
    "    # the final plot doesn't have any parts overlapping\n",
    "    index = np.arange(num_concepts) * bar_width * (num_types + 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3*top_k/2,5))\n",
    "    for i in range(num_types):\n",
    "        bar = ax.bar(index + i * bar_width, np.mean(scores[labels[i]][:,concept_idx],axis=0),\n",
    "                bar_width, yerr=np.std(scores[labels[i]][:,concept_idx],axis=0), \n",
    "                label=f\"{labels[i]}, num={len(scores[labels[i]])}\")\n",
    "    ax.set_title('Concept scores for each concept and ID/OOD data, separability: {1:.5f}'.format(top_k, separa))\n",
    "    ax.set_ylabel('Concept score')\n",
    "    ax.set_xticks(index + num_types * bar_width / 2)\n",
    "    ax.set_xticklabels([f'concept {c}\\nshap={round(shap_class_i[c], 3)}' for c in concept_idx], rotation=45)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(figname)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def save_images(filepaths, figname, k=5):\n",
    "\n",
    "    fig, axes = plt.subplots(1,k)\n",
    "    count = 0\n",
    "    np.random.shuffle(filepaths)\n",
    "    for f in filepaths:\n",
    "        img = Image.open(f).resize((100,100), Image.LANCZOS)\n",
    "        axes[count].imshow(img)\n",
    "        #ax2.set_title(\"ID image\", size=10, color='b')\n",
    "        axes[count].axis('off')\n",
    "    \n",
    "        count += 1\n",
    "        if count >= k:\n",
    "            break\n",
    "\n",
    "    fig.savefig(figname)\n",
    "    plt.close()\n",
    "\n",
    "def run_eval(feature_model, predict_model, in_loader, out_loader, logger, args, num_classes):\n",
    "    in_scores = np.array([])\n",
    "    for i, (x, y) in tqdm(enumerate(in_loader)):\n",
    "        if i == len(in_loader):\n",
    "            break\n",
    "        score = run_ood_over_batch(x, feature_model, predict_model, args, num_classes).numpy()\n",
    "        in_scores = np.concatenate([in_scores, score])\n",
    "    out_scores = np.array([])\n",
    "    for i, x in tqdm(enumerate(out_loader)):\n",
    "        if i == len(in_loader):\n",
    "            break\n",
    "        score = run_ood_over_batch(x, feature_model, predict_model, args, num_classes).numpy()\n",
    "        out_scores = np.concatenate([out_scores, score])\n",
    "    in_examples = np.expand_dims(in_scores, axis=1)\n",
    "    out_examples = np.expand_dims(out_scores, axis=1)\n",
    "    auroc, aupr_in, aupr_out, fpr, thres95 = get_measures(in_examples, out_examples)\n",
    "    return in_scores, out_scores, auroc, fpr, thres95\n",
    "\n",
    "def get_class_labels(loader, savepath):\n",
    "    \"\"\"\n",
    "    extract groundtruth class labels from data loader\n",
    "    :param loader: data loader\n",
    "    :param savepath: path to the numpy file\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(savepath):\n",
    "        y = np.load(savepath)\n",
    "    else:\n",
    "        num_data = len(loader.filenames)\n",
    "        y = []\n",
    "        for (_, y_batch), _ in zip(loader, range(len(loader))):\n",
    "            y.extend(y_batch)\n",
    "       \n",
    "        np.save(savepath, y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f81a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    logger = log.setup_logger(args, filename=\"eval_{}.log\".format(args.score))\n",
    "    LOAD_DIR = 'data/AwA2'\n",
    "    TOPIC_PATH = os.path.join(args.result_dir,'topic_vec_inceptionv3.npy')\n",
    "    INPUT_SHAPE = (args.out_data_dim, args.out_data_dim)\n",
    "    TRAIN_DIR = \"data/AwA2/train\"\n",
    "    N_CLASSES = 50\n",
    "    N_CONCEPTS_ORIG = 100 #np.shape(topic_vec_orig)[-1]\n",
    "    _ = 0\n",
    "    \n",
    "    if args.score == 'ODIN':\n",
    "        args.batch_size = 200\n",
    "    \n",
    "    if not os.path.exists(os.path.join(args.result_dir, 'plots')):\n",
    "        os.makedirs(os.path.join(args.result_dir, 'plots'))\n",
    "    if not os.path.exists(os.path.join(args.result_dir, 'explanations')):\n",
    "        os.makedirs(os.path.join(args.result_dir, 'explanations'))\n",
    "    if not os.path.exists(os.path.join(args.result_dir, 'explanations', args.out_data+'_'+args.score)):\n",
    "        os.makedirs(os.path.join(args.result_dir, 'explanations', args.out_data+'_'+args.score))\n",
    "    explain_dir = os.path.join(args.result_dir, 'explanations', args.out_data+'_'+args.score)\n",
    "    \n",
    "    in_loader, out_loader = prepare_data(args, logger)\n",
    "    \n",
    "    ## load trained_model\n",
    "    logger.info(f\"Loading model from {args.model_path}\")\n",
    "    feature_model, predict_model = helper.load_model_inception_new(_, in_loader, batch_size=args.batch_size, \n",
    "                                        input_size=INPUT_SHAPE, pretrain=True, modelname=args.model_path)\n",
    "    \n",
    "    in_test_features = feature_model.predict(in_loader)\n",
    "    out_test_features = feature_model.predict(out_loader, steps=len(in_loader))\n",
    "    N_IN = in_test_features.shape[0]\n",
    "    N_OUT = out_test_features.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df63228-80ec-4518-9c59-a75a95175e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add30f49-65c0-4576-a101-9869005355fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    ## load topic model\n",
    "    topic_model = concept_model.TopicModel(in_test_features, N_CONCEPTS_ORIG, thres=0.0, predict=predict_model)\n",
    "    for layer in topic_model.layers:\n",
    "        layer.trainable = False\n",
    "    topic_model(in_test_features)\n",
    "    topic_model.load_weights(os.path.dirname(args.result_dir)+f\"/topic_epoch{os.path.dirname(args.logdir).split('_')[-2]}.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58911223",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    ## load topic_vec\n",
    "    topic_vec_orig = topic_model.layers[0].get_weights()[0]\n",
    "    np.save(args.result_dir+'/topic_vec_orig.npy', topic_vec_orig)\n",
    "    logger.info(f'Number of concepts before removing duplicate ones: {str(N_CONCEPTS_ORIG)}')\n",
    "    \n",
    "    topic_vec, dict_dupl_topic = remove_duplicate_concepts(topic_vec_orig, thr=args.concept_sim_thr)\n",
    "    N_CONCEPTS = np.shape(topic_vec)[-1] # 25\n",
    "    logger.info(f'Number of concepts after removing duplicate ones: {str(N_CONCEPTS)}')\n",
    "    \n",
    "    in_test_concepts, in_test_logits = compute_concept_scores(topic_vec, in_test_features, predict_model)\n",
    "    out_test_concepts, out_test_logits = compute_concept_scores(topic_vec, out_test_features, predict_model)\n",
    "    in_test_yhat = np.argmax(in_test_logits, axis=1) \n",
    "    out_test_yhat = np.argmax(out_test_logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    # target OOD detector\n",
    "    logger.info(\"[ID TEST] performance of target OOD detector with test set...\")\n",
    "    in_test_scores, out_test_scores, auroc, fpr, thres95 = run_eval(feature_model, predict_model, in_loader, out_loader, logger, args, N_CLASSES)\n",
    "    # in_test_scores, out_test_scores, thres95, auroc = np.random.rand(N_IN), np.random.rand(N_OUT), 0.5419758558273315, 0.955332290562036\n",
    "    \n",
    "    # Plot ID vs OOD scores by the target detector\n",
    "    savefig = os.path.join(args.result_dir, 'plots', '{}_AwA2_test_{}_test.jpg'.format(args.score, args.out_data))\n",
    "    plot_stats(in_test_scores, out_test_scores, savename=savefig)\n",
    "    \n",
    "    ######################################\n",
    "    ## Evaluating coherency......\n",
    "    coherency = compute_coherency(in_test_features, topic_vec)\n",
    "    logger.info(f'[ID TEST] coherency: {coherency}')\n",
    "    \n",
    "    ######################################\n",
    "    ## Evaluating redundancy.......\n",
    "    redundancy = compute_redundancy(topic_vec)\n",
    "    logger.info(f'[CONCEPTS] redundancy: {redundancy}')\n",
    "    \n",
    "    #######################################\n",
    "    ## Evaluating the difference between two worlds......\n",
    "    y_test = np.argmax(np.load('data/AwA2/y_test.npy'), axis=1) # true labels\n",
    "    \n",
    "    logger.info(\"[ID TEST RECOVERED] performance of target OOD detector with test set...\")\n",
    "    in_test_scores_recov, out_test_scores_recov, auroc_recov, fpr_recov, thres95_recov = run_eval(feature_model, topic_model, in_loader, out_loader, logger, args, N_CLASSES)\n",
    "    savefig = os.path.join(args.result_dir, 'plots', '{}_recov_AwA2_test_{}_test.jpg'.format(args.score, args.out_data))\n",
    "    plot_stats(in_test_scores_recov, out_test_scores_recov, savename=savefig)\n",
    "    \n",
    "    # compute completeness scores\n",
    "    _, logits_recov, _ = topic_model(in_test_features)\n",
    "    in_test_yhat_recov = tf.math.argmax(logits_recov, axis=1).numpy()\n",
    "    compute_completeness(y_test, in_test_yhat, in_test_yhat_recov, N_CLASSES, logger)\n",
    "    compute_detection_completeness(auroc, auroc_recov, logger)\n",
    "    \n",
    "    ######################################\n",
    "    ## Compute Hellinger distance between original vs reconstructed classifier outputs\n",
    "    in_test_logits_recov = softmax(logits_recov).numpy()\n",
    "    H = np.array([hellinger(in_test_logits[i,:], in_test_logits_recov[i,:]) for i in range(in_test_logits.shape[0])])\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    sns.histplot(H, color='blue')\n",
    "    ax.legend(['in-distribution (test)'])\n",
    "    fig.savefig(os.path.join(args.result_dir, 'plots', 'classification_hellinger.jpg'))\n",
    "    plt.close()\n",
    "    \n",
    "    ######################################\n",
    "    # Save results....\n",
    "    results = {'in_yhat':in_test_yhat, 'out_yhat':out_test_yhat, \n",
    "            'in_yhat_recov':in_test_yhat_recov, \n",
    "            # 'out_yhat_recov':out_test_yhat_recov,\n",
    "            'in_logits':in_test_logits, 'in_logits_recov':in_test_logits_recov,\n",
    "            'in_concepts':in_test_concepts, 'out_concepts':out_test_concepts,\n",
    "            'in_scores':in_test_scores, 'out_scores':out_test_scores,\n",
    "            'thres':thres95,\n",
    "            'in_scores_recov':in_test_scores_recov, 'out_scores_recov':out_test_scores_recov}\n",
    "    \n",
    "    result_path = os.path.join(args.result_dir,'results_{}_{}.pkl'.format(args.score,args.out_data))\n",
    "    with open(result_path,'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    ## Evaluating separability of concepts......\n",
    "    #separa_path = os.path.join(args.result_dir, 'separability_AwA2_{}_raw.npy'.format(args.out_data))\n",
    "    separa_path = os.path.join(args.result_dir, 'separability_{}_AwA2_{}_multiv.npy'.format(args.score, args.out_data))\n",
    "    if args.separate:\n",
    "        idx_IN_IN = in_test_scores >= thres95\n",
    "        idx_IN_OUT = ~idx_IN_IN\n",
    "        idx_OUT_IN = out_test_scores >= thres95\n",
    "        idx_OUT_OUT = ~idx_OUT_IN\n",
    "        # separa = compute_separability(in_test_concepts, out_test_concepts, in_test_yhat, out_test_yhat, logger) # using groundtruth ID/OOD labels\n",
    "        in_detect_concepts = np.r_[in_test_concepts[idx_IN_IN], out_test_concepts[idx_OUT_IN]]\n",
    "        out_detect_concepts = np.r_[in_test_concepts[idx_IN_OUT], out_test_concepts[idx_OUT_OUT]]\n",
    "        in_detect_yhat = np.r_[in_test_yhat[idx_IN_IN], out_test_yhat[idx_OUT_IN]]\n",
    "        out_detect_yhat = np.r_[in_test_yhat[idx_IN_OUT], out_test_yhat[idx_OUT_OUT]]\n",
    "        separa = compute_separability(in_detect_concepts, out_detect_concepts, in_detect_yhat, out_detect_yhat, N_CLASSES, logger) # using detector's ID/OOD results in canonical world\n",
    "    \n",
    "        separa_global = separa['global']\n",
    "        logger.info(f'[GLOBAL SEPARABILITY] multivariate separability: {separa_global}')\n",
    "        separa_class = np.array([separa['class'+str(i)] for i in range(N_CLASSES)], dtype=np.float64)\n",
    "        logger.info(f'[PER-CLASS SEPARABILIRY] averaged separability: {np.nanmean(separa_class)}')\n",
    "    \n",
    "        rlt_dir_ = []\n",
    "        for p_ in args.result_dir.split(\"/\"):        \n",
    "            if \"AwA2\" in p_:\n",
    "                rlt_dir_ += [\"AwA2_2_baseline_normal\"]\n",
    "            elif \"epoch\" in p_:\n",
    "                rlt_dir_ += [f\"epoch_40_{args.concept_sim_thr}\"]\n",
    "            else:\n",
    "                rlt_dir_ += [p_]\n",
    "        baseline_folder = \"/\".join(rlt_dir_)\n",
    "    \n",
    "        separa0_path = os.path.join(baseline_folder, 'separability_{}_AwA2_{}_multiv.npy'.format(args.score, args.out_data))\n",
    "        if os.path.exists(separa0_path):\n",
    "            import statistics \n",
    "            separa0 = np.load(separa0_path, allow_pickle=True).item()\n",
    "            rel_separa_list = []\n",
    "            for i in range(N_CLASSES):\n",
    "                if np.isnan(separa0['class'+str(i)]) or np.isnan(separa['class'+str(i)]):\n",
    "                    continue\n",
    "                else:\n",
    "                    rel_ = (separa['class'+str(i)] - separa0['class'+str(i)]) / separa0['class'+str(i)]\n",
    "                    rel_separa_list.append(rel_)\n",
    "            rel_separa = statistics.median(rel_separa_list)\n",
    "            logger.info(f'[RELATIVE SEPARABILITY] relative separability: {rel_separa}')\n",
    "            separa['relative'] = rel_separa\n",
    "    \n",
    "        np.save(separa_path, separa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    # Generating explanations.....\n",
    "    classes = np.argsort(separa_class)[::-1]\n",
    "    #classes = np.append(classes[:5],[c for c in classes[-9:] if separa_class[c]]) # omitting classes with separability==0\n",
    "    classes = np.delete(classes, np.where(np.isnan(separa_class[classes]))[0])\n",
    "    \n",
    "    if args.explain:\n",
    "        logger.info(f'classes with highest and lowest separabilities...: {classes}')\n",
    "        k = 10\n",
    "        for i in range(N_CLASSES):\n",
    "    \n",
    "            idx_in = np.where(in_test_yhat == i)[0]\n",
    "            idx_out = np.where(out_test_yhat == i)[0]\n",
    "            in_concepts_ith = in_test_concepts[idx_in,:] # concept scores of ID data classified as class i\n",
    "            out_concepts_ith = out_test_concepts[idx_out,:] # concept scores of OOD data classified as class i\n",
    "            \n",
    "            if len(idx_in) == 0 or len(idx_out) ==0:\n",
    "                continue\n",
    "    \n",
    "            # indices for OOD detection results\n",
    "            idx_IN_IN = in_test_scores[idx_in] >= thres95   # ID detected as ID\n",
    "            idx_IN_OUT = ~idx_IN_IN                 # ID detected as OOD\n",
    "            idx_OUT_OUT = out_test_scores[idx_out] < thres95 # OOD detected as OOD\n",
    "            idx_OUT_IN = ~idx_OUT_OUT               # OOD detected as ID\n",
    "    \n",
    "            # print(np.sum(idx_IN_IN))\n",
    "            # print(np.sum(idx_IN_OUT))\n",
    "            # print(np.sum(idx_OUT_OUT))\n",
    "            # print(np.sum(idx_OUT_IN))\n",
    "            \n",
    "            explain_topK(in_concepts_ith, top_k=k, separa=separa_class[i], \n",
    "                        figname=os.path.join(explain_dir,'class{}_AwA2_top{}.jpg'.format(i, k)))\n",
    "            explain_topK(out_concepts_ith, top_k=k, separa=separa_class[i],\n",
    "                        figname=os.path.join(explain_dir,'class{}_{}_top{}.jpg'.format(i, args.out_data, k)))\n",
    "    \n",
    "    \n",
    "            # # most prominent concepts for ID/OOD images\n",
    "            # explain_topK(np.r_[in_concepts_ith[idx_IN_IN], out_concepts_ith[idx_OUT_IN]], top_k=k, separa=separa_class[i],\n",
    "            #             figname=os.path.join(explain_dir,'class{}_AwA2_top{}_detected_{}.jpg'.format(i, k, args.score)))\n",
    "            # explain_topK(np.r_[in_concepts_ith[idx_IN_OUT], out_concepts_ith[idx_OUT_OUT]], top_k=k, separa=separa_class[i],\n",
    "            #             figname=os.path.join(explain_dir,'class{}_{}_top{}_detected_{}.jpg'.format(i, args.out_data, k, args.score)))\n",
    "            \n",
    "            \n",
    "            # visualize example ID/OOD images\n",
    "            in_files_ith = np.array(in_loader.filepaths)[idx_in]\n",
    "            out_files_ith = np.array(out_loader.filepaths)[idx_out]\n",
    "            if np.sum(idx_IN_IN)!=0:\n",
    "                save_images(in_files_ith[idx_IN_IN], figname=os.path.join(explain_dir,'class{}_{}_AwA2_IN.jpg'.format(i, args.score)))\n",
    "            if np.sum(idx_IN_OUT)!=0:\n",
    "                save_images(in_files_ith[idx_IN_OUT], figname=os.path.join(explain_dir,'class{}_{}_AwA2_OUT.jpg'.format(i, args.score)))\n",
    "            if np.sum(idx_OUT_OUT)!=0:\n",
    "                save_images(out_files_ith[idx_OUT_OUT], figname=os.path.join(explain_dir,'class{}_{}_{}_OUT.jpg'.format(i, args.score, args.out_data)))\n",
    "            if np.sum(idx_OUT_IN)!=0:\n",
    "                save_images(out_files_ith[idx_OUT_IN], figname=os.path.join(explain_dir,'class{}_{}_{}_IN.jpg'.format(i, args.score, args.out_data)))\n",
    "    logger.flush()\n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ## Computing ConceptSHAP.............\n",
    "            \n",
    "    if args.shap:\n",
    "    \n",
    "        shap_path = os.path.join(explain_dir,'{}_SHAP.pkl'.format(args.score.lower()))\n",
    "        if os.path.exists(shap_path):\n",
    "            print(f\"Loading shap values from file {shap_path}\")\n",
    "            with open(shap_path,'rb') as f:\n",
    "                shap_expl = pickle.load(f)\n",
    "    \n",
    "        else:\n",
    "            nc = N_CONCEPTS_ORIG # number of concepts before duplicate removal\n",
    "            #inputs = list(itertools.product([0, 1], repeat=N_CONCEPTS_ORIG)) #NOTE: computationally very expensive\n",
    "            inputs = np.ones((len(dict_dupl_topic),nc))\n",
    "            for d in dict_dupl_topic:\n",
    "                idx = [d] + dict_dupl_topic[d]\n",
    "                inputs[d,idx] = 0\n",
    "            inputs = np.unique([tuple(row) for row in inputs], axis=0)\n",
    "            # inputs = inputs[:2]\n",
    "    \n",
    "            #classes = [1, 4]\n",
    "            outputs_class = np.array([])\n",
    "            outputs_detect = np.array([])\n",
    "            kernel = np.array([])\n",
    "            for concept_mask in inputs:\n",
    "                logger.info('======================================================')\n",
    "                compl_class, compl_detect = compute_conceptSHAP(concept_mask, topic_vec_orig,\n",
    "                                            in_test_features, out_test_features, y_test, in_test_yhat, out_test_yhat, auroc,\n",
    "                                            in_loader, out_loader,\n",
    "                                            topic_model, feature_model, args, logger,\n",
    "                                            finetune=False, labels=list(range(N_CLASSES)))\n",
    "                outputs_class = np.append(outputs_class, compl_class)\n",
    "                outputs_detect = np.append(outputs_detect, compl_detect)\n",
    "                k = np.sum(concept_mask)\n",
    "                kernel = np.append(kernel, (nc-1)*1.0/((nc-k)*k*comb(nc, k)))\n",
    "    \n",
    "            outputs_class = outputs_class.reshape(-1,N_CLASSES)\n",
    "            outputs_detect = outputs_detect.reshape(-1,N_CLASSES)\n",
    "            kernel[kernel == np.inf] = 1e+4\n",
    "            x = np.array(inputs)\n",
    "            xkx = np.matmul(np.matmul(x.transpose(), np.diag(kernel)), x)\n",
    "            shap_expl = {'mask': inputs}\n",
    "            for i in range(N_CLASSES):\n",
    "                xky_class = np.matmul(np.matmul(x.transpose(), np.diag(kernel)), outputs_class[:,i])\n",
    "                shap_class = np.matmul(np.linalg.pinv(xkx), xky_class)\n",
    "                shap_expl[f'shap_class_class{i}'] = shap_class\n",
    "    \n",
    "                idx = ~np.isnan(outputs_detect[:,i].astype(float))\n",
    "                xkx_detect = np.matmul(np.matmul(x[idx,:].T, np.diag(kernel[idx])), x[idx,:])\n",
    "                xky_detect = np.matmul(np.matmul(x[idx,:].T, np.diag(kernel[idx])), outputs_detect[idx,i])\n",
    "                shap_detect = np.matmul(np.linalg.pinv(xkx), xky_detect)\n",
    "                shap_expl[f'shap_detect_class{i}'] = shap_detect\n",
    "                shap_expl[f'mask_detect_class{i}'] = x[idx,:]\n",
    "    \n",
    "            print(f\"Saving shap values to file {shap_path}\")\n",
    "            with open(shap_path,'wb') as f:\n",
    "                pickle.dump(shap_expl, f)\n",
    "    \n",
    "    # concept_dict = prepare_profiles(feature_model, topic_vec, N_CLASSES, args, logger)\n",
    "    \n",
    "    # if args.plot:\n",
    "    #     log_path = '{}/{}'.format(args.logdir, args.name)\n",
    "    #     plot_score_distr(concept_dict, in_test_concepts, in_test_yhat, out_test_concepts, out_test_yhat, save_plot=log_path)\n",
    "    \n",
    "    logger.flush()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c859f5-7788-467b-96af-dab1d89b2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_expl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6b57e-d3a8-4722-9aa9-b54fc3366d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size=11, sigma=5):\n",
    "    def gauss_kernel(channels, kernel_size, sigma):\n",
    "        ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)\n",
    "        xx, yy = tf.meshgrid(ax, ax)\n",
    "        kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))\n",
    "        kernel = kernel / tf.reduce_sum(kernel)\n",
    "        kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])\n",
    "        return kernel\n",
    "\n",
    "    gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)\n",
    "    gaussian_kernel = gaussian_kernel[..., tf.newaxis]\n",
    "\n",
    "    return tf.nn.depthwise_conv2d(np.expand_dims(img, axis=0), gaussian_kernel, [1, 1, 1, 1],\n",
    "                                  padding='SAME', data_format='NHWC')\n",
    "    \n",
    "k = 10\n",
    "n_seeds = 100\n",
    "n_sampling = 50\n",
    "os.makedirs(os.path.join(args.result_dir, \"concept_sims\"), exist_ok=True)\n",
    "rlt_dict_rob = dict()\n",
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    for perturbations in [\n",
    "                            # [\"rotation\", \"translation\", \"scale\"],\n",
    "                            [\"hue\", \"saturation\", \"bright_contrast\"],\n",
    "                            [\"blur\"]\n",
    "                        ]:\n",
    "        N_ID_SEEDs, N_OOD_SEEDs, N_ID_DAEs, N_OOD_DAEs, N_MAEs = 0, 0, 0, 0, 0\n",
    "        \n",
    "        for class_i in range(23, 33): # 0, 12, 25, 5, 40\n",
    "            concepts = []\n",
    "            concepts_maxpatch = np.argsort(in_test_concepts, axis=0)[::-1]\n",
    "            for concept_id in range(N_CONCEPTS):\n",
    "                if (y_test[concepts_maxpatch[:4, concept_id]] == class_i).all():\n",
    "                    concepts.append(concept_id)\n",
    "            concepts = np.array(concepts, dtype=int)\n",
    "            print(f\"Concepts of class {class_i}:\", concepts)\n",
    "            \n",
    "\n",
    "            idx_in_true = np.where((in_test_yhat == class_i)*(y_test==class_i))[0]\n",
    "            idx_in_false = np.where((in_test_yhat == class_i)*(y_test!=class_i))[0]\n",
    "            \n",
    "            idx_IN_IN = np.where((in_test_yhat == class_i)*(y_test==class_i)*(in_test_scores>=thres95))[0]   # ID detected as ID\n",
    "            idx_IN_OUT = np.where((in_test_yhat == class_i)*(y_test==class_i)*(in_test_scores<thres95))[0]   # ID detected as OOD\n",
    "            idx_OUT_OUT = np.where((out_test_yhat == class_i)*(out_test_scores<thres95))[0] # OOD detected as OOD\n",
    "            idx_OUT_IN = np.where((out_test_yhat == class_i)*(out_test_scores>=thres95))[0]   # OOD detected as ID\n",
    "            \n",
    "            sp_groups = {\"ID->ID\": idx_IN_IN, \"OOD->OOD\": idx_OUT_OUT} # \"ID->OOD\": idx_IN_OUT, \"OOD->ID\": idx_OUT_IN, \n",
    "            for grp_name, grp in sp_groups.items():\n",
    "                if len(grp) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if len(grp) > n_seeds:\n",
    "                    idx_ = np.random.choice(grp, size=n_seeds,replace=False)\n",
    "                else:\n",
    "                    idx_ = grp\n",
    "                \n",
    "                if (\"ID->\" in grp_name) or (\"ID_\" in grp_name):\n",
    "                    x_seeds = np.array([in_loader[i_//256][0][i_%256] for i_ in idx_])\n",
    "                    y_seeds = np.array([in_loader[i_//256][1][i_%256] for i_ in idx_])\n",
    "                    y_seeds = np.argmax(y_seeds, axis=1)\n",
    "                    c_seeds = in_test_concepts[idx_, :]\n",
    "\n",
    "                    N_ID_SEEDs += len(idx_)\n",
    "                else:\n",
    "                    x_seeds = np.array([out_loader[i_//256][i_%256] for i_ in idx_])\n",
    "                    c_seeds = out_test_concepts[idx_, :]\n",
    "\n",
    "                    N_OOD_SEEDs += len(idx_)\n",
    "\n",
    "            \n",
    "                # \"rotation\", \"translation\", \"scale\"\n",
    "            \n",
    "                c_perbs_all = np.empty((0, N_CONCEPTS))\n",
    "                s_perbs_all = np.empty(0)\n",
    "                y_pred_perbs_all = np.empty(0)\n",
    "                y_perbs_all = np.empty(0)\n",
    "                \n",
    "                for s_i, x_seed in enumerate(x_seeds):\n",
    "                    \n",
    "                    # +perturbations\n",
    "                    x_seed = np.expand_dims(x_seed, axis=0)\n",
    "                    x_perbs = np.repeat(x_seed, n_sampling, axis=0)\n",
    "                    \n",
    "                    if \"rotation\" in perturbations:\n",
    "                        rot = tf.keras.layers.RandomRotation(factor=(-0.1, 0.1), fill_mode=\"constant\")\n",
    "                        x_perbs = rot(x_perbs)\n",
    "                    elif \"translation\" in perturbations:\n",
    "                        trans = tf.keras.layers.RandomTranslation(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2), \n",
    "                                                                    fill_mode=\"constant\")\n",
    "                        x_perbs = trans(x_perbs)\n",
    "                    elif \"scale\" in perturbations:\n",
    "                        scale = tf.keras.layers.RandomZoom(height_factor=(-0.2, 0.2), fill_mode=\"constant\")\n",
    "                        x_perbs = scale(x_perbs)\n",
    "                    elif \"hue\" in perturbations:\n",
    "                        x_perbs = tf.image.random_hue(x_perbs, 0.15, seed=None)\n",
    "                    elif \"bright_contrast\" in perturbations:\n",
    "                        x_perbs = tf.image.random_brightness(x_perbs, 0.3, seed=None)\n",
    "                        x_perbs = tf.image.random_contrast(x_perbs, 0.7, 1.3)\n",
    "                    elif \"saturation\" in perturbations:\n",
    "                        saturation_factor = np.random.uniform(0.5, 1.5)\n",
    "                        x_perbs = tf.image.adjust_saturation(x_perbs, saturation_factor)\n",
    "                    elif \"blur\" in perturbations:\n",
    "                        sigmas = np.random.uniform(0.2, 0.8, size=x_perbs.shape[0])\n",
    "                        for i_, sig in enumerate(sigmas):\n",
    "                            x_perbs[i_] = gaussian_blur(x_perbs[i_], kernel_size=10, sigma=sig)\n",
    "                    elif \"Linf\" in perturbations:\n",
    "                        x_perbs += np.random.uniform(0, 0.1, size=x_perbs.shape)\n",
    "                \n",
    "                    f_perbs = feature_model(x_perbs)\n",
    "                    c_perbs, logit_perbs = compute_concept_scores(topic_vec, f_perbs, predict_model)\n",
    "                    y_pred_perbs = np.argmax(logit_perbs, axis=1)\n",
    "\n",
    "                    s_perbs = run_ood_over_batch(x_perbs, feature_model, predict_model, args, N_CLASSES).numpy()\n",
    "\n",
    "                    c_perbs_all = np.concatenate([c_perbs_all, c_perbs])\n",
    "                    s_perbs_all = np.concatenate([s_perbs_all, s_perbs])\n",
    "\n",
    "                    if (\"ID->\" in grp_name) or (\"ID_\" in grp_name):\n",
    "                        y_perbs_all = np.concatenate([y_perbs_all, np.repeat(y_seeds[s_i], n_sampling)])\n",
    "                        y_pred_perbs_all = np.concatenate([y_pred_perbs_all, y_pred_perbs])\n",
    "\n",
    "                if (\"ID->\" in grp_name) or (\"ID_\" in grp_name):\n",
    "                    i_ndaes = np.where(s_perbs_all >= thres95)[0]\n",
    "                    i_daes = np.where(s_perbs_all < thres95)[0]\n",
    "                    i_nmaes = np.where(y_pred_perbs_all == y_perbs_all)[0]\n",
    "                    i_maes = np.where(y_pred_perbs_all != y_perbs_all)[0]\n",
    "\n",
    "                    c_nmaes = c_perbs_all[i_nmaes]\n",
    "                    c_maes = c_perbs_all[i_maes]\n",
    "\n",
    "                    N_ID_DAEs += len(i_daes)\n",
    "                    N_MAEs += len(i_maes)\n",
    "\n",
    "                else:\n",
    "                    i_ndaes = np.where(s_perbs_all < thres95)[0]\n",
    "                    i_daes = np.where(s_perbs_all >= thres95)[0]\n",
    "\n",
    "                    N_OOD_DAEs += len(i_daes)\n",
    "\n",
    "                c_ndaes = c_perbs_all[i_ndaes]\n",
    "                c_daes = c_perbs_all[i_daes]\n",
    "\n",
    "                if len(concepts) == 0:\n",
    "                    continue     \n",
    "                \n",
    "                if (\"ID->\" in grp_name) or (\"ID_\" in grp_name):\n",
    "                    fig, axes = plt.subplots(len(concepts),2, figsize=(16, len(concepts)*4), layout=\"constrained\")\n",
    "                    axes = axes.flatten()\n",
    "                    for a_i in range(0, len(axes), 2):\n",
    "                        c_i = concepts[a_i//2]\n",
    "                        ax = axes[a_i]\n",
    "                        ax1 = axes[a_i+1]\n",
    "                        sns.barplot({f\"Seeds\\nN={len(idx_)}\": c_seeds[:, c_i], \n",
    "                                    f\"Non-DAEs\\n({round(len(i_ndaes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_ndaes[:, c_i], \n",
    "                                    f\"DAEs\\n({round(len(i_daes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_daes[:, c_i],\n",
    "                                    f\"Non-MAEs\\n({round(len(i_nmaes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_nmaes[:, c_i], \n",
    "                                    f\"MAEs\\n({round(len(i_maes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_maes[:, c_i]}, ax=ax)\n",
    "                        sns.violinplot({f\"Seeds\\nN={len(idx_)}\": c_seeds[:, c_i], \n",
    "                                    f\"Non-DAEs\\n({round(len(i_ndaes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_ndaes[:, c_i], \n",
    "                                    f\"DAEs\\n({round(len(i_daes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_daes[:, c_i],\n",
    "                                    f\"Non-MAEs\\n({round(len(i_nmaes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_nmaes[:, c_i], \n",
    "                                    f\"MAEs\\n({round(len(i_maes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_maes[:, c_i]}, ax=ax1)\n",
    "                        ax.set_ylim(0,1)\n",
    "                        ax1.set_ylim(0,1)\n",
    "                        ax.set_title(f\"C{c_i}\", fontsize=18, loc=\"left\")\n",
    "                    plt.suptitle(f\"Class {class_i}, {grp_name} seeds, perturbation={'_'.join(perturbations)}\")\n",
    "                    os.makedirs(os.path.join(args.result_dir, \"robustness_test\"), exist_ok=True)\n",
    "                    plt.savefig(os.path.join(args.result_dir, \"robustness_test\", f\"class_{class_i}_{grp_name}_perb_{'_'.join(perturbations)}.jpg\"))\n",
    "                    plt.show()\n",
    "                    plt.close(\"all\")\n",
    "                \n",
    "                else:\n",
    "                    fig, axes = plt.subplots(len(concepts),2, figsize=(16, len(concepts)*4), layout=\"constrained\")\n",
    "                    axes = axes.flatten()\n",
    "                    for a_i in range(0, len(axes), 2):\n",
    "                        c_i = concepts[a_i//2]\n",
    "                        ax = axes[a_i]\n",
    "                        ax1 = axes[a_i+1]\n",
    "                        sns.barplot({f\"Seeds\\nN={len(idx_)}\": c_seeds[:, c_i], \n",
    "                                    f\"Non-DAEs\\n({round(len(i_ndaes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_ndaes[:, c_i], \n",
    "                                    f\"DAEs\\n({round(len(i_daes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_daes[:, c_i]}, ax=ax)\n",
    "                        sns.violinplot({f\"Seeds\\nN={len(idx_)}\": c_seeds[:, c_i], \n",
    "                                        f\"Non-DAEs\\n({round(len(i_ndaes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_ndaes[:, c_i], \n",
    "                                        f\"DAEs\\n({round(len(i_daes)/(len(idx_)*n_sampling)*100, 3)}%)\": c_daes[:, c_i]}, ax=ax1)\n",
    "                        ax.set_ylim(0,1)\n",
    "                        ax1.set_ylim(0,1)\n",
    "                        ax.set_title(f\"C{c_i}\", fontsize=18, loc=\"left\")\n",
    "                    plt.suptitle(f\"Class {class_i}, {grp_name} seeds, perturbation={'_'.join(perturbations)}\")\n",
    "                    os.makedirs(os.path.join(args.result_dir, \"robustness_test\"), exist_ok=True)\n",
    "                    plt.savefig(os.path.join(args.result_dir, \"robustness_test\", f\"class_{class_i}_{grp_name}_perb_{'_'.join(perturbations)}.jpg\"))\n",
    "                    plt.show()\n",
    "                    plt.close(\"all\")\n",
    "\n",
    "            rlt_dict_rob[\"_\".join(perturbations)] = {\"N_ID_SEEDs\": N_ID_SEEDs, \"N_OOD_SEEDs\": N_OOD_SEEDs,\n",
    "                                                    \"N_ID_DAEs\": N_ID_DAEs, \"N_OOD_DAEs\": N_OOD_DAEs, \"N_MAEs\": N_MAEs}\n",
    "            print(rlt_dict_rob)\n",
    "        \n",
    "        # rlt_dict_rob[\"_\".join(perturbations)] = {\"N_ID_SEEDs\":N_ID_SEEDs,\"N_OOD_SEEDs\":N_OOD_SEEDs,\n",
    "        #                                         \"N_ID_DAEs\":N_ID_DAEs, \"N_OOD_DAEs\":N_OOD_DAEs, \"N_MAEs\":N_MAEs}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
